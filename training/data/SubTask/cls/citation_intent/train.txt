{"text": "This was done by MERT optimization ( Och , 2003 ) towards post-edits under the TER target metric .", "label": "Uses", "metadata": {}}
{"text": "Briscoe and Carroll ( 1997 ) report on manually analyzing an open-class vocabulary of 35,000 head words for predicate subcategorization information and comparing the results against the subcategorization details in COMLEX .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Finally , feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication ( Fujie et al. , 2004 ; Morency et al. , 2005 ; Morency et al. , 2007 ; Morency et al. , 2009 ) .", "label": "Background", "metadata": {}}
{"text": "We use the agreement checker code developed by Alkuhlani and Habash ( 2011 ) and evaluate our baseline ( MaltParser using only CORE12 ) , best performing model ( Easy-First Parser using CORE12 + DET+LMM+PERSON+FN * NGR g + p ) , and the gold reference .", "label": "Uses", "metadata": {}}
{"text": "The diagnoser , based on Dzikovska et al. ( 2008b ) , outputs a diagnosis which consists of lists of correct , contradictory and non-mentioned objects and relations from the student 's answer .", "label": "Extends", "metadata": {}}
{"text": "Similar to ( Li et al. , 2013a ) , our summarization system is , which consists of three key components : an initial sentence pre-selection module to select some important sentence candidates ; the above compression model to generate n-best compressions for each sentence ; and then an ILP summarization method to select the best summary sentences from the multiple compressed sentences .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The extraction procedure consists of three steps : First , the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of Magerman ( 1994 ) and Collins ( 1997 ) .", "label": "Background", "metadata": {}}
{"text": "But their importance has grown far beyond machine translation : for instance , transferring annotations between languages ( Yarowsky and Ngai 2001 ; Hwa et al. 2005 ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay 2008 ) .", "label": "Motivation", "metadata": {}}
{"text": "McKnight and Srinivasan ( 2003 ) have previously examined the task of categorizing sentences in medical abstracts using supervised discriminative machine learning techniques .", "label": "Background", "metadata": {}}
{"text": "This recognizer incrementally outputs word hypotheses as soon as they are found in the best-scored path in the forward search ( Hirasawa et al. , 1998 ) using the ISTAR ( Incremental Structure Transmitter And Receiver ) protocol , which conveys word graph information as well as word hypotheses .", "label": "Background", "metadata": {}}
{"text": "Tateisi et al. also translated LTAG into HPSG ( Tateisi et al. , 1998 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "There has also been work focused upon determining the political leaning ( e.g. , `` liberal '' vs. `` conservative '' ) of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified ( the `` unlabeled '' texts ) ( Laver et al. , 2003 ; Efron , 2004 ; Mullen and Malouf , 2006 ) .", "label": "Background", "metadata": {}}
{"text": "In this paper , inspired by KNN-SVM ( Zhang et al. , 2006 ) , we propose a local training method , which trains sentence-wise weights instead of a single weight , to address the above two problems .", "label": "Motivation", "metadata": {}}
{"text": "1990 ) , on linguisitic acquisition ( by the use of Part-of-Speech filters hand-crafted by a linguist ) ( Oueslati , 1999 ) or , more frequently , on a combination of the two ( Smadja , 1993 ; Kilgarriff and Tugwell , 2001 , for example ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Thus for instance , ( Copestake and Flickinger , 2000 ; Copestake et al. , 2001 ) describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and ( Dalrymple , 1999 ) show how to equip Lexical Functional grammar ( LFG ) with a glue semantics .", "label": "Background", "metadata": {}}
{"text": "While many linguistic theories state subcategorization requirements in terms of phrase structure ( CFG categories ) , Dalrymple ( 2001 ) questions the viability and universality of such an approach because of the variety of ways in which grammatical functions may be realized at the language-specific constituent structure level .", "label": "Background", "metadata": {}}
{"text": "We are going to make such a comparison with the theories proposed by J. Hobbs ( 1979 , 1982 ) that represent a more computationally oriented approach to coherence , and those of T.A. van Dijk and W. Kintch ( 1983 ) , who are more interested in addressing psychological and cognitive aspects of discourse coherence .", "label": "CompareOrContrast", "metadata": {}}
{"text": "11 From ( Zollmann and Vogel , 2011 ) , we find that the performance of SAMT system is similar with the method of labeling SCFG rules with POS tags .", "label": "Motivation", "metadata": {}}
{"text": "In this paper we focus on the exploitation of the LDOCE grammar coding system ; Alshawi et al. ( 1985 ) and Alshawi ( 1987 ) describe further research in Cambridge utilising different types of information available in LDOCE .", "label": "Background", "metadata": {}}
{"text": "Although originally developed as a tool to assist in query formulation , Booth ( 2000 ) pointed out that PICO frames can be employed to structure IR results for improving precision .", "label": "Background", "metadata": {}}
{"text": "We can define PCAT using a probabilistic grammar ( Garrette et al. , 2014 ) .", "label": "Background", "metadata": {}}
{"text": "It is these orthographic variations and complex morphological structure that make Arabic language processing challenging ( Xu et al. , 2001 ; Xu et al. , 2002 ) .", "label": "Background", "metadata": {}}
{"text": "The first is the one used in the chunking competition in CoNLL-2000 ( Tjong Kim Sang and Buchholz , 2000 ) .", "label": "Uses", "metadata": {}}
{"text": "There have been many studies on parsing techniques ( Poller and Becker , 1998 ; Flickinger et al. , 2000 ) , ones on disambiguation models ( Chiang , 2000 ; Kanayama et al. , 2000 ) , and ones on programming/grammar-development environ -", "label": "Background", "metadata": {}}
{"text": "The ten most specific nouns have been produced by comparing our corpus of computing to the French corpus Le Monde , composed of newspaper articles ( Lemay et al. , 2004 ) .", "label": "Uses", "metadata": {}}
{"text": "Secondly , we need to investigate techniques for identifying identical documents , virtually identical documents and highly repetitive documents , such as those pioneered by Fletcher ( 2004b ) and shingling techniques described by Chakrabarti ( 2002 ) .", "label": "Future", "metadata": {}}
{"text": "From an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition ( Pacak et al. , 1980 ; Norton and Pacak , 1983 ; Wolff , 1984 ; Wingert , 1985 ; Dujols et al. , 1991 ; Baud et al. , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Rather than producing a complete analysis of sentences , the alternative is to perform only partial analysis of the syntactic structures in a text ( Harris , 1957 ; Abney , 1991 ; Greffenstette , 1993 ) .", "label": "Background", "metadata": {}}
{"text": "Problems such as these have motivated research on more abstract , dependencybased parser evaluation ( e.g. , Lin 1995 ; Carroll , Briscoe , and Sanfilippo 1998 ; Carroll et al. 2002 ; Clark and Hockenmaier 2002 ; King et al. 2003 ; Preiss 2003 ; Kaplan et al. 2004 ; Miyao and Tsujii 2004 ) .", "label": "Motivation", "metadata": {}}
{"text": "They are widely used in MT as a way to figure out how to translate input in one language into output in another language ( Koehn et al. , 2003 ) .", "label": "Background", "metadata": {}}
{"text": "Dale and Reiter ( 1995 ) , for example , discussed the transcripts of a dialogue between people who assemble a piece of garden furniture ( originally recorded by Candy Sidner ) .", "label": "Background", "metadata": {}}
{"text": "Here , PV ( A ) represents an ascent direction chosen as follows : For inequality constraints , it is the projected gradient ( Bertsekas 1999 ) ; for equality constraints with slack , we use conjugate gradient ( Nocedal and Wright 1999 ) , noting that when A = 0 , the objective is not differentiable .", "label": "Uses", "metadata": {}}
{"text": "Some methods are based on likelihood ( Och and Ney , 2002 ; Blunsom et al. , 2008 ) , error rate ( Och , 2003 ; Zhao and Chen , 2009 ; Pauls et al. , 2009 ; Galley and Quirk , 2011 ) , margin ( Watanabe et al. , 2007 ; Chiang et al. , 2008 ) and ranking ( Hopkins and May , 2011 ) , and among which minimum error rate training ( MERT ) ( Och , 2003 ) is the most popular one .", "label": "Motivation", "metadata": {}}
{"text": "A parsing experiment shows that an efficient HPSG parser with the obtained grammar achieved a significant speed-up against an existing LTAG parser ( Yoshinaga et al. , 2001 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Such questions are typically answered by designing appropriate priming experiments ( Marslen-Wilson et al. , 1994 ) or other lexical decision tasks .", "label": "Background", "metadata": {}}
{"text": "The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program ( Stabler , 1997 ; Harkema , 2000 ; Niyogi , 2001 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Michiels ( 1982 ) and Akkerman et al. ( 1985 ) provide a more detailed analysis of the information encoded by the LDOCE grammar codes and discuss their efficacy as a system of linguistic description .", "label": "Background", "metadata": {}}
{"text": "The research described below is taking place in the context of three collaborative projects ( Boguraev , 1987 ; Russell et al. , 1986 ; Phillips and Thompson , 1986 ) to develop a general-purpose , wide coverage morphological and syntactic analyser for English .", "label": "Background", "metadata": {}}
{"text": "Viewed in this way , gradable adjectives are an extreme example of the `` efficiency of language '' ( Barwise and Perry 1983 ) : Far from meaning something concrete like `` larger than 8 cm '' -- a concept that would have very limited applicability -- or even something more general like `` larger than the average N , '' a word like large is applicable across a wide range of different situations .", "label": "CompareOrContrast", "metadata": {}}
{"text": "However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time ( Charniak , 1997b ; Charniak , 1997a ; Collins , 1997 ; Ratnaparkhi , 1997 ) .", "label": "Background", "metadata": {}}
{"text": "However , the greatest increase is in the amount of raw text available to be processed , e.g. the English Gigaword Corpus ( Linguistic Data Consortium , 2003 ) .", "label": "Background", "metadata": {}}
{"text": "For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning ( Menezes & Richardson , 2001 ) , ( Aramaki et al. , 2001 ) , ( Watanabe et al. , 2000 ) , ( Meyers et al. , 2000 ) , ( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 ( Sato & Nagao , 1990 ) , ( Sato , 1991 ) , ( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 ) .", "label": "Background", "metadata": {}}
{"text": "Och and Ney ( 2002 ) introduced the log-linear model for statistical machine translation ( SMT ) , in which translation is considered as the following optimization problem :", "label": "Background", "metadata": {}}
{"text": "Representative systems are described in Boisen et al. ( 1989 ) , De Mattia and Giachin ( 1989 ) , Niedermair ( 1989 ) , Niemann ( 1990 ) , and Young ( 1989 ) .", "label": "Background", "metadata": {}}
{"text": "Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations ( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring ( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .", "label": "Background", "metadata": {}}
{"text": "We first identified the most informative unigrams and bigrams using the information gain measure ( Yang and Pedersen 1997 ) , and then selected only the positive outcome predictors using odds ratio ( Mladenic and Grobelnik 1999 ) .", "label": "Uses", "metadata": {}}
{"text": "Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed ( Neville and Jensen , 2000 ; Lafferty et al. , 2001 ; Getoor et al. , 2002 ; Taskar et al. , 2002 ; Taskar et al. , 2003 ; Taskar et al. , 2004 ; McCallum and Wellner , 2004 ) .", "label": "Background", "metadata": {}}
{"text": "It compares favorably to other stemming or root extraction algorithms ( Yates and Neto , 1999 ; Al-Shalabi and Evens , 1998 ; and Houmame , 1999 ) , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .", "label": "Motivation", "metadata": {}}
{"text": "We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in ( Ratnaparkhi , 1997 ) and ( Chelba and Jelinek , 1998 ) .", "label": "Future", "metadata": {}}
{"text": "The PERSIVAL project , the most comprehensive study of such techniques applied on medical texts to date , leverages patient records to generate personalized summaries in response to physicians ' queries ( McKeown , Elhadad , and Hatzivassiloglou 2003 ; Elhadad et al. 2005 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "See Lopez and Resnik ( 2006 ) for further discussion .", "label": "Background", "metadata": {}}
{"text": "Thus , for example , it can acquire a `` script '' such as the one for going to a restaurant as defined in Schank and Abelson ( 1977 ) .", "label": "Background", "metadata": {}}
{"text": "There is some literature on procedure acquisition such as the LISP synthesis work described in Biermann et al. ( 1984 ) and the PROLOG synthesis method of Shapiro ( 1982 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The system uses a domain-specific content planner to produce input to the surface realizer based on the strategy decision , and a FUF/SURGE ( Elhadad and Robin , 1992 ) generation system to produce the appropriate text .", "label": "Uses", "metadata": {}}
{"text": "However , each of these fields requires further decoding and restructuring to provide client programs with easy access to the information they require ( see Calzolari ( 1984 ) for further discussion ) .", "label": "Background", "metadata": {}}
{"text": "It compares favorably to other stemming or root extraction algorithms ( Yates and Neto , 1999 ; Al-Shalabi and Evens , 1998 ; and Houmame , 1999 ) , with a performance of over 97 % for extracting the correct root in web documents , and it addresses the challenge of the Arabic broken plural and hollow verbs .", "label": "Motivation", "metadata": {}}
{"text": "In a similar vein , Steyvers ( 2010 ) showed that a different feature-topic model improved predictions on a fill-in-the-blank task .", "label": "Background", "metadata": {}}
{"text": "As ( Daelemans et al. , 1999 ) show , lexical information improves on NP and VP chunking as well .", "label": "Future", "metadata": {}}
{"text": "In multi-party discussion people usually mention each other 's name for the purpose of disentanglement ( Elsner and Charniak , 2008 ) .", "label": "Background", "metadata": {}}
{"text": "Fortunately , indirect associations are usually not difficult to identify , because they tend to be weaker than the direct associations on which they are based ( Melamed , 1996c ) .", "label": "Background", "metadata": {}}
{"text": "The work of Sarkar ( 2001 ) and Steedman , Osborne , et al. ( 2003 ) suggests that co-training can be helpful for statistical parsing .", "label": "Background", "metadata": {}}
{"text": "TNT refers to the HPSG parser ( Torisawa et al. , 2000 ) , C++ implementation of the two-phase parsing algorithm that performs filtering with a compiled CFG ( phase 1 ) and then executes feature unification ( phase 2 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "1 \u00c2\u00b0 The body of a plan can be an action or sequence of actions , a goal or sequence 9 Moore and Paris also note that `` a generation system must maintain the kinds of information outlined by Grosz and Sidner '' ( Moore and Paris 1989 , 203 ) .", "label": "Background", "metadata": {}}
{"text": "The standard way to handle this problem is to handcraft a finite set of features which provides a sufficient summary of the unbounded history ( Ratnaparkhi , 1999 ; Collins , 1999 ; Charniak , 2000 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Most approaches rely on VerbNet ( Kipper et al. , 2000 ) and FrameNet ( Baker et al. , 1998 ) to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions ( Carreras and Marquez , 2004 ; Carreras and Marquez , 2005 ) and also ( Gildea and Jurafsky , 2002 ; Pradhan et al. , 2005 ; Shi and Mihalcea , 2005 ) .", "label": "Background", "metadata": {}}
{"text": "Note that this ensures that greater importance is attributed to longer chunks , as is usual in most EBMT systems ( cfXXX Sato and Nagao 1990 ; Veale and Way 1997 ; Carl 1999 ) .7 As an example , consider the translation into French of the house collapsed .", "label": "Background", "metadata": {}}
{"text": "These automatic transformations are based on linguistic rules ( Bohmova , 2001 ) .", "label": "Uses", "metadata": {}}
{"text": "\u00e2\u0080\u00a2 use of low level knowledge from the speech recognition phase , \u00e2\u0080\u00a2 use of high level knowledge about the domain in particular and the dialogue task in general , \u00e2\u0080\u00a2 a `` continue '' facility and an `` auto-loop '' facility as described by Biermann and Krishnaswamy ( 1976 ) , \u00e2\u0080\u00a2 a `` conditioning '' facility as described by Fink et al. ( 1985 ) , \u00e2\u0080\u00a2 implementation of new types of paraphrasing , \u00e2\u0080\u00a2 checking a larger environment in the expectation acquisition algorithm when deciding if an incoming sentence is the same or similar to one already seen , and \u00e2\u0080\u00a2 examining inter-speaker dialogue patterns .", "label": "Future", "metadata": {}}
{"text": "Ratinov and Roth ( 2009 ) present detailed studies on the task of named entity recognition , which discusses and compares different methods on multiple aspects including chunk representation , inference method , utility of non-local features , and integration of external knowledge .", "label": "Background", "metadata": {}}
{"text": "Cases like this would be covered if the decision-theoretic property of Pareto optimality ( e.g. , Feldman 1980 ) was used as the sole criterion : Formally , an object r E C has a Pareto-optimal combination of Values V iff there is no other x E C such that", "label": "Background", "metadata": {}}
{"text": "A formula for the test set perplexity ( Lee 1989 ) is :13", "label": "Background", "metadata": {}}
{"text": "This method follows a traditional Information Retrieval paradigm ( Salton and McGill 1983 ) , where a query is represented by the content terms it contains , and the system retrieves from the corpus a set of documents that best match this query .", "label": "Uses", "metadata": {}}
{"text": "Brockmann and Lapata ( 2003 ) have showed that WordNet-based approaches do not always outperform simple frequency-based models , and a number of techniques have been recently proposed which may offer ideas for refining our current unsupervised approach ( Erk , 2007 ; Bergsma et al. , 2008 ) .", "label": "Future", "metadata": {}}
{"text": "For the cases where retrieval took place , we used F-score ( van Rijsbergen 1979 ; Salton and McGill 1983 ) to determine the similarity between the response from the top-ranked document and the real response ( the formulas for F-score and its contributing factors , recall and precision , appear in Section 4.2 ) .", "label": "Uses", "metadata": {}}
{"text": "The list , a synthesis of a number of relation lists cited in the literature , has been designed to be general , domainindependent ( Barker et al. , 1997a ) .", "label": "Motivation", "metadata": {}}
{"text": "Unlike our approach , those of Xia ( 1999 ) and Hockenmaier , Bierner , and Baldridge ( 2004 ) include a substantial initial correction and clean-up of the Penn-II trees .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Our motivation for generation of material for language education exists in work such as Sumita et al. ( 2005 ) and Mostow and Jang ( 2012 ) , which deal with automatic generation of classic fill in the blank questions .", "label": "Motivation", "metadata": {}}
{"text": "In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance ( Blume , 2005 ; Chen and Martin , 2007 ; Popescu and Magnini , 2007 ; Kalashnikov et al. , 2007 ) .", "label": "Background", "metadata": {}}
{"text": "Some works abstract perception via the usage of symbolic logic representations ( Chen et al. , 2010 ; Chen and Mooney , 2011 ; Matuszek et al. , 2012 ; Artzi and Zettlemoyer , 2013 ) , while others choose to employ concepts elicited from psycholinguistic and cognition studies .", "label": "Background", "metadata": {}}
{"text": "Over the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation ( Brown et al. , 1988 ; Brown et al. , 1990 ; Brown et al. , 1993a ) .", "label": "Background", "metadata": {}}
{"text": "One area of current interest concerns the left-to-right arrangement of premodifying adjectives within an NP ( e.g. , Shaw and Hatzivassiloglou 1999 ; Malouf 2000 ) .", "label": "Background", "metadata": {}}
{"text": "Models of translational equivalence that are ignorant of indirect associations have `` a tendency ... to be confused by collocates '' ( Dagan et al. , 1993 ) .", "label": "Background", "metadata": {}}
{"text": "Note that although our feature set was drawn primarily from our prior uncertainty detection experiments ( Forbes-Riley and Litman , 2011a ; Drummond and Litman , 2011 ) , we have also experimented with other features , including state-of-theart acoustic-prosodic features used in the last Interspeech Challenges ( Schuller et al. , 2010 ; Schuller et al. , 2009b ) and made freely available in the openSMILE Toolkit ( Florian et al. , 2010 ) .", "label": "Extends", "metadata": {}}
{"text": "For this mention-pair coreference model \u00cf\u0086 ( u , v ) , we use the same set of features used in Bengtson and Roth ( 2008 ) .", "label": "Uses", "metadata": {}}
{"text": "Compared to the reranking technique in Collins ( 2000 ) , who obtained an LP of 89.9 % and an LR of 89.6 % , our results show a 9 % relative error rate reduction .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The paper compares and contrasts the training time needed and performance achieved by our modified learner with two other systems : a standard transformation-based learner , and the ICA system ( Hepple , 2000 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "There has also been work focused upon determining the political leaning ( e.g. , `` liberal '' vs. `` conservative '' ) of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified ( the `` unlabeled '' texts ) ( Laver et al. , 2003 ; Efron , 2004 ; Mullen and Malouf , 2006 ) .", "label": "Background", "metadata": {}}
{"text": "It projects a functional head , voice ( Kratzer , 1994 ) , whose specifier is the external argument .", "label": "Background", "metadata": {}}
{"text": "This is noticeable for German ( Brants et al. , 2002 ) and Portuguese ( Afonso et al. , 2002 ) , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B \u00c2\u00a8 ohmov \u00c2\u00b4 a et al. , 2003 ) , Dutch ( van der Beek et al. , 2002 ) and Slovene ( D\u00cb\u0087zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 71 % and 41 % , respectively , and root recall is also affected negatively .", "label": "CompareOrContrast", "metadata": {}}
{"text": "3 The degree of precision of the measurement ( James et al. 1996 , Section 1.5 ) determines which objects can be described by the GRE algorithm , since it determines which objects count as having the same size .", "label": "Background", "metadata": {}}
{"text": "Table look-up using an explicit translation lexicon is sufficient and preferable for many multilingual NLP applications , including `` crummy '' MT on the World Wide Web ( Church & Hovy , 1993 ) , certain machine-assisted translation tools ( e.g. ( Macklovitch , 1994 ; Melamed , 1996b ) ) , concordancing for bilingual lexicography ( Catizone et al. , 1993 ; Gale & Church , 1991 ) , computerassisted language learning , corpus linguistics ( Melby .", "label": "Background", "metadata": {}}
{"text": "SWIZZLE is a multilingual enhancement of COCKTAIL ( Harabagiu and Maiorano , 1999 ) , a coreference resolution system that operates on a mixture of heuristics that combine semantic and textual cohesive information ' .", "label": "Extends", "metadata": {}}
{"text": "( Davis and Ogden , 1997 ; Ballesteros and Croft , 1997 ; Hull and ( 3refenstette , 1996 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "de URL : http://www.sfs.nphil.uni-tuebingen.de/sfb / b4home.html 1 This is , for example , the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement ( Hinrichs and Nakazawa 1989 ) that also use lexical rules such as the Complement Extraction Lexical Rule ( Pollard and Sag 1994 ) or the Complement Cliticization Lexical Rule ( Miller and Sag 1993 ) to operate on those raised elements .", "label": "Background", "metadata": {}}
{"text": "The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program ( Stabler , 1997 ; Harkema , 2000 ; Niyogi , 2001 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance ( Blume , 2005 ; Chen and Martin , 2007 ; Popescu and Magnini , 2007 ; Kalashnikov et al. , 2007 ) .", "label": "Background", "metadata": {}}
{"text": "Typical letter-to-sound rule sets are those described by Ainsworth ( 1973 ) , McIlroy ( 1973 ) , Elovitz et al. ( 1976 ) , Hurmicutt ( 1976 ) , and Divay and Vitale ( 1997 ) .", "label": "Background", "metadata": {}}
{"text": "Venables and Ripley ( 1994 ) describe an efficient algorithm ( of linear complexity in the number of training sentences ) for computing the LDA transform matrix , which entails computing the withinand between-covariance matrices of the classes , and using Singular Value Decomposition ( SVD ) to compute the eigenvectors of the new space .", "label": "Uses", "metadata": {}}
{"text": "Some examples include text categorization ( Lewis and Catlett 1994 ) , base noun phrase chunking ( Ngai and Yarowsky 2000 ) , part-of-speech tagging ( Engelson Dagan 1996 ) , spelling confusion set disambiguation ( Banko and Brill 2001 ) , and word sense disambiguation ( Fujii et al. 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Differently , Cohn and Blunsom ( 2009 ) designed a sampler to infer an STSG by fixing the tree structure and exploring the space of alignment .", "label": "Motivation", "metadata": {}}
{"text": "W. Labov ( 1973 ) discussed sentences of the form * This is a chair but you can sit on it .", "label": "Background", "metadata": {}}
{"text": "This imbalance foils thresholding strategies , clever as they might be ( Gale & Church , 1991 ; Wu & Xia , 1994 ; Chen , 1996 ) .", "label": "Background", "metadata": {}}
{"text": "The problem of handling ill-formed input has been studied by Carbonell and Hayes ( 1983 ) , Granger ( 1983 ) , Jensen et al. ( 1983 ) , Kwasny and Sondheimer ( 1981 ) , Riesbeck and Schank ( 1976 ) , Thompson ( 1980 ) , Weischedel and Black ( 1980 ) , and Weischedel and Sondheimer ( 1983 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp ( Kehoe and Renouf , 2002 ) , KWiCFinder ( Fletcher , 2004a ) and the Linguist 's Search Engine ( Kilgarriff , 2003 ; Resnik and Elkiss , 2003 ) .", "label": "Background", "metadata": {}}
{"text": "More recently , Silberer et al. ( 2013 ) show that visual attribute classifiers , which have been immensely successful in object recognition ( Farhadi et al. , 2009 ) , act as excellent substitutes for feature", "label": "Background", "metadata": {}}
{"text": "In other methods , lexical resources are specifically tailored to meet the requirements of the domain ( Rosario and Hearst , 2001 ) or the system ( Gomez , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Such systems extract information from some types of syntactic units ( clauses in ( Fillmore and Atkins , 1998 ; Gildea and Jurafsky , 2002 ; Hull and Gomez , 1996 ) ; noun phrases in ( Hull and Gomez , 1996 ; Rosario et al. , 2002 ) ) .", "label": "Background", "metadata": {}}
{"text": "As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .", "label": "Background", "metadata": {}}
{"text": "Klein and Manning ( 2002 ) 's CCM is an unlabeled bracketing model that generates the span of part-of-speech tags that make up each constituent and the pair of tags surrounding each constituent span ( as well as the spans and contexts of each non-constituent ) .", "label": "Background", "metadata": {}}
{"text": "Opposition ( called `` adversative '' or `` contrary-to-expectation '' by Halliday and Hasan 1976 ; cfXXX also Quirk et al. 1972 , p. 672 ) .", "label": "Background", "metadata": {}}
{"text": "Aside from the extraction of theory-neutral subcategorization lexicons , there has also been work in the automatic construction of lexical resources which comply with the principles of particular linguistic theories such as LTAG , CCG , and HPSG ( Chen and Vijay-Shanker 2000 ; Xia 1999 ; Hockenmaier , Bierner , and Baldridge 2004 ; Nakanishi , Miyao , and Tsujii 2004 ) .", "label": "Background", "metadata": {}}
{"text": "29 This improvement of the covariation encoding can also be viewed as an instance of the program transformation technique referred to as deletion of clauses with a finitely failed body ( Pettorossi and Proietti 1994 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The reordering models we describe follow our previous work using function word models for translation ( Setiawan et al. , 2007 ; Setiawan et al. , 2009 ) .", "label": "Extends", "metadata": {}}
{"text": "For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning ( Menezes & Richardson , 2001 ) , ( Aramaki et al. , 2001 ) , ( Watanabe et al. , 2000 ) , ( Meyers et al. , 2000 ) , ( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 ( Sato & Nagao , 1990 ) , ( Sato , 1991 ) , ( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 ) .", "label": "Background", "metadata": {}}
{"text": "In corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible ( Kennedy , 1998 : 56 ) unless the web is used as a corpus ( Kilgarriff and Grefenstette , 2003 ) .", "label": "Background", "metadata": {}}
{"text": "Figure 2 ( a ) shows the frame-based semantic representation for the utterance `` What time is Analyze This playing 2 See ( Nakatani and Chu-Carroll , 2000 ) for how MIMIC 's dialoguelevel knowledge is used to override default prosodic assignments for concept-to-speech generation .", "label": "Background", "metadata": {}}
{"text": "Instead , we will adopt the nomenclature of the Automatic Content Extraction program ( NIST , 2004 ) : we will call the instances of textual references to objects/abstractions mentions , which can be either named ( e.g. John Mayor ) , nominal ( the president ) or pronominal ( she , it ) .", "label": "Uses", "metadata": {}}
{"text": "Such a component would serve as the first stage of a clinical question answering system ( Demner-Fushman and Lin , 2005 ) or summarization system ( McKeown et al. , 2003 ) .", "label": "Future", "metadata": {}}
{"text": "In the areas of Natural Language Processing ( NLP ) and computational linguistics , proposals have been made for using the computational Grid for data-intensive NLP and text-mining for eScience ( Carroll et al. , 2005 ; Hughes et al , 2004 ) .", "label": "Background", "metadata": {}}
{"text": "Ingria ( 1984 ) comprehensively compares different approaches to complementation within grammatical theory providing a touchstone against which the LDOCE scheme can be evaluated .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Blunsom et al. ( 2008 , 2009 , 2010 ) utilized Bayesian methods to learn synchronous context free grammars ( SCFG ) from a parallel corpus .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Since the arguments can provide useful semantic information , the SRL is crucial to many natural language processing tasks , such as Question and Answering ( Narayanan and Harabagiu 2004 ) , Information Extraction ( Surdeanu et al. 2003 ) , and Machine Translation ( Boas 2002 ) .", "label": "Background", "metadata": {}}
{"text": "Another technique for making better use of unlabeled data is cotraining ( Blum and Mitchell 1998 ) , in which two sufficiently different learners help each other learn by labeling training data for one another .", "label": "Background", "metadata": {}}
{"text": "For example , modeling CASE in Czech improves Czech parsing ( Collins et al. 1999 ) : CASE is relevant , not redundant , and can be predicted with sufficient accuracy .", "label": "Motivation", "metadata": {}}
{"text": "Table look-up using an explicit translation lexicon is sufficient and preferable for many multilingual NLP applications , including `` crummy '' MT on the World Wide Web ( Church & Hovy , 1993 ) , certain machine-assisted translation tools ( e.g. ( Macklovitch , 1994 ; Melamed , 1996b ) ) , concordancing for bilingual lexicography ( Catizone et al. , 1993 ; Gale & Church , 1991 ) , computerassisted language learning , corpus linguistics ( Melby .", "label": "Background", "metadata": {}}
{"text": "There has been some controversy , at least for simple stemmers ( Lovins , 1968 ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval ( Harman , 1991 ; Krovetz , 1993 ; Hull , 1996 ) .", "label": "Background", "metadata": {}}
{"text": "This situation suggests a response-automation approach that follows the document retrieval paradigm ( Salton and McGill 1983 ) , where a new request is matched with existing response documents ( e-mails ) .", "label": "Background", "metadata": {}}
{"text": "This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) ( Vijay-Shanker , 1987 ; Vijay-Shanker and Joshi , 1988 ) and Head-Driven Phrase Structure Grammar ( HPSG ) ( Pollard and Sag , 1994 ) by a method of grammar conversion .", "label": "Background", "metadata": {}}
{"text": "Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp ( Kehoe and Renouf , 2002 ) , KWiCFinder ( Fletcher , 2004a ) and the Linguist 's Search Engine ( Kilgarriff , 2003 ; Resnik and Elkiss , 2003 ) .", "label": "Background", "metadata": {}}
{"text": "Table look-up using an explicit translation lexicon is sufficient and preferable for many multilingual NLP applications , including `` crummy '' MT on the World Wide Web ( Church & Hovy , 1993 ) , certain machine-assisted translation tools ( e.g. ( Macklovitch , 1994 ; Melamed , 1996b ) ) , concordancing for bilingual lexicography ( Catizone et al. , 1993 ; Gale & Church , 1991 ) , computerassisted language learning , corpus linguistics ( Melby .", "label": "Background", "metadata": {}}
{"text": "Some efforts have tackled tasks such as automatic image caption generation ( Feng and Lapata , 2010a ; Ordonez et al. , 2011 ) , text illustration ( Joshi et al. , 2006 ) , or automatic location identification of Twitter users ( Eisenstein et al. , 2010 ; Wing and Baldridge , 2011 ; Roller et al. , 2012 ) .", "label": "Background", "metadata": {}}
{"text": "The system was trained on the Penn Treebank ( Marcus et al. , 1993 ) WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by Magerman ( 1995 ) , Collins ( 1997 ) , and Ratnaparkhi ( 1997 ) , and became a common testbed .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Briscoe and Carroll ( 1997 ) predefine 163 verbal subcategorization frames , obtained by manually merging the classes exemplified in the COMLEX ( MacLeod , Grishman , and Meyers 1994 ) and ANLT ( Boguraev et al. 1987 ) dictionaries and adding around 30 frames found by manual inspection .", "label": "Background", "metadata": {}}
{"text": "Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed ( Neville and Jensen , 2000 ; Lafferty et al. , 2001 ; Getoor et al. , 2002 ; Taskar et al. , 2002 ; Taskar et al. , 2003 ; Taskar et al. , 2004 ; McCallum and Wellner , 2004 ) .", "label": "Background", "metadata": {}}
{"text": "Berstel and Reutenauer ( 1988 ) give a sufficiently general finite-state framework to allow this : weights may fall in any set K ( instead of R ) .", "label": "Uses", "metadata": {}}
{"text": "There are several variations of such a method ( Ballesteros and Croft , 1998 ; Pirkola , 1998 ; Hull 1997 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "12 In order to focus on the computational aspects of the covariation approach , in this paper we will not go into a discussion of the full lexical rule specification language introduced in Meurers ( 1995 ) .", "label": "Background", "metadata": {}}
{"text": "This Principle of Finitism is also assumed by Johnson-Laird ( 1983 ) , Jackendoff ( 1983 ) , Kamp ( 1981 ) , and implicitly or explicitly by almost all researchers in computational linguistics .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In this paper , a flexible annotation schema called Structured String-Tree Correspondence ( SSTC ) ( Boitet & Zaharin , 1988 ) will be introduced to capture a natural language text , its corresponding abstract linguistic representation and the mapping ( correspondence ) between these two .", "label": "Background", "metadata": {}}
{"text": "More sophisticated approaches have been proposed ( Hillard et al. , 2003 ) , including an extension that , in an interesting reversal of our problem , makes use of sentimentpolarity indicators within speech segments ( Galley et al. , 2004 ) .", "label": "Background", "metadata": {}}
{"text": "The one-sided t-test ( Hull , 1993 ) at significance level 0.05 indicated that the improvement on Trec5C is not statistically significant .", "label": "Uses", "metadata": {}}
{"text": "It is therefore no surprise that early attempts at response automation were knowledge-driven ( Barr and Tessler 1995 ; Watson 1997 ; Delic and Lahaix 1998 ) .", "label": "Background", "metadata": {}}
{"text": "The framework was originally developed for the realization of deep-syntactic structures in NLG ( Lavoie and Rambow , 1997 ) .", "label": "Background", "metadata": {}}
{"text": "Few approaches to parsing have tried to handle disfluent utterances ( notable exceptions are Core & Schubert , 1999 ; Hindle , 1983 ; Nakatani & Hirschberg , 1994 ; Shriberg , Bear , & Dowding , 1992 ) .", "label": "Background", "metadata": {}}
{"text": "There have been several efforts aimed at developing a domain-independent method for generating responses from a frame representation of user requests ( Bobrow et al. , 1977 ; Chu-Carroll , 1999 ) .", "label": "Future", "metadata": {}}
{"text": "Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) [ 18 ] , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase [ 22 ] , Human Nomenclature Database ( HUGO ) [ 23 ] , Online Mendelian Inheritance in Man ( OMIM ) [ 24 ] , and Enzyme Nomenclature Database ( ECNUM ) [ 25 , 26 ] .", "label": "Uses", "metadata": {}}
{"text": "We then use the program Snob ( Wallace and Boulton 1968 ; Wallace 2005 ) to cluster these experiences .", "label": "Uses", "metadata": {}}
{"text": "Our implementation of the NP-based QA system uses the Empire noun phrase finder , which is described in detail in Cardie and Pierce ( 1998 ) .", "label": "Uses", "metadata": {}}
{"text": "In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement ( Galley et al. , 2004 ; Misra and Walker , 2013 ) .", "label": "Motivation", "metadata": {}}
{"text": "Specifically , we examine the strength of association between the verb and the noun constituent of a combination ( the target expression or its lexical variants ) as an indirect cue to its idiomaticity , an approach inspired by Lin ( 1999 ) .", "label": "Motivation", "metadata": {}}
{"text": "The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in Minsky and Papert ( 1969 ) , assertional statements as in Michalski ( 1980 ) , or semantic nets as in Winston ( 1975 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Lin ( 1998 ) for example discusses a method where a syntactic parse of the text is performed and the context of a word is modeled using dependency triples .", "label": "Background", "metadata": {}}
{"text": "The strategies employed when MIMIC has only dialogue initiative are similar to the mixed initiative dialogue strategies employed by many existing spoken dialogue systems ( e.g. , ( Bennacef et at. , 1996 ; Stent et al. , 1999 ) ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "7A11 our results are computed with the evalb program following the now-standard criteria in ( Collins , 1999 ) .", "label": "Uses", "metadata": {}}
{"text": "Also relevant is work on the general problems of dialog-act tagging ( Stolcke et al. , 2000 ) , citation analysis ( Lehnert et al. , 1990 ) , and computational rhetorical analysis ( Marcu , 2000 ; Teufel and Moens , 2002 ) .", "label": "Background", "metadata": {}}
{"text": "For projective parsing , it is significantly faster than exact dynamic programming , at the cost of small amounts of search error , We are interested in extending these ideas to phrase-structure and lattice parsing , and in trying other higher-order features , such as those used in parse reranking ( Charniak and Johnson , 2005 ; Huang , 2008 ) and history-based parsing ( Nivre and McDonald , 2008 ) .", "label": "Future", "metadata": {}}
{"text": "Word alignments are used primarily for extracting minimal translation units for machine translation ( MT ) ( e.g. , phrases [ Koehn , Och , and Marcu 2003 ] and rules [ Galley et al. 2004 ; Chiang et al. 2005 ] ) as well as for", "label": "Background", "metadata": {}}
{"text": "We have also applied our more general unification grammar acquisition methodology to the TIGER Treebank ( Brants et al. 2002 ) and Penn Chinese Treebank ( Xue , Chiou , and Palmer 2002 ) , extracting wide-coverage , probabilistic LFG grammar", "label": "Uses", "metadata": {}}
{"text": "We use the structures previously used by Nguyen et al. ( 2009 ) , and propose one new structure .", "label": "Uses", "metadata": {}}
{"text": "Towards this aim , a flexible annotation structure called Structured String-Tree Correspondence ( SSTC ) was introduced in Boitet & Zaharin ( 1988 ) to record the string of terms , its associated representation structure and the mapping between the two , which is expressed by the sub-correspondences recorded as part of a SSTC .", "label": "Background", "metadata": {}}
{"text": "In this paper , I present a computational implementation of Distributed Morphology ( Halle and Marantz , 1993 ) , a non-lexicalist linguistic theory that erases the distinction between syntactic derivation and morphological derivation .", "label": "Uses", "metadata": {}}
{"text": "Some recent GRE algorithms have done away with the separation between content determination and linguistic realization , interleaving the two processes instead ( Stone and Webber 1998 ; Krahmer and Theune 2002 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "This is implemented as a cascade of simple strategies , which were briefly described in Mikheev ( 1999 ) .", "label": "Uses", "metadata": {}}
{"text": "Better results would be expected by combining the PCFG-LA parser with discriminative reranking approaches ( Charniak and Johnson , 2005 ; Huang , 2008 ) for self training .", "label": "Future", "metadata": {}}
{"text": "Morphological alterations of a search term have a negative impact on the recall performance of an information retrieval ( IR ) system ( Choueka , 1990 ; J \u00c2\u00a8 appinen and Niemist \u00c2\u00a8 o , 1988 ; Kraaij and Pohlmann , 1996 ) , since they preclude a direct match between the search term proper and its morphological variants in the documents to be retrieved .", "label": "Background", "metadata": {}}
{"text": "ment ( Sarkar and Wintner , 1999 ; Doran et al. , 2000 ; Makino et al. , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Finally , feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication ( Fujie et al. , 2004 ; Morency et al. , 2005 ; Morency et al. , 2007 ; Morency et al. , 2009 ) .", "label": "Background", "metadata": {}}
{"text": "Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information ( Andrews et al. , 2009 ; Steyvers , 2010 ; Feng and Lapata , 2010b ; Bruni et al. , 2011 ; Silberer and Lapata , 2012 ; Johns and Jones , 2012 ; Bruni et al. , 2012a ; Bruni et al. , 2012b ; Silberer et al. , 2013 ) .", "label": "Background", "metadata": {}}
{"text": "We also made use of the person-name/instance pairs automatically extracted by Fleischman et al. ( 2003 ) .2 This data provides counts for pairs such as `` Edwin Moses , hurdler '' and `` William Farley , industrialist . ''", "label": "Uses", "metadata": {}}
{"text": "Al-Adhaileh and Tang ( 2001 ) presented an approach for constructing a BKB based on the S-SSTC .", "label": "Background", "metadata": {}}
{"text": "However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time ( Charniak , 1997b ; Charniak , 1997a ; Collins , 1997 ; Ratnaparkhi , 1997 ) .", "label": "Background", "metadata": {}}
{"text": "Also , advanced methods often require many training iterations , for example active learning ( Dagan and Engelson ,1995 ) and co-training ( Blum and Mitchell , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Andrews et al. ( 2009 ) furthered this work by showing that a bimodal topic model , consisting of both text and feature norms , outperformed models using only one modality on the prediction of association norms , word substitution errors , and semantic interference tasks .", "label": "Extends", "metadata": {}}
{"text": "Shortly after the publication of The Sound Pattern of English ( Chomsky and Halle 1968 ) , Kornai points out , `` Johnson ( 1970 ) demonstrated that the context-sensitive machinery of SPE ... [ could ] be replaced by a much simpler one , based on finite-state transducers ( FSTs ) ; the same conclusion was reached independently by Kaplan and Kay , whose work remained an underground classic until it was finally published in Kaplan and Kay ( 1994 ) . ''", "label": "Background", "metadata": {}}
{"text": "18 In this article , we use a newer version of the corpus by Alkuhlani and Habash ( 2011 ) than the one we used in Marton , Habash , and Rambow ( 2011 ) .", "label": "Uses", "metadata": {}}
{"text": "Atallah et al. ( 2001b ) and Topkara et al. ( 2006a ) attained the embedding capacity of 0.5 bits per sentence with the syntactic transformation method .", "label": "Background", "metadata": {}}
{"text": "Another possibility that often works better is to use Minimum Bayes-Risk ( MBR ) decoding ( Kumar and Byrne 2002 ; Liang , Taskar , and Klein 2006 ; Ganchev , and Taskar 2007 ) .", "label": "Uses", "metadata": {}}
{"text": "This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) ( Vijay-Shanker , 1987 ; Vijay-Shanker and Joshi , 1988 ) and Head-Driven Phrase Structure Grammar ( HPSG ) ( Pollard and Sag , 1994 ) by a method of grammar conversion .", "label": "Background", "metadata": {}}
{"text": "We use the same set of binary features as in previous work on this dataset ( Pang et al. , 2002 ; Pang and Lee , 2004 ; Zaidan et al. , 2007 ) .", "label": "Uses", "metadata": {}}
{"text": "\u00e2\u0080\u00a2 Learnability ( Zernik and Dyer 1987 ) \u00e2\u0080\u00a2 Text generation ( Hovy 1988 ; Milosavljevic , Tulloch , and Dale 1996 ) \u00e2\u0080\u00a2 Speech generation ( Rayner and Carter 1997 ) \u00e2\u0080\u00a2 Localization ( Sch \u00c2\u00a8 aler 1996 )", "label": "Background", "metadata": {}}
{"text": "For example , a ` web page ' is more similar to an infinite canvas than a written page ( McCloud , 2001 ) .", "label": "Background", "metadata": {}}
{"text": "This approach resembles the work by Grishman et al. ( 1986 ) and Hirschman et al. ( 1975 ) on selectional restrictions .", "label": "CompareOrContrast", "metadata": {}}
{"text": "This is noticeable for German ( Brants et al. , 2002 ) and Portuguese ( Afonso et al. , 2002 ) , which still have high overall accuracy thanks to very high attachment scores , but much more conspicuous for Czech ( B \u00c2\u00a8 ohmov \u00c2\u00b4 a et al. , 2003 ) , Dutch ( van der Beek et al. , 2002 ) and Slovene ( D\u00cb\u0087zeroski et al. , 2006 ) , where root precision drops more drastically to about 69 % , 71 % and 41 % , respectively , and root recall is also affected negatively .", "label": "CompareOrContrast", "metadata": {}}
{"text": "LTAG ( Schabes et al. , 1988 ) is a grammar formalism that provides syntactic analyses for a sentence by composing elementary trees with two opera -", "label": "Background", "metadata": {}}
{"text": "Translations have been generated by the CrowdFlower3 channel to Amazon Mechanical Turk4 ( MTurk ) , adopting the methodology proposed by ( Negri and Mehdad , 2010 ) .", "label": "Uses", "metadata": {}}
{"text": "This work is a continuation of that initiated in ( Yahyaoui , 2001 ) , which reports an overall NB classification correctness of 75.6 % , in cross validation experiments , on a data set that consists of 100 documents for each of 12 categories ( the data set is collected from different Arabic portals ) .", "label": "Extends", "metadata": {}}
{"text": "We used a standard implementation of IBM Model 4 ( Och and Ney 2003 ) and because changing the existing code is not trivial , we could not use the same stopping criterion to avoid overfitting and we are not able to produce precision/recall curves .", "label": "Uses", "metadata": {}}
{"text": "Some approaches apply semantic parsing , where words and sentences are mapped to logical structure meaning ( Kate and Mooney , 2007 ) .", "label": "Background", "metadata": {}}
{"text": "For projective parsing , it is significantly faster than exact dynamic programming , at the cost of small amounts of search error , We are interested in extending these ideas to phrase-structure and lattice parsing , and in trying other higher-order features , such as those used in parse reranking ( Charniak and Johnson , 2005 ; Huang , 2008 ) and history-based parsing ( Nivre and McDonald , 2008 ) .", "label": "Future", "metadata": {}}
{"text": "Prototypes of Internet search engines for linguists , corpus linguists and lexicographers have been proposed : WebCorp ( Kehoe and Renouf , 2002 ) , KWiCFinder ( Fletcher , 2004a ) and the Linguist 's Search Engine ( Kilgarriff , 2003 ; Resnik and Elkiss , 2003 ) .", "label": "Background", "metadata": {}}
{"text": "Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) [ 18 ] , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase [ 22 ] , Human Nomenclature Database ( HUGO ) [ 23 ] , Online Mendelian Inheritance in Man ( OMIM ) [ 24 ] , and Enzyme Nomenclature Database ( ECNUM ) [ 25 , 26 ] .", "label": "Uses", "metadata": {}}
{"text": "Other factors , such as the role of focus ( Grosz 1977 , 1978 ; Sidner 1983 ) or quantifier scoping ( Webber 1983 ) must play a role , too .", "label": "Background", "metadata": {}}
{"text": "Since mid-2002 , the Library has been employing software that automatically suggests MeSH headings based on content ( Aronson et al. 2004 ) .", "label": "Background", "metadata": {}}
{"text": "Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , ( Joachims , 1998 ; Ng and Jordan , 2001 ) .", "label": "Background", "metadata": {}}
{"text": "Also , the Keller and Lapata ( 2003 ) approach will be undefined if the pair is unobserved on the web .", "label": "Uses", "metadata": {}}
{"text": "Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts ( Baker et al. , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "or quotation of messages in emails or postings ( see Mullen and Malouf ( 2006 ) but cfXXX Agrawal et al. ( 2003 ) ) .", "label": "Background", "metadata": {}}
{"text": "Andrews et al. ( 2009 ) extend LDA to allow for the inference of document and topic distributions in a multimodal corpus .", "label": "Background", "metadata": {}}
{"text": "SNoW ( Carleson et al. , 1999 ; Roth , 1998 ) is a multi-class classifier that is specifically tailored for learning in domains in which the potential number of information sources ( features ) taking part in decisions is very large , of which NLP is a principal example .", "label": "Uses", "metadata": {}}
{"text": "The search algorithm is the standard Viterbi search ( Viterbi 1967 ) , except that the match involves a network-to-network alignment problem rather than sequence-to-sequence .", "label": "Uses", "metadata": {}}
{"text": "Since then this idea has been applied to several tasks , including word sense disambiguation ( Yarowsky 1995 ) and named-entity recognition ( Cucerzan and Yarowsky 1999 ) .", "label": "Background", "metadata": {}}
{"text": "7 We employed the LIBSVM package ( Chang and Lin 2001 ) .", "label": "Uses", "metadata": {}}
{"text": "coreference performance on perfect mentions ( e.g. , Incorporate the two knowledge sources in a Luo et al. ( 2004 ) ) ; and for those that do report percoreference resolver .", "label": "CompareOrContrast", "metadata": {}}
{"text": "According to Hobbs ( 1979 , p. 67 ) , these two sentences are incoherent .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers ( Collins , 1997 ; Charniak , 1997a ; Charniak , 1997b ; Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 ) .", "label": "Background", "metadata": {}}
{"text": "1Our rules are similar to those from Xu et al. ( 2009 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In psycholinguistics , relatedness of words can also be determined through association tests ( Schulte im Walde and Melinger , 2005 ) .", "label": "Background", "metadata": {}}
{"text": "In this article , we use an in-house system which provides functional gender , number , and rationality features ( Alkuhlani and Habash 2012 ) .", "label": "Uses", "metadata": {}}
{"text": "The use of the web as a corpus for teaching and research on language has been proposed a number of times ( Kilgarriff , 2001 ; Robb , 2003 ; Rundell , 2000 ; Fletcher , 2001 , 2004b ) and received a special issue of the journal Computational Linguistics ( Kilgarriff and Grefenstette , 2003 ) .", "label": "Background", "metadata": {}}
{"text": "Our method resorts to some translation examples , which is similar as example-based translation or translation memory ( Watanabe and Sumita , 2003 ; He et al. , 2010 ; Ma et al. , 2011 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Baseline Systems We choose three publicly available state-of-the-art end-to-end coreference systems as our baselines : Stanford system ( Lee et al. , 2011 ) , Berkeley system ( Durrett and Klein , 2014 ) and HOTCoref system ( Bj \u00c2\u00a8 orkelund and Kuhn , 2014 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , Erman et al. 1980 , Haton and Pierrel 1976 , Lea 1980 , Lowerre and Reddy 1980 , Medress 1980 , Reddy 1976 , Walker 1978 , and Wolf and Woods 1980 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .", "label": "Background", "metadata": {}}
{"text": "Other representations use the link structure ( Malin , 2005 ) or generate graph representations of the extracted features ( Kalashnikov et al. , 2007 ) .", "label": "Background", "metadata": {}}
{"text": "There has been some controversy , at least for simple stemmers ( Lovins , 1968 ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval ( Harman , 1991 ; Krovetz , 1993 ; Hull , 1996 ) .", "label": "Background", "metadata": {}}
{"text": "This revalidates the observation of Nguyen et al. ( 2009 ) that phrase structure representations and dependency representations add complimentary value to the learning task .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The semantic categories of verbs and other words are extracted from the Semantic Knowledge-base of Contemporary Chinese ( Wang et al. 2003 ) .", "label": "Uses", "metadata": {}}
{"text": "6 The Partial-VP Topicalization Lexical Rule proposed by Hinrichs and Nakazawa ( 1994 , 10 ) is a linguistic example .", "label": "Background", "metadata": {}}
{"text": "We measure the inter annotator agreement using the Fleiss Kappa ( Fleiss et al. , 1981 ) measure ( x ) where the agreement lies around 0.79 .", "label": "Uses", "metadata": {}}
{"text": "The task we used to compare different generalisation techniques is similar to that used by Pereira et al. ( 1993 ) and Rooth et al. ( 1999 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "It is not aimed at handling dependencies , which require heavy use of lexical information ( Hindle and Rooth , 1993 , for PP attachment ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "This includes work on question answering ( Wang et al. , 2007 ) , sentiment analysis ( Nakagawa et al. , 2010 ) , MT reordering ( Xu et al. , 2009 ) , and many other tasks .", "label": "Background", "metadata": {}}
{"text": "I A more detailed discussion of various aspects of the proposed parser can be found in ( Minnen , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Our experimental design with professional bilingual translators follows our previous work Green et al. ( 2013a ) comparing scratch translation to post-edit .", "label": "Extends", "metadata": {}}
{"text": "Lexical functional grammar ( Kaplan and Bresnan 1982 ; Bresnan 2001 ; Dalrymple 2001 ) is a member of the family of constraint-based grammars .", "label": "Background", "metadata": {}}
{"text": "Thus , the second class of SBD systems employs machine learning techniques such as decision tree classifiers ( Riley 1989 ) , neural networks ( Palmer and Hearst 1994 ) , and maximum-entropy modeling ( Reynar and Ratnaparkhi 1997 ) .", "label": "Background", "metadata": {}}
{"text": "The third approach to cross-lingual retrieval is to map queries and documents to some intermediate representation , e.g latent semantic indexing ( LSI ) ( Littman et al , 1998 ) , or the General Vector space model ( GVSM ) , ( Carbonell et al , 1997 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Many provide graphical user interfaces ( GUI ) for manual annotation ( e.g. General Architecture for Text Engineering ( GATE ) ( Cunningham et al. , 1997 ) and the Alembic Workbench ( Day et al. , 1997 ) ) as well as NLP tools and resources that can be manipulated from the GUI .", "label": "Background", "metadata": {}}
{"text": "The keypoints are clustered into 5,000 visual codewords ( centroids ) using k-means clustering ( Sculley , 2010 ) , and images are then quantized over the 5,000 codewords .", "label": "Uses", "metadata": {}}
{"text": "Another approach for partial parsing was presented by Skut and Brants ( 1998 ) .", "label": "Background", "metadata": {}}
{"text": "In knowledge-lean approaches , coreference resolvers employ only morpho-syntactic cues as knowledge sources in the resolution process ( e.g. , Mitkov ( 1998 ) , Tetreault ( 2001 ) ) .", "label": "Background", "metadata": {}}
{"text": "The application of domain models and deep semantic knowledge to question answering has been explored by a variety of researchers ( e.g. , Jacquemart and Zweigenbaum 2003 , Rinaldi et al. 2004 ) , and was also the focus of recent workshops on question answering in restricted domains at ACL 2004 and AAAI 2005 .", "label": "Background", "metadata": {}}
{"text": "This result is consistent with other works using this model with these features ( Andrews et al. , 2009 ; Silberer and Lapata , 2012 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The feature of head word trigger which we apply to the log-linear model is motivated by the trigger-based approach ( Hasan and Ney , 2009 ) .", "label": "Motivation", "metadata": {}}
{"text": "Other work on modeling the meanings of verbs using video recognition has also begun showing great promise ( Mathe et al. , 2008 ; Regneri et al. , 2013 ) .", "label": "Background", "metadata": {}}
{"text": "No attempt has been made to map any closed class entries from LDOCE , as a 3,000 word lexicon containing most closed class items has been developed independently by one of the groups collaborating with us to develop the general purpose morphological and syntactic analyser ( see the Introduction and Russell et al. , 1986 ) .", "label": "Background", "metadata": {}}
{"text": "We see no good reason , however , why such text spans should necessarily be sentences , since the majority of tagging paradigms ( e.g. , Hidden Markov Model [ HMM ] [ Kupiec 1992 ] , Brill 's [ Brill 1995a ] , and MaxEnt [ Ratnaparkhi 1996 ] ) do not attempt to parse an entire sentence and operate only in the local window of two to three tokens .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In future work we plan to experiment with richer representations , e.g. including long-range n-grams ( Rosenfeld , 1996 ) , class n-grams ( Brown et al. , 1992 ) , grammatical features ( Amaya and Benedy , 2001 ) , etc ' .", "label": "Future", "metadata": {}}
{"text": "Furthermore , we demonstrate that our results carry over successfully to another parser , the Easy-First Parser ( Goldberg and Elhadad 2010 ) ( Section 6 ) .", "label": "Uses", "metadata": {}}
{"text": "We follow our previous work ( Dickinson et al. , 2010 ) in our feature choices , using a fiveword window that includes the target stem and two words on either side for context ( see also Tetreault and Chodorow , 2008 ) .", "label": "Extends", "metadata": {}}
{"text": "Adjectives , more than other categories , are a striking example of regular polysemy since they are able to take on different meanings depending on their context , viz. , the noun or noun class they modify ( see Pustejovsky ( 1995 ) and the references therein ) .", "label": "Background", "metadata": {}}
{"text": "According to Dalrymple ( 2001 ) , LFG assumes the following universally available inventory of grammatical functions : SUBJ ( ect ) , OBJ ( ect ) , OBJe , COMP , XCOMP , OBL ( ique ) e , ADJ ( unct ) , XADJ .", "label": "Background", "metadata": {}}
{"text": "But their importance has grown far beyond machine translation : for instance , transferring annotations between languages ( Yarowsky and Ngai 2001 ; Hwa et al. 2005 ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay 2008 ) .", "label": "Motivation", "metadata": {}}
{"text": "4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and King 1994 ; Gerdemann 1995 ) .", "label": "Background", "metadata": {}}
{"text": "Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models ( Erk , 2007 ; Keller and Lapata , 2003 ; Rooth et al. , 1999 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "There have already been several attempts to develop distributed NLP systems for dialogue systems ( Bayer et al. , 2001 ) and speech recognition ( Hacioglu and Pellom , 2003 ) .", "label": "Background", "metadata": {}}
{"text": "For instance , implementing an efficient version of the MXPOST POS tagger ( Ratnaparkhi , 1996 ) will simply involve composing and configuring the appropriate text file reading component , with the sequential tagging component , the collection of feature extraction components and the maximum entropy model component .", "label": "Future", "metadata": {}}
{"text": "cue word and name the first ( or several ) associated words that come to mind ( e.g. , Nelson et al. ( 2004 ) ) , and feature norms , where subjects are given a cue word and asked to describe typical properties of the cue concept ( e.g. , McRae et al. ( 2005 ) ) .", "label": "Background", "metadata": {}}
{"text": "Hirschberg and Litman ( 1987 ) and Litman and Hirschberg ( 1990 ) also examine the relation between discourse and prosodic phrasing .", "label": "Background", "metadata": {}}
{"text": "Sarkar and Zeman ( 2000 ) evaluate 914 Czech verbs against a custom-made gold standard and record a token recall of 88 % .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The automation of help-desk responses has been previously tackled using mainly knowledge-intensive paradigms , such as expert systems ( Barr and Tessler 1995 ) and case-based reasoning ( Watson 1997 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Xue and Palmer ( 2004 ) did very encouraging work on the feature calibration of semantic role labeling .", "label": "Background", "metadata": {}}
{"text": "This approach , which uses words that appear in the context of terms to formulate hypotheses on their semantic relatedness ( Habert et al. , 1996 , for example ) , does not specify the relationship itself .", "label": "Background", "metadata": {}}
{"text": "And ( Glickman and Dagan , 2003 ) use clustering and similarity measures to identify similar contexts in a single corpus and extract verbal paraphrases from these contexts .", "label": "Background", "metadata": {}}
{"text": "There has also been work focused upon determining the political leaning ( e.g. , `` liberal '' vs. `` conservative '' ) of a document or author , where most previously-proposed methods make no direct use of relationships between the documents to be classified ( the `` unlabeled '' texts ) ( Laver et al. , 2003 ; Efron , 2004 ; Mullen and Malouf , 2006 ) .", "label": "Background", "metadata": {}}
{"text": "To sum up , this work has been carried out to automatically classify Arabic documents using the NB algorithm , with the use of a different data set , a different number of categories , and a different root extraction algorithm from those used in ( Yahyaoui , 2001 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Our work builds on earlier research on learning to identify dialogues in which the user experienced poor speech recognizer performance ( Litman et al. , 1999 ) .", "label": "Extends", "metadata": {}}
{"text": "More recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms : Daille ( 2003 ) uses derivational morphology ; Grabar and Zweigenbaum ( 2002 ) use , as a starting point , a number of identical characters .", "label": "Background", "metadata": {}}
{"text": "Narrative writings or essays are creative works and they generally treat ownership as authorship , even for the most enthusiastic fellows of free culture ( Stallman , 2001 ) .", "label": "Background", "metadata": {}}
{"text": "McDonald has even argued for extending the model to a large number of components ( McDonald 1988 ) , and several systems have indeed added an additional component between the planner and the linguistic component ( Meteer 1994 ; Panaget 1994 ; Wanner 1994 ) .", "label": "Background", "metadata": {}}
{"text": "According to current tagger comparisons ( van Halteren et al. , 1998 ; Zavrel and Daelemans , 1999 ) , and according to a comparsion of the results presented here with those in ( Ratnaparkhi , 1996 ) , the Maximum Entropy framework seems to be the only other approach yielding comparable results to the one presented here .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The first lexical substitution method was proposed by Chapman and Davida ( 1997 ) .", "label": "Background", "metadata": {}}
{"text": "This can be a hazardous affair , since vague expressions tend to be interpreted in different ways by different people ( Toogood 1980 ) , sometimes in stark contrast with the intention of the speaker/writer ( Berry , Knapp , and Raynor 2002 ) .", "label": "Background", "metadata": {}}
{"text": "Hermann and Deutsch ( 1976 ; also reported in Levelt 1989 ) show that greater differences are most likely to be chosen , presumably because they are more striking .", "label": "Background", "metadata": {}}
{"text": "Other psycholing-uistic studies that confirm the validity of paragraph units can be found in Black and Bower ( 1979 ) and Haberlandt et al. ( 1980 ) .", "label": "Background", "metadata": {}}
{"text": "This contrasts with one of the traditional approaches ( e.g. , Dorr 1994 ; Watanabe 1995 ) to posing the translation problem , i.e. , the approach in which translation problems are seen in terms of bridging the gap between the most natural monolingual representations underlying the sentences of each language .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers ( Collins , 1997 ; Charniak , 1997a ; Charniak , 1997b ; Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 ) .", "label": "Background", "metadata": {}}
{"text": "While IA is generally thought to be consistent with findings on human language production ( Hermann and Deutsch 1976 ; Levelt 1989 ; Pechmann 1989 ; Sonnenschein 1982 ) , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it operates .", "label": "Background", "metadata": {}}
{"text": "It helps them build complex knowledge bases by combining components : events , entities and modifiers ( Clark and Porter , 1997 ) .", "label": "Background", "metadata": {}}
{"text": "Word frequency counts in internet search engines are inconsistent and unreliable ( Veronis , 2005 ) .", "label": "Background", "metadata": {}}
{"text": "Other milestones of recent research include the deployment of probabilistic and machine learning techniques ( Aone and Bennett 1995 ; Kehler 1997 ; Ge , Hale , and Charniak 1998 ; Cardie and Wagstaff 1999 ; the continuing interest in centering , used either in original or in revised form ( Abracos and Lopes 1994 ; Strube and Hahn 1996 ; Hahn and Strube 1997 ; Tetreault 1999 ) ; and proposals related to the evaluation methodology in anaphora resolution ( Mitkov 1998a , 2001b ) .", "label": "Background", "metadata": {}}
{"text": "Actually , if we use LSH technique ( Andoni and Indyk , 2008 ) in retrieval process , the local method can be easily scaled to a larger training data .", "label": "Future", "metadata": {}}
{"text": "Agreement between two annotation sets is calculated here in terms of Cohen 's kappa ( Cohen , 1960 ) 1 and corrected kappa ( Brennan and Prediger , 1981 ) 2 .", "label": "Uses", "metadata": {}}
{"text": "The implementation has been inspired by experience in extracting information from very large corpora ( Curran and Moens , 2002 ) and performing experiments on maximum entropy sequence tagging ( Curran and Clark , 2003 ; Clark et al. , 2003 ) .", "label": "Motivation", "metadata": {}}
{"text": "Some efforts have tackled tasks such as automatic image caption generation ( Feng and Lapata , 2010a ; Ordonez et al. , 2011 ) , text illustration ( Joshi et al. , 2006 ) , or automatic location identification of Twitter users ( Eisenstein et al. , 2010 ; Wing and Baldridge , 2011 ; Roller et al. , 2012 ) .", "label": "Background", "metadata": {}}
{"text": "These types of features result in an improvement in both the mention detection and coreference resolution performance , as shown through experiments on the ACE 2004 Arabic data .", "label": "Uses", "metadata": {}}
{"text": "14We parse each sentence with the Collins parser ( Collins , 1999 ) .", "label": "Uses", "metadata": {}}
{"text": "Encouraged by the success of chunk-based verb reordering lattices on ArabicEnglish ( Bisazza and Federico , 2010 ) , we tried to adapt the same approach to the German-English language pair .", "label": "Motivation", "metadata": {}}
{"text": "In our experiments , we employed the well-known classifier SVM `` ght to obtain individual-document classification scores , treating Y as the positive class and using plain unigrams as features .5 Following standard practice in sentiment analysis ( Pang et al. , 2002 ) , the input to SVM `` ght consisted of normalized presence-of-feature ( rather than frequency-of-feature ) vectors .", "label": "Uses", "metadata": {}}
{"text": "The problem of handling ill-formed input has been studied by Carbonell and Hayes ( 1983 ) , Granger ( 1983 ) , Jensen et al. ( 1983 ) , Kwasny and Sondheimer ( 1981 ) , Riesbeck and Schank ( 1976 ) , Thompson ( 1980 ) , Weischedel and Black ( 1980 ) , and Weischedel and Sondheimer ( 1983 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "After the PropBank ( Xue and Palmer 2003 ) was built , Xue and Palmer ( 2005 ) and Xue ( 2008 ) have produced more complete and systematic research on Chinese SRL .", "label": "Background", "metadata": {}}
{"text": "In order to estimate the parameters of our model , we develop a blocked sampler based on that of Johnson et al. ( 2007 ) to sample parse trees for sentences in the raw training corpus according to their posterior probabilities .", "label": "Uses", "metadata": {}}
{"text": "Many other such cases are described in Danlos 's book ( Danlos 1987 ) .", "label": "Background", "metadata": {}}
{"text": "\u00e2\u0080\u00a2 Before indexing the text , we process it with Textract ( Byrd and Ravin , 1998 ; Wacholder et al. , 1997 ) , which performs lemmatization , and discovers proper names and technical terms .", "label": "Uses", "metadata": {}}
{"text": "Therefore , we repeated the experiments with POS tags predicted by the MADA toolkit ( Habash and Rambow 2005 ; Habash , Rambow , and Roth 2012 ) 15 ( see Table 2 , 14 Some parsers predict POS tags internally , instead of receiving them as input , but this is not the case in this article .", "label": "Uses", "metadata": {}}
{"text": "Experiments on Chinese SRL ( Xue and Palmer 2005 , Xue 2008 ) reassured these findings .", "label": "Motivation", "metadata": {}}
{"text": "An example of this is the estimation of maximum entropy models , from simple iterative estimation algorithms used by Ratnaparkhi ( 1998 ) that converge very slowly , to complex techniques from the optimisation literature that converge much more rapidly ( Malouf , 2002 ) .", "label": "Background", "metadata": {}}
{"text": "The choice of learning algorithm for each classifier is motivated by earlier findings showing that discriminative classifiers outperform other machine-learning methods on error correction tasks ( Rozovskaya and Roth , 2011 ) .", "label": "Motivation", "metadata": {}}
{"text": "A good study comparing document categorization algorithms can be found in ( Yang and Liu , 1999 ) .", "label": "Background", "metadata": {}}
{"text": "For HMMs ( footnote 11 ) , Ti is the familiar trellis , and we would like this computation of ti to reduce to the forwardbackward algorithm ( Baum , 1972 ) .", "label": "Background", "metadata": {}}
{"text": "For statistical significance , we use McNemar 's test on non-gold LAS , as implemented by Nilsson and Nivre ( 2008 ) .", "label": "Uses", "metadata": {}}
{"text": "The availability of toolkits for this weighted case ( Mohri et al. , 1998 ; van Noord and Gerdemann , 2001 ) promises to unify much of statistical NLP .", "label": "Background", "metadata": {}}
{"text": "tionally reconstructed by Alshawi and Crouch ( 1992 ) and Crouch and Putman ( 1994 ) , the context-independent meaning of a sentence is given by one or more QLFs that are built directly from syntactic and semantic rules .", "label": "CompareOrContrast", "metadata": {}}
{"text": "We use a standard split of 268 training documents , 68 development documents , and 106 testing documents ( Culotta et al. , 2007 ; Bengtson and Roth , 2008 ) .", "label": "Uses", "metadata": {}}
{"text": "Bojar and Kos ( 2010 ) improved on this by marking prepositions with the case they mark ( one of the most important markups in our system ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "But typical OT grammars offer much richer finite-state models of left context ( Eisner 1997a ) than provided by the traditional HMM finite-state topologies .", "label": "Background", "metadata": {}}
{"text": "Other tools have been designed around particular techniques , such as finite state machines ( Karttunen et al. , 1997 ; Mohri et al. , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Budanitsky and Hirst ( 2006 ) pointed out that distribution plots of judgments for the word pairs used by Rubenstein and Goodenough display an empty horizontal band that could be used to separate related and unrelated pairs .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In fact , Reiter has even argued in favor of this approach , claiming that the interactions are sufficiently minor to be ignored ( or at least handled on an ad hoc basis ) ( Reiter 1994 ) .", "label": "Background", "metadata": {}}
{"text": "The method is called targeted self-training as it is similar in vein to self-training ( McClosky et al. , 2006 ) , with the exception that the new parse data is targeted to produce accurate word reorderings .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In our previous work ( Zhang and Chai , 2009 ) , we started an initial investigation on conversation entailment .", "label": "Extends", "metadata": {}}
{"text": "It is also possible to focus on non-compositional compounds , a key point in bilingual applications ( Su et al. , 1994 ; Melamed , 1997 ; Lin , 99 ) .", "label": "Background", "metadata": {}}
{"text": "This is mainly due to the fact that Arabic is a non-concatenative language ( Al-Shalabi and Evens , 1998 ) , and that the stem/infix obtained by suppression of infix and prefix add-ons is not the same for words derived from the same origin called the root .", "label": "Background", "metadata": {}}
{"text": "ear regression adapted for classification ( Ting and Witten 1999 ) , which can be described by the following equation :", "label": "Uses", "metadata": {}}
{"text": "For example , the forward-backward algorithm ( Baum , 1972 ) trains only Hidden Markov Models , while ( Ristad and Yianilos , 1996 ) trains only stochastic edit distance .", "label": "Background", "metadata": {}}
{"text": "Using the tree-cut technique described above , our previous work ( Tomuro , 2000 ) extracted systematic polysemy from WordNet .", "label": "Extends", "metadata": {}}
{"text": "( Och and Ney , 2002 ; Blunsom et al. , 2008 ) used maximum likelihood estimation to learn weights for MT. ( Och , 2003 ; Moore and Quirk , 2008 ; Zhao and Chen , 2009 ; Galley and Quirk , 2011 ) employed an evaluation metric as a loss function and directly optimized it .", "label": "CompareOrContrast", "metadata": {}}
{"text": "5 Significant bigrams are obtained using the n-gram statistics package NSP ( Banerjee and Pedersen 2003 ) , which offers statistical tests to decide whether to accept or reject the null hypothesis regarding a bigram ( that it is not a collocation ) .", "label": "Uses", "metadata": {}}
{"text": "Liu et al. ( 2005 ) , Meral et al. ( 2007 ) , Murphy ( 2001 ) , Murphy and Vogel ( 2007 ) and Topkara et al. ( 2006a ) all belong to the syntactic transformation category .", "label": "Background", "metadata": {}}
{"text": "The local training method ( Bottou and Vapnik , 1992 ) is widely employed in computer vision ( Zhang et al. , 2006 ; Cheng et al. , 2010 ) .", "label": "Background", "metadata": {}}
{"text": "Recent work ( Banko and Brill , 2001 ; Curran and Moens , 2002 ) has suggested that some tasks will benefit from using significantly more data .", "label": "Background", "metadata": {}}
{"text": "The standard approach is to train two models independently and then intersect their predictions ( Och and Ney 2003 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "We use the same method as Andrews et al. ( 2009 ) for generating our multimodal corpora : for each word token in the text corpus , a feature is selected stochastically from the word 's feature distribution , creating a word-feature pair .", "label": "Uses", "metadata": {}}
{"text": "For example , 10 million words of the American National Corpus ( Ide et al. , 2002 ) will have manually corrected POS tags , a tenfold increase over the Penn Treebank ( Marcus et al. , 1993 ) , currently used for training POS taggers .", "label": "Background", "metadata": {}}
{"text": "The forward and backward probabilities , p0j and pkn , can be computed using single-source algebraic path for the simpler semiring ( R , + , x , \u00e2\u0088\u0097 ) -- or equivalently , by solving a sparse linear system of equations over R , a much-studied problem at O ( n ) space , O ( nm ) time , and faster approximations ( Greenbaum , 1997 ) .", "label": "Background", "metadata": {}}
{"text": "4To prove ( 1 ) \u00e2\u0087\u0092 ( 3 ) , express f as an FST and apply the well-known Kleene-Sch \u00c2\u00a8 utzenberger construction ( Berstel and Reutenauer , 1988 ) , taking care to write each regexp in the construction as a constant times a probabilistic regexp .", "label": "Uses", "metadata": {}}
{"text": "Second , software for utilizing this ontology already exists : MetaMap ( Aronson 2001 ) identifies concepts in free text , and SemRep ( Rindflesch and Fiszman 2003 ) extracts relations between the concepts .", "label": "Background", "metadata": {}}
{"text": "Most DOP models , such as in Bod ( 1993 ) , Goodman ( 1996 ) , Bonnema et al. ( 1997 ) , Sima'an ( 2000 ) and Collins & Duffy ( 2002 ) , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e. most probable ) tree as a candidate for the best tree of a sentence .", "label": "Background", "metadata": {}}
{"text": "The best performance on the WSJ corpus was achieved by a combination of the SATZ system ( Palmer and Hearst 1997 ) with the Alembic system ( Aberdeen et al. 1995 ) : a 0.5 % error rate .", "label": "CompareOrContrast", "metadata": {}}
{"text": "This method allows the efficient retrieval of arbitrary length n-grams ( Nagao and Mori , 94 ; Haruno et al. , 96 ; Ikehaxa et al. , 96 ; Shimohata et al. , 1997 ; Russell , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "The current system learns finite state flowcharts whereas typical learning systems usually acquire coefficient values as in Minsky and Papert ( 1969 ) , assertional statements as in Michalski ( 1980 ) , or semantic nets as in Winston ( 1975 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Our most accurate product model achieves an F score of 92.5 without the use of discriminative reranking and comes close to the best known numbers on this test set ( Zhang et al. , 2009 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Efficient hardware implementation is also possible via chip-level parallelism ( Rote , 1985 ) .", "label": "Future", "metadata": {}}
{"text": "Krahmer and Theune ( 2002 ) have argued that Dale and Reiter 's ( 1995 ) dichotomy between salient and nonsalient objects ( where the objects in the domain are the salient ones ) should be replaced by an account that takes degrees of salience into account : No object can be too unsalient to be referred to , as long as the right properties are available .", "label": "Background", "metadata": {}}
{"text": "The acquisition of dialogue as implemented in VNLCE is reminiscent of the program synthesis methodology developed by Biermann and Krishnaswamy ( 1976 ) where program flowcharts were constructed from traces of their behaviors .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In other methods , lexical resources are specifically tailored to meet the requirements of the domain ( Rosario and Hearst , 2001 ) or the system ( Gomez , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "The exact form of M ( Si ) need not be discussed at this point ; it could be a conceptual dependence graph ( Schank and Abelson 1977 ) , a deep parse of Si , or some other representation .", "label": "Background", "metadata": {}}
{"text": "Some methods are based on likelihood ( Och and Ney , 2002 ; Blunsom et al. , 2008 ) , error rate ( Och , 2003 ; Zhao and Chen , 2009 ; Pauls et al. , 2009 ; Galley and Quirk , 2011 ) , margin ( Watanabe et al. , 2007 ; Chiang et al. , 2008 ) and ranking ( Hopkins and May , 2011 ) , and among which minimum error rate training ( MERT ) ( Och , 2003 ) is the most popular one .", "label": "Background", "metadata": {}}
{"text": "Similarly , ( Barzilay and Lee , 2003 ) and ( Shinyanma et al. , 2002 ) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source .", "label": "Background", "metadata": {}}
{"text": "This setup is also scalable to a higher number of word pairs ( 350 ) as was shown in Gurevych ( 2006 ) .", "label": "Background", "metadata": {}}
{"text": "More recent work on terminology structuring has focussed on formal similarity to develop hypotheses on the semantic relationships between terms : Daille ( 2003 ) uses derivational morphology ; Grabar and Zweigenbaum ( 2002 ) use , as a starting point , a number of identical characters .", "label": "Background", "metadata": {}}
{"text": "Louwerse et al. ( 2006 ) and Louwerse et al. ( 2007 ) study the relation between eye gaze , facial expression , pauses and dialogue structure in annotated English map-task dialogues ( Anderson et al. , 1991 ) and find correlations between the various modalities both within and across speakers .", "label": "Background", "metadata": {}}
{"text": "Some examples include text categorization ( Lewis and Catlett 1994 ) , base noun phrase chunking ( Ngai and Yarowsky 2000 ) , part-of-speech tagging ( Engelson Dagan 1996 ) , spelling confusion set disambiguation ( Banko and Brill 2001 ) , and word sense disambiguation ( Fujii et al. 1998 ) .", "label": "Background", "metadata": {}}
{"text": "It is known that certain cue words and phrases ( Hirschberg and Litman 1993 ) can serve as explicit indicators of discourse structure .", "label": "Motivation", "metadata": {}}
{"text": "The last point may be seen better if we look at some differences between our system and KRYPTON , which also distinguishes between an object theory and background knowledge ( cfXXX Brachman et al. 1985 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Though we could have used a further downstream measure like BLEU , METEOR has also been shown to directly correlate with translation quality ( Banerjee and Lavie , 2005 ) and is simpler to measure .", "label": "Motivation", "metadata": {}}
{"text": "In our previous work ( Salloum and Habash , 2011 ; Salloum and Habash , 2012 ) , we applied our approach to tokenized Arabic and our DA-MSA transfer component used feature transfer rules only .", "label": "CompareOrContrast", "metadata": {}}
{"text": "It has already been used to implement a framework for teaching NLP ( Loper and Bird , 2002 ) .", "label": "Extends", "metadata": {}}
{"text": "Similarly , the notion of R + M-abduction is spiritually related to the `` abductive inference '' of Reggia ( 1985 ) , the `` diagnosis from first principles '' of Reiter ( 1987 ) , `` explainability '' of Poole ( 1988 ) , and the subset principle of Berwick ( 1986 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "To address this inconsistency in the correspondence between inflectional features and morphemes , and inspired by Smr\u00c5\u00be ( 2007 ) , we distinguish between two types of inflectional features : formbased ( a.k.a. surface , or illusory ) features and functional features .6 Most available Arabic NLP tools and resources model morphology using formbased ( `` surface '' ) inflectional features , and do not mark rationality ; this includes the Penn Arabic Treebank ( PATB ) ( Maamouri et al. 2004 ) , the Buckwalter morphological analyzer ( Buckwalter 2004 ) , and tools using them such as the Morphological Analysis and Disambiguation for Arabic ( MADA ) toolkit ( Habash and Rambow 2005 ; Habash , Rambow , and Roth 2012 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Jiang et al. ( 2005 ) has built a semantic role classifier exploiting the interdependence of semantic roles .", "label": "Uses", "metadata": {}}
{"text": "8 It is based on the dataset of Pang and Lee ( 2004 ) ,9 which consists of 1000 positive and 1000 negative movie reviews , tokenized and divided into 10 folds ( F0 -- F9 ) .", "label": "Extends", "metadata": {}}
{"text": "In previous work ( Bachenko et al. 1986 ) , we described an experimental text-to-speech system that determined prosodic phrasing for the Olive -- Liberman synthesizer ( Olive and Liberman 1985 ) .", "label": "Extends", "metadata": {}}
{"text": "The UMLS -- the Unified Medical Language System ( UMLS ) has been developed and maintained by National Library of Medicine ( NLM ) [ 17 ] .", "label": "Background", "metadata": {}}
{"text": "The data used in the experiment was selected from the Penn Treebank Wall Street Journal , and is the same used by Brill and Wu ( 1998 ) .", "label": "Uses", "metadata": {}}
{"text": "Following Soon et al. ( 2001 ) , we represent use the ACE training data for acquiring our SC clasSCA as a binary value that indicates whether the insifier ; instead , we use the BBN Entity Type Corpus duced SCs of the two NPs involved are the same or ( Weischedel and Brunstein , 2005 ) , which consists of not .", "label": "Uses", "metadata": {}}
{"text": "Church and Hanks ( 1990 ) use mutual information to identify collocations , a method they claim is reasonably effective for words with a frequency of not less than five .", "label": "Background", "metadata": {}}
{"text": "We do this with a first-order HMM part-ofspeech tagger ( Merialdo [ 13 ] ) .", "label": "Uses", "metadata": {}}
{"text": "Using the bottom-up , dynamic programming technique ( see the appendix for details ) of computing inside probabilities ( Lari and Young 1990 ) , we can efficiently compute the probability of the sentence , P ( w | G ) .", "label": "Uses", "metadata": {}}
{"text": "As shown in ( Minnen , 1996 ) \u00e2\u0080\u00a2 The presented research was carried out at the University of Tubingen , Germany , as part of the Sonderforschungsbereich 340 .", "label": "Background", "metadata": {}}
{"text": "According to Hinds ( 1979 ) , paragraphs are made up of segments , which in turn are made up of sentences or clauses , which in turn are made up of phrases .", "label": "Background", "metadata": {}}
{"text": "This choice is motivated by an observation we made previously ( Hasan and Ng , 2013a ) : since each post in a sequence is a reply to the preceding post , we could exploit their dependencies by determining their stance labels together .3 As our sequence learner , we employ a maximum entropy Markov model ( MEMM ) ( McCallum et al. , 2000 ) .", "label": "Extends", "metadata": {}}
{"text": "Over the past decade , researchers at IBM have developed a series of increasingly sophisticated statistical models for machine translation ( Brown et al. , 1988 ; Brown et al. , 1990 ; Brown et al. , 1993a ) .", "label": "Background", "metadata": {}}
{"text": "This approach has its roots in Fillmore 's Case Grammar ( 1968 ) , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet ( Baker et al. , 1998 ) and PropBank ( Kingsbury et al. , 2002 ) .", "label": "Background", "metadata": {}}
{"text": "Two exceptions to this generalisation are the Linguistic String Project ( Sager , 1981 ) and the IBM CRITIQUE ( formerly EPISTLE ) Project ( Heidorn et al. , 1982 ; Byrd , 1983 ) ; the former employs a dictionary of approximately 10,000 words , most of which are specialist medical terms , the latter has well over 100,000 entries , gathered from machine readable sources .", "label": "CompareOrContrast", "metadata": {}}
{"text": "They can also shift the dialogue 2The notion of the initiative in this paper is different from that of the dialogue initiative of Chu-Carroll ( 2000 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The Google n-gram data was collected by Google Research for statistical language modelling , and has been used for many tasks such as lexical disambiguation ( Bergsma et al. , 2009 ) , and contains English n-grams and their observed frequency counts , for counts of at least 40 .", "label": "Background", "metadata": {}}
{"text": "Withindocument coreference resolution has been applied to produce summaries of text surrounding occurrences of the name ( Bagga and Baldwin , 1998 ; Gooi and Allan , 2004 ) .", "label": "Background", "metadata": {}}
{"text": "Sridhar et al. ( 2009 ) obtain promising results in dialogue act tagging of the Switchboard-DAMSL corpus using lexical , syntactic and prosodic cues , while Gravano and Hirschberg ( 2009 ) examine the relation between particular acoustic and prosodic turn-yielding cues and turn taking in a large corpus of task-oriented dialogues .", "label": "Background", "metadata": {}}
{"text": "( Yang and Pedersen , 1997 ) has found strong correlations between DF , IG and the X2 statistic for a term .", "label": "Background", "metadata": {}}
{"text": "Despite this , to date , there has been little work on corpus-based approaches to help-desk response automation ( notable exceptions are Carmel , Shtalhaim , and Soffer 2000 ; Lapalme and Kosseim 2003 ; Bickel and Scheffer 2004 ; Malik , Subramaniam , and Kaushik 2007 ) .", "label": "Background", "metadata": {}}
{"text": "To quantify the relative strengths of these transitive inferences , Shaw and Hatzivassiloglou ( 1999 ) propose to assign a weight to each link .", "label": "Background", "metadata": {}}
{"text": "While these approaches have been reasonably successful ( see Mitkov ( 2002 ) ) , Kehler et al. ( 2004 ) speculate that deeper linguistic knowledge needs to be made available to resolvers in order to reach the next level of performance .", "label": "Background", "metadata": {}}
{"text": "Lisp is not particularly well suited for interfacing to complex , structured objects , and it was not our intention to embark on a major effort involving the development of a formal model of a dictionary ( of the style described in , eg. , Tompa 1986 ) ; on the other hand a method of access was clearly required , which was flexible enough to support a range of applications intending to make use of the LDOCE tape .", "label": "Background", "metadata": {}}
{"text": "\u00e2\u0080\u00a2 Learnability ( Zernik and Dyer 1987 ) \u00e2\u0080\u00a2 Text generation ( Hovy 1988 ; Milosavljevic , Tulloch , and Dale 1996 ) \u00e2\u0080\u00a2 Speech generation ( Rayner and Carter 1997 ) \u00e2\u0080\u00a2 Localization ( Sch \u00c2\u00a8 aler 1996 )", "label": "Background", "metadata": {}}
{"text": "In addition , Moulin et al. ( 1985 ) note that our Object Raising rule would assign mean to this category incorrectly .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The parallel corpus is word-aligned using GIZA + + ( Och and Ney , 2003 ) .", "label": "Uses", "metadata": {}}
{"text": "tions for the remaining 20 % of the instances ; and ( 3 ) train an SVM classifier ( using the LIBSVM package ( Chang and Lin , 2001 ) ) on these 20 % of the instances , where each instance , i , is represented by a set of 31 binary features .", "label": "Uses", "metadata": {}}
{"text": "Children use vague adjectives among their first dozens of words ( Peccei 1994 ) and understand some of their intricacies as early as their 24th month ( Ebeling and Gelman 1994 ) .", "label": "Background", "metadata": {}}
{"text": "( 4 ) NE : We use BBN 's IdentiFinder ( Bikel et al. , 1999 ) , a MUC-style NE recognizer to determine the NE type of NPZ .", "label": "Uses", "metadata": {}}
{"text": "raw length value as a feature , we follow our previous work ( Rubino et al. , 2013 ; Wagner et al. , 2014 ) and create multiple features for length using a decision tree ( J48 ) .", "label": "Extends", "metadata": {}}
{"text": "Following Ruch et al. ( 2003 ) and Barzilay and Lee ( 2004 ) , we employed Hidden Markov Models to model the discourse structure of MEDLINE abstracts .", "label": "Uses", "metadata": {}}
{"text": "A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , Erman et al. 1980 , Haton and Pierrel 1976 , Lea 1980 , Lowerre and Reddy 1980 , Medress 1980 , Reddy 1976 , Walker 1978 , and Wolf and Woods 1980 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "It allows the construction of a non-TAL ( Shieber , 1994 ) , ( Harbusch & Poller , 2000 ) .", "label": "Background", "metadata": {}}
{"text": "In addition , the advantages of using linguistically annotated data over raw data are well documented ( Mair , 2005 ; Granger and Rayson , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "In particular , the `` Semantic Information Retrieval '' project ( SIR Project , 2006 ) systematically investigates the use of lexical-semantic relations between words or concepts for improving the performance of information retrieval systems .", "label": "Motivation", "metadata": {}}
{"text": "Our re-ranking approach , like the approach to parse re-ranking of Collins ( 2000 ) , employs a simpler model -- a local semantic role labeling algorithm -- as a first pass to generate a set of n likely complete assignments of labels to all parse tree nodes .", "label": "CompareOrContrast", "metadata": {}}
{"text": "For instance , the Alembic workbench ( Aberdeen et al. 1995 ) contains a sentence-splitting module that employs over 100 regular-expression rules written in Flex .", "label": "Background", "metadata": {}}
{"text": "In contrast , a single statistical model allows one to maintain a single table ( Langkilde , 2000 ) .", "label": "Background", "metadata": {}}
{"text": "Our experiments are based on the multimodal extension of Latent Dirichlet Allocation developed by Andrews et al. ( 2009 ) .", "label": "Uses", "metadata": {}}
{"text": "First , it has been noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization ( Grishman , 1995 ; Appelt et al. , 1993 ) .", "label": "Background", "metadata": {}}
{"text": "Cohn and Blunsom ( 2009 ) adopted a Bayesian method to infer an STSG by exploring the space of alignments based on parse trees .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In corpus linguistics building such megacorpora is beyond the scope of individual researchers , and they are not easily accessible ( Kennedy , 1998 : 56 ) unless the web is used as a corpus ( Kilgarriff and Grefenstette , 2003 ) .", "label": "Background", "metadata": {}}
{"text": "Part of speech taggers typically require input in the format of a single sentence per line ( for example Brill 's tagger ( Brill , 1992 ) ) and parsers generally aim to produce a tree spanning each sentence .", "label": "Background", "metadata": {}}
{"text": "For instance , GATE currently provides a POS tagger , named entity recogniser and gazetteer and ontology editors ( Cunningham et al. , 2002 ) .", "label": "Background", "metadata": {}}
{"text": "Latent variables we wish to consider are an increased number of word classes ; more flexible regions -- see Petrov et al. ( 2007 ) on learning a state transition diagram for acoustic regions in phone recognition -- and phonological features and syllable boundaries .", "label": "Background", "metadata": {}}
{"text": "Since earlier versions of the SNoW based CSCL were used only to identify single phrases ( Punyakanok and Roth , 2001 ; Munoz et al. , 1999 ) and never to identify a collection of several phrases at the same time , as we do here , we also trained and tested it under the exact conditions of CoNLL-2000 ( Tjong Kim Sang and Buchholz , 2000 ) to compare it to other shallow parsers .", "label": "Uses", "metadata": {}}
{"text": "Recent developments in linguistics , and especially on grammatical theory -- for example , Generalised Phrase Structure Grammar ( GPSG ) ( Gazdar et al. , 1985 ) , Lexical Functional Grammar ( LFG ) ( Kaplan and Bresnan , 1982 ) -- and on natural language parsing frameworks -- for example , Functional Unification Grammar ( FUG ) ( Kay , 1984a ) , PATR-II ( Shieber , 1984 ) -- make it feasible to consider the implementation of efficient systems for the syntactic analysis of substantial fragments of natural language .", "label": "Background", "metadata": {}}
{"text": "We train a 4-gram language model on the Xinhua portion of the English Gigaword corpus using the SRILM Toolkits ( Stolcke , 2002 ) with modified Kneser-Ney smoothing ( Chen and Goodman , 1998 ) .", "label": "Uses", "metadata": {}}
{"text": "It is only recently that the web name ambiguity has been approached as a separate problem and defined as an NLP task Web People Search on its own ( Artiles et al. , 2005 ; Artiles et al. , 2007 ) .", "label": "Background", "metadata": {}}
{"text": "This deficiency is rectified in the verb classification system employed by Jackendoff and Grimshaw ( 1985 ) in the Brandeis verb catalogue .", "label": "CompareOrContrast", "metadata": {}}
{"text": "It is frequently used in tasks like scene identification , and Deselaers and Ferrari ( 2011 ) shows that distance in GIST space correlates well with semantic distance in WordNet .", "label": "Motivation", "metadata": {}}
{"text": "Because each rule r consists of a target tree fragment frag and a source string str in the model , we follow Cohn and Blunsom ( 2009 ) and decompose the prior probability P0 ( r | N ) into two factors as follows :", "label": "Uses", "metadata": {}}
{"text": "To address this inconsistency in the correspondence between inflectional features and morphemes , and inspired by Smr\u00c5\u00be ( 2007 ) , we distinguish between two types of inflectional features : formbased ( a.k.a. surface , or illusory ) features and functional features .6 Most available Arabic NLP tools and resources model morphology using formbased ( `` surface '' ) inflectional features , and do not mark rationality ; this includes the Penn Arabic Treebank ( PATB ) ( Maamouri et al. 2004 ) , the Buckwalter morphological analyzer ( Buckwalter 2004 ) , and tools using them such as the Morphological Analysis and Disambiguation for Arabic ( MADA ) toolkit ( Habash and Rambow 2005 ; Habash , Rambow , and Roth 2012 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In our prior work ( Xiong and Litman , 2011 ) , we examined whether techniques used for predicting the helpfulness of product reviews ( Kim et al. , 2006 ) could be tailored to our peer-review domain , where the definition of helpfulness is largely influenced by the educational context of peer review .", "label": "Extends", "metadata": {}}
{"text": "Bruni et al. ( 2012a ) show how a BoVW model may be easily combined with a distributional vector space model of language using only vector concatenation .", "label": "Background", "metadata": {}}
{"text": "The numeral ( whether it is implicit , as in ( 3 ) , or explicit ) can be construed as allowing the reader to draw inferences about the standards employed ( Kyburg and Morreau 2000 ; DeVault and Stone 2004 ) : ( 3 ) , for example , implies a standard that counts 10 cm as large and 8 cm as not large .", "label": "Background", "metadata": {}}
{"text": "Sanderson , 1994 studied the issue of disambiguation for mono-lingual M.", "label": "Background", "metadata": {}}
{"text": "Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed ( Neville and Jensen , 2000 ; Lafferty et al. , 2001 ; Getoor et al. , 2002 ; Taskar et al. , 2002 ; Taskar et al. , 2003 ; Taskar et al. , 2004 ; McCallum and Wellner , 2004 ) .", "label": "Background", "metadata": {}}
{"text": "To address this inconsistency in the correspondence between inflectional features and morphemes , and inspired by Smr\u00c5\u00be ( 2007 ) , we distinguish between two types of inflectional features : formbased ( a.k.a. surface , or illusory ) features and functional features .6 Most available Arabic NLP tools and resources model morphology using formbased ( `` surface '' ) inflectional features , and do not mark rationality ; this includes the Penn Arabic Treebank ( PATB ) ( Maamouri et al. 2004 ) , the Buckwalter morphological analyzer ( Buckwalter 2004 ) , and tools using them such as the Morphological Analysis and Disambiguation for Arabic ( MADA ) toolkit ( Habash and Rambow 2005 ; Habash , Rambow , and Roth 2012 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Although in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX Levesque 1984 ; Frisch 1987 ; Patel-Schneider 1985 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Riehemann 1993 ; Oliva 1994 ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "A number of proposals in the 1990s deliberately limited the extent to which they relied on domain and/or linguistic knowledge and reported promising results in knowledge-poor operational environments ( Dagan and Itai 1990 , 1991 ; Lappin and Leass 1994 ; Nasukawa 1994 ; Kennedy and Boguraev 1996 ; Williams , Harvey , and Preston 1996 ; Baldwin 1997 ; Mitkov 1996 , 1998b ) .", "label": "Background", "metadata": {}}
{"text": "As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .", "label": "Background", "metadata": {}}
{"text": "However , learning-based resolvers have not been able to benefit from having an SC agreement feature , presumably because the method used to compute the SC of an NP is too simplistic : while the SC of a proper name is computed fairly accurately using a named entity ( NE ) recognizer , many resolvers simply assign to a common noun the first ( i.e. , most frequent ) WordNet sense as its SC ( e.g. , Soon et al. ( 2001 ) , Markert and Nissim ( 2005 ) ) .", "label": "Background", "metadata": {}}
{"text": "Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers ( Collins , 1997 ; Charniak , 1997a ; Charniak , 1997b ; Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 ) .", "label": "Background", "metadata": {}}
{"text": "For instance , ( Lin and Pantel , 2001 ) acquire two-argument templates ( inference rules ) from corpora using an extended version of the distributional analysis in which paths in dependency trees that have similar arguments are taken to be close in meaning .", "label": "Background", "metadata": {}}
{"text": "Per-state joint normalization ( Eisner , 2001b , \u00c2\u00a7 8.2 ) is similar but drops the dependence on a .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Other studies on the value of disambiguation for cross-lingual IR include Hiemstra and de Jong , 1999 ; Hull , 1997 .", "label": "Background", "metadata": {}}
{"text": "We have not yet made use of TINA 'S probabilities in adjusting the recognizer scores on the fly , but we have been able to incorporate linguistic scores to resort N-best outputs , giving a significant improvement in performance ( Goodine et al. 1991 ) .", "label": "Uses", "metadata": {}}
{"text": "More recently , ( Sebastiani , 2002 ) has performed a good survey of document categorization ; recent works can also be found in ( Joachims , 2002 ) , ( Crammer and Singer , 2003 ) , and ( Lewis et al. , 2004 ) .", "label": "Background", "metadata": {}}
{"text": "McDonald has even argued for extending the model to a large number of components ( McDonald 1988 ) , and several systems have indeed added an additional component between the planner and the linguistic component ( Meteer 1994 ; Panaget 1994 ; Wanner 1994 ) .", "label": "Background", "metadata": {}}
{"text": "It is these orthographic variations and complex morphological structure that make Arabic language processing challenging ( Xu et al. , 2001 ; Xu et al. , 2002 ) .", "label": "Background", "metadata": {}}
{"text": "A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , Erman et al. 1980 , Haton and Pierrel 1976 , Lea 1980 , Lowerre and Reddy 1980 , Medress 1980 , Reddy 1976 , Walker 1978 , and Wolf and Woods 1980 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "It has been more difficult showing that agreement morphology helps parsing , however , with negative results for dependency parsing in several languages ( Eryigit , Nivre , and Oflazer 2008 ; Nivre , Boguslavsky , and Iomdin 2008 ; Nivre 2009 ) .", "label": "Motivation", "metadata": {}}
{"text": "Some efforts have tackled tasks such as automatic image caption generation ( Feng and Lapata , 2010a ; Ordonez et al. , 2011 ) , text illustration ( Joshi et al. , 2006 ) , or automatic location identification of Twitter users ( Eisenstein et al. , 2010 ; Wing and Baldridge , 2011 ; Roller et al. , 2012 ) .", "label": "Background", "metadata": {}}
{"text": "This idea was proposed by Krauwer and des Tombe ( 1981 ) , Langendoen and Langsam ( 1987 ) , and Pulman ( 1986 ) , and was rediscovered by Black ( 1989 ) and recently by Johnson ( 1998 ) .", "label": "Background", "metadata": {}}
{"text": "However , since work in this direction has started , a significant progress has also been made in the research on statistical learning of full parsers , both in terms of accuracy and processing time ( Charniak , 1997b ; Charniak , 1997a ; Collins , 1997 ; Ratnaparkhi , 1997 ) .", "label": "Background", "metadata": {}}
{"text": "Some methods are based on likelihood ( Och and Ney , 2002 ; Blunsom et al. , 2008 ) , error rate ( Och , 2003 ; Zhao and Chen , 2009 ; Pauls et al. , 2009 ; Galley and Quirk , 2011 ) , margin ( Watanabe et al. , 2007 ; Chiang et al. , 2008 ) and ranking ( Hopkins and May , 2011 ) , and among which minimum error rate training ( MERT ) ( Och , 2003 ) is the most popular one .", "label": "Background", "metadata": {}}
{"text": "Various approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based ( Lesk , 1986 ) , ontology-based ( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based ( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional ( Weeds and Weir , 2005 ) .", "label": "Background", "metadata": {}}
{"text": "EM maximizes G ( 0 ) via block-coordinate ascent on a lower bound F ( q , 0 ) using an auxiliary distribution over the latent variables q ( z | x , y ) ( Neal and Hinton 1998 ) :", "label": "Uses", "metadata": {}}
{"text": "\u00e2\u0080\u00a2 Only qualitative observations of the responses were reported ( no formal evaluation was performed ) ( Lapalme and Kosseim 2003 ; Roy and Subramaniam 2006 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "A stops B from doing something ; A disagreees with B on something , 8 % and 12 % ) Note that in our original work ( Zhang and Chai , 2009 ) , only development data were used to show some initial observations .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The EM algorithm ( Dempster et al. , 1977 ) can maximize these functions .", "label": "Uses", "metadata": {}}
{"text": "Finally , feedback expressions ( head nods and shakes ) are successfully predicted from speech , prosody and eye gaze in interaction with Embodied Communication Agents as well as human communication ( Fujie et al. , 2004 ; Morency et al. , 2005 ; Morency et al. , 2007 ; Morency et al. , 2009 ) .", "label": "Background", "metadata": {}}
{"text": "For these or for a specific domain , basic synonymic dictionaries can be complemented using learning methods based on distributional similarity ( Pereira et al. , 1993 ; Lin , 1998 ) .", "label": "Future", "metadata": {}}
{"text": "For projective parsing , it is significantly faster than exact dynamic programming , at the cost of small amounts of search error , We are interested in extending these ideas to phrase-structure and lattice parsing , and in trying other higher-order features , such as those used in parse reranking ( Charniak and Johnson , 2005 ; Huang , 2008 ) and history-based parsing ( Nivre and McDonald , 2008 ) .", "label": "Future", "metadata": {}}
{"text": "The research described below is taking place in the context of three collaborative projects ( Boguraev , 1987 ; Russell et al. , 1986 ; Phillips and Thompson , 1986 ) to develop a general-purpose , wide coverage morphological and syntactic analyser for English .", "label": "Background", "metadata": {}}
{"text": "transition-based dependency parsing framework ( Nivre , 2008 ) using an arc-eager transition strategy and are trained using the perceptron algorithm as in Zhang and Clark ( 2008 ) with a beam size of 8 .", "label": "Uses", "metadata": {}}
{"text": "Acoustic models for HTK is trained with the continuous speech database of the Acoustical Society of Japan ( Kobayashi et al. , 1992 ) .", "label": "Uses", "metadata": {}}
{"text": "For our Text modality , we use deWaC , a large German web corpus created by the WaCKy group ( Baroni et al. , 2009 ) containing approximately 1.7 B word tokens .", "label": "Uses", "metadata": {}}
{"text": "Previous work on Chinese SRL mainly focused on how to transplant the machine learning methods which has been successful with English , such as Sun and Jurafsky ( 2004 ) , Xue and Palmer ( 2005 ) and Xue ( 2008 ) .", "label": "Background", "metadata": {}}
{"text": "Our training examples are similar to the data created for pseudodisambiguation , the usual evaluation task for SP models ( Erk , 2007 ; Keller and Lapata , 2003 ; Rooth et al. , 1999 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "With the use of computers in storing the explosive amount of biological information , natural language processing ( NLP ) approaches have been explored to make the task of managing information recorded in free text more feasible [ 1 , 2 ] .", "label": "Background", "metadata": {}}
{"text": "A formula q5 of L ( =-RRB- , the language with equality , is weakly R + M-abductible from an object theory T , denoted by T I-R + m 0 , iff there exists a partial theory T e PT ( T ) and a preferred model M E PM ( T ) such that M = 0 , i.e. 0 is true in at least one preferred model of the partial theory T. Note : The notions of strong provability and strong R + M-abduction can be introduced by replacing `` there exists '' by `` all '' in the above definitions ( cfXXX Zadrozny 1987b ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "A third problem arises with the approach to the semantics of QLFs that this notion of the relationship between QLF and RQLF encourages one to adopt : it is that taken by Alshawi and Crouch ( 1992 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In ( Lin , 2004 ) , I present evidence from Mandarin Chinese that this analysis is on the right track .", "label": "Extends", "metadata": {}}
{"text": "Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) [ 18 ] , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase [ 22 ] , Human Nomenclature Database ( HUGO ) [ 23 ] , Online Mendelian Inheritance in Man ( OMIM ) [ 24 ] , and Enzyme Nomenclature Database ( ECNUM ) [ 25 , 26 ] .", "label": "Uses", "metadata": {}}
{"text": "There are many more distinctions which are conveyed by the conjunction of grammar codes and word qualifiers ( see Michiels , 1982 , for further details ) .", "label": "Background", "metadata": {}}
{"text": "The most common way is to divide each half of the bitext into an equal number of segments and to align the segments so that each pair of segments Si and Ti are translations of each other ( Gale & Church , 1991 ; Melamed , 1996a ) .", "label": "Background", "metadata": {}}
{"text": "In the field of machine learning research , incremental training has been employed in the work ( Cauwenberghs and Poggio , 2001 ; Shilton et al. , 2005 ) , but there is little work for tuning parameters of statistical machine translation .", "label": "Background", "metadata": {}}
{"text": "In a log-linear parameterization , for example , a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting ( Chen and Rosenfeld , 1999 ) .", "label": "Uses", "metadata": {}}
{"text": "A study of the query log of the AllTheWeb and Altavista search sites gives an idea of the relevance of the people search task : 11-17 % of the queries were composed of a person name with additional terms and 4 % were identified as person names ( Spink et al. , 2004 ) .", "label": "Background", "metadata": {}}
{"text": "This was done because purely unsupervised techniques ( e.g. , Baum-Welch [ Baum and Petrie 1966 ] or Brill 's [ Brill 1995b ] ) enable regularities to be induced for word classes which contain many entries , exploiting the fact that individual words that belong to a POS class occur in different ambiguity patterns .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Future research should apply the work of Blunsom et al. ( 2008 ) and Blunsom and Osborne ( 2008 ) , who marginalize over derivations to find the most probable translation rather than the most probable derivation , to these multi-nonterminal grammars .", "label": "Future", "metadata": {}}
{"text": "Using the section labels , the HMM was trained using the HTK toolkit ( Young et al. , 2002 ) , which efficiently performs the forward-backward algorithm and BaumWelch estimation .", "label": "Uses", "metadata": {}}
{"text": "In this paper , we use TF-IDF ( a kind of augmented DF ) as a feature selection criterion , in order to ensure results are comparable with those in ( Yahyaoui , 2001 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "A variety of statistical methods were proposed over the recent years for learning to produce a full parse of free-text sentences ( e.g. , Bod ( 1992 ) , Magerman ( 1995 ) , Collins ( 1997 ) , Ratnaparkhi ( 1997 ) , and Sekine ( 1998 ) ) .", "label": "Background", "metadata": {}}
{"text": "There is a rich literature on organization and lexical access of morphologically complex words where experiments have been conducted mainly for derivational suffixed words of English , Hebrew , Italian , French , Dutch , and few other languages ( Marslen-Wilson et al. , 2008 ; Frost et al. , 1997 ; Grainger , et al. , 1991 ; Drews and Zwitserlood , 1995 ) .", "label": "Background", "metadata": {}}
{"text": "In the disambiguation of capitalized words , the most widespread method is POS tagging , which achieves about a 3 % error rate on the Brown corpus and a 5 % error rate on the WSJ corpus , as reported in Mikheev ( 2000 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The problem with this approach is that any threshold is , to some extent , arbitrary , and there is evidence to suggest that , for some tasks , low counts are important ( Collins and Brooks , 1995 ) .", "label": "Motivation", "metadata": {}}
{"text": "Steganography is concerned with hiding information in some cover medium , by manipulating properties of the medium in such a way that the hidden information is not easily detectable by an observer ( Fridrich , 2009 ) .", "label": "Background", "metadata": {}}
{"text": "We offer a theorem that highlights the broad applicability of these modeling techniques .4 If f ( input , output ) is a weighted regular relation , then the following statements are equivalent : ( 1 ) f is a joint probabilistic relation ; ( 2 ) f can be computed by a Markovian FST that halts with probability 1 ; ( 3 ) f can be expressed as a probabilistic regexp , i.e. , a regexp built up from atomic expressions a : b ( for a E E U -LCB- E -RCB- , b E A U -LCB- E -RCB- ) using concatenation , probabilistic union + p , and probabilistic closure * p. For defining conditional relations , a good regexp language is unknown to us , but they can be defined in several other ways : ( 1 ) via FSTs as in Fig. 1c , ( 2 ) by compilation of weighted rewrite rules ( Mohri and Sproat , 1996 ) , ( 3 ) by compilation of decision trees ( Sproat and Riley , 1996 ) , ( 4 ) as a relation that performs contextual left-to-right replacement of input substrings by a smaller conditional relation ( Gerdemann and van Noord , 1999 ) ,5 ( 5 ) by conditionalization of a joint relation as discussed below .", "label": "Background", "metadata": {}}
{"text": "Word pairs containing polysemous words are expanded to concept pairs using GermaNet ( Kunze , 2004 ) , the German equivalent to WordNet , as a sense inventory for each word .", "label": "Uses", "metadata": {}}
{"text": "Our results are lower than those of full parsers , e.g. , Collins ( 1997 ) as might be expected since much less structural data , and no lexical data are being used .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Hermann and Deutsch ( 1976 ; also reported in Levelt 1989 ) show that greater differences are most likely to be chosen , presumably because they are more striking .", "label": "Background", "metadata": {}}
{"text": "We then use Illinois Chunker ( Punyakanok and Roth , 2001 ) 6 to extract more noun phrases from the text and employ Collins head rules ( Collins , 1999 ) to identify their heads .", "label": "Uses", "metadata": {}}
{"text": "Butt ( 1993 ) argues CV formations in Hindi and Urdu are either morphological or syntactical and their formation take place at the argument structure .", "label": "Background", "metadata": {}}
{"text": "feature Cohen 's k corrected k agreement 73.59 98.74 dial act 84.53 98.87 turn 73.52 99.16 Table 2 : Inter-coder agreement on feedback expression annotation Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures , see Artstein and Poesio ( 2008 ) , it is usually assumed that Cohen 's kappa figures over 60 are good while those over 75 are excellent ( Fleiss , 1971 ) .", "label": "Background", "metadata": {}}
{"text": "We run TreeTagger ( Schmid , 1994 ) for tokenization , and used the Giza + + ( Och and Ney , 2003 ) to align the tokenized corpora at the word level .", "label": "Uses", "metadata": {}}
{"text": "We then go on to compare the current approach with that of some other theories with similar aims : the `` standard '' version of quasi-logical form implemented in the Core Language Engine , as rationally reconstructed by Alshawi and Crouch ( 1992 ) and Crouch and Pulman ( 1994 ) ; underspecified Discourse Representation Theory ( Reyle 1993 ) ; and the `` glue language '' approach of Dalrymple et al. ( 1996 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Note that this ensures that greater importance is attributed to longer chunks , as is usual in most EBMT systems ( cfXXX Sato and Nagao 1990 ; Veale and Way 1997 ; Carl 1999 ) .7 As an example , consider the translation into French of the house collapsed .", "label": "Background", "metadata": {}}
{"text": "Using WordNet , annotating the sem feature of an adjective involves first choosing the correct sense for the adjective 2Some descriptions of int modifiers can be found in ( Cheng and Mellish , 2000b ) .", "label": "Background", "metadata": {}}
{"text": "One common approach is using Machine Translation ( MT ) to translate the queries to the language of the documents or translate documents to the language of the queries ( Gey et al , 1999 ; Oard , 1998 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Both use the evaluation software and triple encoding presented in Crouch et al. ( 2002 ) .", "label": "Uses", "metadata": {}}
{"text": "In this Section , we will describe some example cases , which are drawn from the problem of using synchronous formalisms to define translations between languages ( e.g. Shieber ( 1994 ) cases ) .", "label": "Background", "metadata": {}}
{"text": "Some examples include text categorization ( Lewis and Catlett 1994 ) , base noun phrase chunking ( Ngai and Yarowsky 2000 ) , part-of-speech tagging ( Engelson Dagan 1996 ) , spelling confusion set disambiguation ( Banko and Brill 2001 ) , and word sense disambiguation ( Fujii et al. 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Most coreference resolution work simply mentions it in passing as a module in the pipelined system ( Chang et al. , 2013 ; Durrett and Klein , 2013 ; Lee et al. , 2011 ; Bj \u00c2\u00a8 orkelund and Kuhn , 2014 ) .", "label": "Background", "metadata": {}}
{"text": "Because the judges do not evaluate the same cases , we could not employ standard inter-annotator agreement measures ( Carletta 1996 ) .", "label": "Uses", "metadata": {}}
{"text": "Related are also the studies by Rieks op den Akker and Schulz ( 2008 ) and Murray and Renals ( 2008 ) : both achieve promising results in the automatic segmentation of dialogue acts using the annotations in a large multimodal corpus .", "label": "Background", "metadata": {}}
{"text": "The reader may consult recent papers on this subject ( e.g. Moens and Steedman 1987 ; Webber 1987 ) to see what a formal interpretation of events in time might look like .", "label": "Background", "metadata": {}}
{"text": "Because it is also consistent , it will be chosen as a best interpretation of S , ( cfXXX Zadrozny 1987a , 1987b ) .", "label": "Background", "metadata": {}}
{"text": "With respect to this , we apply the different priming and other lexical decision experiments , described in literature ( Marslen-Wilson et al. , 1994 ; Bentin , S. and Feldman , 1990 ) specifically for derivationally suffixed polymorphemic words and compound verbs of Bangla .", "label": "Uses", "metadata": {}}
{"text": "The starting point for the approach followed here was a dissatisfaction with certain aspects of the theory of quasi-logical form as described in Alshawi ( 1990 , 1992 ) , and implemented in SRI 's Core Language Engine ( CLE ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The computational treatment of lexical rules as covariation in lexical entries was implemented in Prolog by the authors in cooperation with Dieter Martini for the ConTroll system ( Gerdemann and King 1994 ; Gotz and Meurers 1997a ) .", "label": "Uses", "metadata": {}}
{"text": "Arabic has two kinds of plurals : broken plurals and sound plurals ( Wightwick and Gaafar , 1998 ; Chen and Gey , 2002 ) .", "label": "Background", "metadata": {}}
{"text": "To prove that our method is effective , we also make a comparison between the performances of our system and Xue and Palmer ( 2005 ) , Xue ( 2008 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "But while Bod 's estimator obtains state-of-the-art results on the WSJ , comparable to Charniak ( 2000 ) and Collins ( 2000 ) , Bonnema et al. 's estimator performs worse and is comparable to Collins ( 1996 ) .", "label": "Background", "metadata": {}}
{"text": "For instance , part of the ACE Phase 2 also adopted a corpus-based approach to SC deterevaluation involves classifying an NP as PERSON , mination that is investigated as part of the mention ORGANIZATION , GPE ( a geographical-political redetection ( MD ) task ( e.g. , Florian et al. ( 2006 ) ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In most cases , the accuracy of parsers degrades when run on out-of-domain data ( Gildea , 2001 ; McClosky et al. , 2006 ; Blitzer et al. , 2006 ; Petrov et al. , 2010 ) .", "label": "Background", "metadata": {}}
{"text": "Based on this assumption , the problem of identifying mention heads is a sequential phrase identification problem , and we choose to employ the BILOU-representation as it has advantages over traditional BIO-representation , as shown , e.g. in Ratinov and Roth ( 2009 ) .", "label": "Motivation", "metadata": {}}
{"text": "TF is given by TFD , t , and it denotes frequency of term t in document D. IDF is given by IDFt = log ( N/dft ) , where N is the number of documents in the collection , and dft is the number of documents containing the term t. ( Salton and Yang , 1973 ) proposed the combination of TF and IDF as weighting schemes , and it has been shown that their product gave better performance .", "label": "Motivation", "metadata": {}}
{"text": "An HPSG grammar consists of lexical entries and ID grammar rules , each of which is described with typed feature structures ( Carpenter , 1992 ) .", "label": "Background", "metadata": {}}
{"text": "In our work , we gather sets of sentences , and assume ( but do not employ ) existing approaches for their organization ( Goldstein et al. 2000 ; Barzilay , Elhadad , and McKeown 2001 ; Barzilay and McKeown 2005 ) .", "label": "Background", "metadata": {}}
{"text": "For example , such schema can serve as a mean to represent translation examples , or find structural correspondences for the purpose of transfer grammar learning ( Menezes & Richardson , 2001 ) , ( Aramaki et al. , 2001 ) , ( Watanabe et al. , 2000 ) , ( Meyers et al. , 2000 ) , ( Matsumoto et al. , 1993 ) , ( kaji et al. , 1992 ) , and example-base machine translation EBMT3 ( Sato & Nagao , 1990 ) , ( Sato , 1991 ) , ( Richardson et al. , 2001 ) , ( Al-Adhaileh & Tang , 1999 ) .", "label": "Background", "metadata": {}}
{"text": "This was done because purely unsupervised techniques ( e.g. , Baum-Welch [ Baum and Petrie 1966 ] or Brill 's [ Brill 1995b ] ) enable regularities to be induced for word classes which contain many entries , exploiting the fact that individual words that belong to a POS class occur in different ambiguity patterns .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Two formalizations of lexical rules as used by HPSG linguists have been proposed , the meta-level lexical rules ( MLRs ; Calcagno 1995 ; Calcagno and Pollard 1995 ) and the .", "label": "Background", "metadata": {}}
{"text": "Various feature selection techniques have been used in automatic text categorization ; they include document frequency ( DF ) , information gain ( IG ) ( Tzeras and Hartman , 1993 ) , minimum description length principal ( Lang , 1995 ) , and the X2 statistic .", "label": "Background", "metadata": {}}
{"text": "The account sketched in Section 4 was superimposed on an incremental GRE algorithm , partly because incrementality is well established in this area ( Appelt 1985 ; Dale and Reiter 1995 ) .", "label": "Background", "metadata": {}}
{"text": "In most cases , the accuracy of parsers degrades when run on out-of-domain data ( Gildea , 2001 ; McClosky et al. , 2006 ; Blitzer et al. , 2006 ; Petrov et al. , 2010 ) .", "label": "Background", "metadata": {}}
{"text": "Johns and Jones ( 2012 ) take an entirely different approach by showing that one can successfully infer held out feature norms from weighted mixtures based on textual similarity .", "label": "Background", "metadata": {}}
{"text": "Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations ( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring ( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .", "label": "Background", "metadata": {}}
{"text": "We assume that every determiner has its own equivalence , which resolves it as a quantifier : sometimes this can be quite a complicated matter , as with any ( Alshawi 1990 ) , which will resolve in different ways depending on its linguistic context , but here we avoid this complexity ' 6 Separate equivalences might also make it easier to encode determiner-specific preferences , such as that of each for wide scope .", "label": "Background", "metadata": {}}
{"text": "Following Pinkal ( 1979 ) , such expressions will be called vague descriptions even though , as we shall see , the vagueness of the adjective does not extend to the description as a whole .", "label": "Uses", "metadata": {}}
{"text": "Such approaches have been tried recently in restricted cases ( McCallum et al. , 2000 ; Eisner , 2001b ; Lafferty et al. , 2001 ) .", "label": "Background", "metadata": {}}
{"text": "There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity ( Dowty , 1979 ; Jackendoff , 1983 ; Pustejovsky , 1991b ; Rappaport Hovav and Levin , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Liu et al. ( 2012 ) re-trained the linguistic parsers bilingually based on word alignment .", "label": "CompareOrContrast", "metadata": {}}
{"text": "de URL : http://www.sfs.nphil.uni-tuebingen.de/sfb / b4home.html 1 This is , for example , the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement ( Hinrichs and Nakazawa 1989 ) that also use lexical rules such as the Complement Extraction Lexical Rule ( Pollard and Sag 1994 ) or the Complement Cliticization Lexical Rule ( Miller and Sag 1993 ) to operate on those raised elements .", "label": "Background", "metadata": {}}
{"text": "Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures ( Rambow & Satta , 1996 ) , such as the relation between syntax and semantic .", "label": "Background", "metadata": {}}
{"text": "From an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition ( Pacak et al. , 1980 ; Norton and Pacak , 1983 ; Wolff , 1984 ; Wingert , 1985 ; Dujols et al. , 1991 ; Baud et al. , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "The following are the various tag sets we use in this article : ( a ) the core POS tag sets CORE44 and the newly introduced CORE12 ; ( b ) CATiB Treebank tag set ( CATIB6 ) ( Habash and Roth 2009 ) and its newly introduced extension of CATIBEX created using simple regular expressions on word form , indicating particular morphemes such as the prefix JI Al + or the suffix v ' + wn ; this tag set is the best-performing tag set for Arabic on predicted values as reported in Section 4 ; ( c ) the PATB full tag set with complete morphological tag ( BW ) ( Buckwalter 2004 ) ; and two extensions of the PATB reduced tag set ( PENN POS , a.k.a. RTS , size 24 [ Diab , Hacioglu , and Jurafsky 2004 ] ) , both outperforming it : ( d ) Kulick , Gabbard , and Marcus ( 2006 ) 's tag set ( KULICK ) , size 43 , one of whose most important extensions is the marking of the definite article clitic , and ( e ) Diab and Benajiba 's ( in preparation ) EXTENDED RTS tag set ( ERTS ) , which marks gender , number , and definiteness , size 134 .", "label": "Uses", "metadata": {}}
{"text": "A similar problem is discussed in the psycholinguistics of interpretation ( Sedivy et al. 1999 ) : Interpretation is widely assumed to proceed incrementally , but vague descriptions resist strict incrementality , since an adjective in a vague description can only be fully interpreted when its comparison set is known .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In this paper , we evaluated the role of low-level image features , SURF and GIST , for their compatibility with the multimodal Latent Dirichlet Allocation model of Andrews et al. ( 2009 ) .", "label": "Uses", "metadata": {}}
{"text": "Boutsis and Piperidis ( 1998 ) use a tagged parallel corpus to extract translationally equivalent English-Greek clauses on the basis of word occurrence and co-occurrence probabilities .", "label": "Background", "metadata": {}}
{"text": "The key linguistic knowledge sources that we use are morphological analysis and generation of German based on SMOR , a morphological analyzer/generator of German ( Schmid et al. , 2004 ) and the BitPar parser , which is a state-of-the-art parser of German ( Schmid , 2004 ) .", "label": "Uses", "metadata": {}}
{"text": "Authors may choose this right with the No-Deriv option of the Creative Commons licences ( Lessig , 2004 ) .", "label": "Background", "metadata": {}}
{"text": "The same annotation scheme as in our previous work on anger detection has been applied , see e.g. ( Schmitt et al. , 2009 ) .", "label": "Extends", "metadata": {}}
{"text": "We also compute GIST vectors ( Oliva and Torralba , 2001 ) for every image using LearGIST ( Douze et al. , 2009 ) .", "label": "Uses", "metadata": {}}
{"text": "In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ Kaplan and Bresnan 1982 ; Bresnan 2001 ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar [ CCG ] [ Ades and Steedman 1982 ] ) , the lexicon is the central repository for much morphological , syntactic , and semantic information .", "label": "Background", "metadata": {}}
{"text": "The analysis of the data we have collected indicates that student satisfaction may be affected if the system rephrases student answers using different words ( for example , using better terminology ) but does n't explicitly explain the reason why different terminology is needed ( Dzikovska et al. , 2010 ) .", "label": "Future", "metadata": {}}
{"text": "A logic that provides the formal architecture required by Pollard and Sag ( 1994 ) was defined by King ( 1989 , 1994 ) .", "label": "Background", "metadata": {}}
{"text": "Collins et al. ( 1999 ) report that an optimal tag set for parsing Czech consists of a basic POS tag plus a CASE feature ( when applicable ) .", "label": "Background", "metadata": {}}
{"text": "The elimination of redundant nondeterminism is based on Unfold/Fold transformation techniques ( Tamaki and Sato 1984 ) .29 The unfolding transformation is also referred to as partial execution , for example , by Pereira and Shieber ( 1987 ) .", "label": "Background", "metadata": {}}
{"text": "Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations ( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring ( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .", "label": "Background", "metadata": {}}
{"text": "9 We do not relate to specific results in their study because it has been brought to our attention that Hohensee and Bender ( 2012 ) are in the process of rechecking their code for errors , and rerunning their experiments ( personal communication ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Inspired by ( Klein and Manning , 2003 ) , we split one phrase type into several subsymbols , which contain category information of current constituent 's parent .", "label": "Motivation", "metadata": {}}
{"text": "The recent great advances in speech and language technologies have made it possible to build fully implemented spoken dialogue systems ( Aust et al. , 1995 ; Allen et al. , 1996 ; Zue et al. , 2000 ; Walker et al. , 2000 ) .", "label": "Background", "metadata": {}}
{"text": "Moreover , in order to determine whether the performances of the predictive criteria are consistent across different learning models within the same domain , we have performed the study on two parsing models : one based on a context-free variant of tree-adjoining grammars ( Joshi , Levy , and Takahashi 1975 ) , the Probabilistic Lexicalized Tree Insertion Grammar ( PLTIG ) formalism ( Schabes and Waters 1993 ; Hwa 1998 ) , and Collins 's Model 2 parser ( 1997 ) .", "label": "Uses", "metadata": {}}
{"text": "We prepare the training data by splitting compounds in two steps , following the technique of Fritzinger and Fraser ( 2010 ) .", "label": "Uses", "metadata": {}}
{"text": "Some efforts have tackled tasks such as automatic image caption generation ( Feng and Lapata , 2010a ; Ordonez et al. , 2011 ) , text illustration ( Joshi et al. , 2006 ) , or automatic location identification of Twitter users ( Eisenstein et al. , 2010 ; Wing and Baldridge , 2011 ; Roller et al. , 2012 ) .", "label": "Background", "metadata": {}}
{"text": "For example , Jokinen and Ragni ( 2007 ) and Jokinen et al. ( 2008 ) find that machine learning algorithms can be trained to recognise some of the functions of head movements , while Reidsma et al. ( 2009 ) show that there is a dependence between focus of attention and assignment of dialogue act labels .", "label": "Background", "metadata": {}}
{"text": "As a logical postulate it is not very radical ; it is possible within a finitary framework to develop that part of mathematics that is used or has potential applications in natural science , such as mathematical analysis ( cfXXX Mycielski 1981 ) .", "label": "Background", "metadata": {}}
{"text": "In a similar vain to Skut and Brants ( 1998 ) and Buchholz et al. ( 1999 ) , the method extends an existing flat shallow-parsing method to handle composite structures .", "label": "Future", "metadata": {}}
{"text": "\u00e2\u0080\u00a2 language learning ( Green 1979 ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 ) \u00e2\u0080\u00a2 monolingual grammar induction ( Juola 1998 ) \u00e2\u0080\u00a2 grammar optimization ( Juola 1994 ) \u00e2\u0080\u00a2 insights into universal grammar ( Juola 1998 ) \u00e2\u0080\u00a2 machine translation ( Juola 1994 , 1997 ; Veale and Way 1997 ; Gough , Way , and Hearne 2002 )", "label": "Background", "metadata": {}}
{"text": "We apply our system to the latest version of the XTAG English grammar ( The XTAG Research Group , 2001 ) , which is a large-scale FB-LTAG grammar .", "label": "Uses", "metadata": {}}
{"text": "Furthermore , the need to answer questions related to patient care at the point of service has been well studied and documented ( Covell , Uman , and Manning 1985 ; Gorman , Ash , and Wykoff 1994 ; Ely et al. 1999 , 2005 ) .", "label": "Background", "metadata": {}}
{"text": "Typical examples are Bulgarian ( Simov et al. , 2005 ; Simov and Osenova , 2003 ) , Chinese ( Chen et al. , 2003 ) , Danish ( Kromann , 2003 ) , and Swedish ( Nilsson et al. , 2005 ) .", "label": "Background", "metadata": {}}
{"text": "Over the last decade there has been a lot of interest in developing tutorial dialogue systems that understand student explanations ( Jordan et al. , 2006 ; Graesser et al. , 1999 ; Aleven et al. , 2001 ; Buckley and Wolska , 2007 ; Nielsen et al. , 2008 ; VanLehn et al. , 2007 ) , because high percentages of selfexplanation and student contentful talk are known to be correlated with better learning in humanhuman tutoring ( Chi et al. , 1994 ; Litman et al. , 2009 ; Purandare and Litman , 2008 ; Steinhauser et al. , 2007 ) .", "label": "Background", "metadata": {}}
{"text": "Worst case , calculating the set corresponding with such a property , of the form size ( x ) = maxm , for example , involves sorting the distractors as to their size , which may amount to O ( n2d ) or O ( nd log nd ) calculations ( depending on the sorting algorithm : cfXXX [ Aho et al. 1983 ] Chapter 8 ) .", "label": "Background", "metadata": {}}
{"text": "\u00e2\u0080\u00a2 language learning ( Green 1979 ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 ) \u00e2\u0080\u00a2 monolingual grammar induction ( Juola 1998 ) \u00e2\u0080\u00a2 grammar optimization ( Juola 1994 ) \u00e2\u0080\u00a2 insights into universal grammar ( Juola 1998 ) \u00e2\u0080\u00a2 machine translation ( Juola 1994 , 1997 ; Veale and Way 1997 ; Gough , Way , and Hearne 2002 )", "label": "Background", "metadata": {}}
{"text": "Virpioja et al. ( 2007 ) , Badr et al. ( 2008 ) , Luong et al. ( 2010 ) , Clifton and Sarkar ( 2011 ) , and others are primarily concerned with using morpheme segmentation in SMT , which is a useful approach for dealing with issues of word-formation .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Before using the DCA method , we applied a Russian morphological processor ( Mikheev and Liubushkina 1995 ) to convert each word in the text to its main form : nominative case singular for nouns and adjectives , infinitive for verbs , etc. .", "label": "Uses", "metadata": {}}
{"text": "The result holds for both the MaltParser ( Nivre 2008 ) and the Easy-First Parser ( Goldberg and Elhadad 2010 ) .", "label": "Uses", "metadata": {}}
{"text": "Also relevant is work on the general problems of dialog-act tagging ( Stolcke et al. , 2000 ) , citation analysis ( Lehnert et al. , 1990 ) , and computational rhetorical analysis ( Marcu , 2000 ; Teufel and Moens , 2002 ) .", "label": "Background", "metadata": {}}
{"text": "A common way to combine different models consists of selecting the model that is most confident regarding its decision ( Burke 2002 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Common sense ( as well as the Gricean maxims ; Grice 1975 ) suggests that vague descriptions are preferred by speakers over quantitative ones whenever the additional information provided by a quantitative description is irrelevant to the purpose of the communication .", "label": "Background", "metadata": {}}
{"text": "A similar method is included in PATR-II ( Shieber et al. 1983 ) and can be used to encode lexical rules as binary relations in the CUF system ( Dorre and Eisele 1991 ; Done and Dorna 1993b ) or the TFS system ( Emele and Zajac 1990 ; Emele 1994 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "This description can then be given the standard set-theoretical interpretation of King ( 1989 , 1994 ) . '", "label": "Background", "metadata": {}}
{"text": "Griffiths et al. ( 2007 ) helped pave the path for cognitive-linguistic multimodal research , showing that Latent Dirichlet Allocation outperformed Latent Semantic Analysis ( Deerwester et al. , 1990 ) in the prediction of association norms .", "label": "Background", "metadata": {}}
{"text": "A more flexible approach is used by Reiter and Sripada ( 2002 ) , where users can specify boundary values for attributes like rainfall , specifying , for example , rain counts as moderate above 7 mm/h , as heavy above 20 mm/h , and so on .", "label": "Background", "metadata": {}}
{"text": "Collins and Duffy ( 2002 ) define a kernel over parse trees and apply it to re-ranking the output of a parser , but the resulting feature space is restricted by the need to compute the kernel efficiently , and the results are not as good as Collins ' previous work on re-ranking using a finite set of features ( Collins , 2000 ) .", "label": "Background", "metadata": {}}
{"text": "The shallow parser used is the SNoW-based CSCL parser ( Punyakanok and Roth , 2001 ; Munoz et al. , 1999 ) .", "label": "Uses", "metadata": {}}
{"text": "In practice , perceptron-type algorithms are often applied in a batch learning scenario , i.e. , the algorithm is applied for K epochs to a training sample of size T and then used for prediction on an unseen test set ( Freund and Schapire , 1999 ; Collins , 2002 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Table 2 shows the results on identifying all phrases -- chunking in CoNLL2000 ( Tjong Kim Sang and Buchholz , 2000 ) terminology .", "label": "Uses", "metadata": {}}
{"text": "Perhaps some variation of multi-level bulleted lists , appropriately integrated with interface elements for expanding and hiding items , might provide physicians a better overview of the information landscape ; see , for example , Demner-Fushman and Lin ( 2006 ) .", "label": "Background", "metadata": {}}
{"text": "Pierce and Cardie ( 2001 ) have shown , in the context of base noun identification , that combining sample selection and cotraining can be an effective learning framework for large-scale training .", "label": "Background", "metadata": {}}
{"text": "\u00e2\u0080\u00a2 The regular TBL , as described in section 2 ; \u00e2\u0080\u00a2 An improved version of TBL , which makes extensive use of indexes to speed up the rules ' update ; \u00e2\u0080\u00a2 The FastTBL algorithm ; \u00e2\u0080\u00a2 The ICA algorithm ( Hepple , 2000 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "For example , Jokinen and Ragni ( 2007 ) and Jokinen et al. ( 2008 ) find that machine learning algorithms can be trained to recognise some of the functions of head movements , while Reidsma et al. ( 2009 ) show that there is a dependence between focus of attention and assignment of dialogue act labels .", "label": "Background", "metadata": {}}
{"text": "Unless it is desired to intentionally filter these out as being outside of the new domain , one can insert some arbitrarily small probability for these arcs , using , for example , an N-gram back-off model ( Katz 1987 ) .", "label": "Background", "metadata": {}}
{"text": "feature Cohen 's k corrected k agreement 73.59 98.74 dial act 84.53 98.87 turn 73.52 99.16 Table 2 : Inter-coder agreement on feedback expression annotation Although researchers do not totally agree on how to measure agreement in various types of annotated data and on how to interpret the resulting figures , see Artstein and Poesio ( 2008 ) , it is usually assumed that Cohen 's kappa figures over 60 are good while those over 75 are excellent ( Fleiss , 1971 ) .", "label": "Background", "metadata": {}}
{"text": "Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories ( Krovetz , 1993 ; Kraaij and Pohlmann , 1996 ; Tzoukermann et al. , 1997 ) .", "label": "Background", "metadata": {}}
{"text": "The lexicon is used to mediate and map between a language-independent domain model and a language-dependent ontology widely used in NLG , the Upper Model ( Bateman 1990 ) .", "label": "Background", "metadata": {}}
{"text": "ImageNet is a large-scale and widely used image database , built on top of WordNet , which maps words into groups of images , called synsets ( Deng et al. , 2009 ) .", "label": "Uses", "metadata": {}}
{"text": "Two applications that , like help-desk , deal with question -- answer pairs are : summarization of e-mail threads ( Dalli , Xia , and Wilks 2004 ; Shrestha and McKeown 2004 ) , and answer extraction in FAQs ( Frequently Asked Questions ) ( Berger and Mittal 2000 ;", "label": "CompareOrContrast", "metadata": {}}
{"text": "The retrieval process relies on the vector space model ( Salton , 1989 ) , with the cosine measure expressing the similarity between a query and a document .", "label": "Uses", "metadata": {}}
{"text": "For right-branching structures , the leftcorner ancestor is the parent , conditioning on which has been found to be beneficial ( Johnson , 1998 ) , as has conditioning on the left-corner child ( Roark and Johnson , 1999 ) .", "label": "Background", "metadata": {}}
{"text": "A few others incorporate various measures of inter-document similarity between the texts to be labeled ( Agarwal and Bhattacharyya , 2005 ; Pang and Lee , 2005 ; Goldberg and Zhu , 2006 ) .", "label": "Background", "metadata": {}}
{"text": "This is similar to `` one sense per collocation '' idea of Yarowsky ( 1993 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "This system has been successfully tested with the development of plug-ins supporting instant messaging , distributed video encoding ( Hughes and Walkerdine , 2005 ) , distributed virtual worlds ( Hughes et al. , 2005 ) and digital library management ( Walkerdine and Rayson , 2004 ) .", "label": "Background", "metadata": {}}
{"text": "be found in figure 2 , which is similar with that in Moschitti et al. ( 2005 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Riehemann 1993 ; Oliva 1994 ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "These translations gave rise to a number of automatically constructed linguistic resources : ( 1 ) the original ( source , target ) phrasal translation pairs , ( 2 ) the marker lexicon , ( 3 ) the gen11 Thanks are due to one of the anonymous reviewers for pointing out that our wEBMT system , seeded with input from multiple translation systems , with a postvalidation process via the Web ( amounting to an n-gram target language model ) , in effect forms a multiengine MT system as described by Frederking and Nirenburg ( 1994 ) , Frederking et al. ( 1994 ) , and Hogan and Frederking ( 1998 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Discriminative approaches ( especially SVMs ) have been shown to be very effective for many supervised classification tasks ; see , for example , ( Joachims , 1998 ; Ng and Jordan , 2001 ) .", "label": "Background", "metadata": {}}
{"text": "A few others incorporate various measures of inter-document similarity between the texts to be labeled ( Agarwal and Bhattacharyya , 2005 ; Pang and Lee , 2005 ; Goldberg and Zhu , 2006 ) .", "label": "Background", "metadata": {}}
{"text": "For instance , when building translation units in EBMT approaches ( Richardson et al. , 2001 ) , ( Aramaki , 2001 ) , ( AlAdhaileh & Tang , 1999 ) , ( Sato & Nagao , 1990 ) , ( Sato , 1991 ) , ( Sadler & Vendelmans , 1990 ) , etc. , where S-SSTC can be used to represent the entries of the BKB or when S-SSTC used as an annotation schema to find the translation correspondences ( lexical and structural correspondences ) for transferrules ' extraction from parallel parsed corpus ( Menezes & Richardson , 2001 ) , ( Watanabe et al. ,", "label": "Background", "metadata": {}}
{"text": "More details on how the structural divergences described in ( Don , 1994 ) can be accounted for using our formalism can be found in ( Nasr et al. , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "At present , the system takes into consideration the number of incorrect answers received in response to the current question and the number of uninterpretable answers .1 In addition to a remediation policy , the tutorial planner implements an error recovery policy ( Dzikovska et al. , 2009 ) .", "label": "Uses", "metadata": {}}
{"text": "Similar things hold for multifaceted properties like intelligence ( Kamp 1975 ) .", "label": "Background", "metadata": {}}
{"text": "( Och and Ney , 2002 ; Blunsom et al. , 2008 ) used maximum likelihood estimation to learn weights for MT. ( Och , 2003 ; Moore and Quirk , 2008 ; Zhao and Chen , 2009 ; Galley and Quirk , 2011 ) employed an evaluation metric as a loss function and directly optimized it .", "label": "CompareOrContrast", "metadata": {}}
{"text": "There has been some controversy , at least for simple stemmers ( Lovins , 1968 ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval ( Harman , 1991 ; Krovetz , 1993 ; Hull , 1996 ) .", "label": "Background", "metadata": {}}
{"text": "Rubenstein and Goodenough ( 1965 ) reported an intra-subject correlation of r = .85 for 15 subjects judging the similarity of a subset ( 36 ) of the original 65 word pairs .", "label": "CompareOrContrast", "metadata": {}}
{"text": "More recently , Simard and Langlais ( 2001 ) have proposed the exploitation of TMs at a subsentential level , while Carl , Way , and Sch \u00c2\u00a8 aler ( 2002 ) and Sch \u00c2\u00a8 aler , Way , and Carl ( 2003 , pages 108 -- 109 ) describe how phrasal lexicons might come to occupy a central place in a future hybrid integrated translation environment .", "label": "Background", "metadata": {}}
{"text": "For some adjectives , including the ones that Bierwisch ( 1989 ) called evaluative ( as opposed to dimensional ) , this is clearly inadequate .", "label": "Background", "metadata": {}}
{"text": "WIT has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system ( Nakano et al. , 1999b ) , a video-recording programming system , a schedule management system ( Nakano et al. , 1999a ) , and a weather infomiation system ( Dohsaka et al. , 2000 ) .", "label": "Extends", "metadata": {}}
{"text": "While this is simply irrelevant for general-purpose morphological analyzers , dealing with such phenomena is crucial for any attempt to cope adequately with medical free-texts in an IR setting ( Wolff , 1984 ) .", "label": "Background", "metadata": {}}
{"text": "The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations ( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks .", "label": "Background", "metadata": {}}
{"text": "In English , where the base form is morphologically simpler than the other two , this rule could be argued to follow from Gricean principles ( Grice 1975 ) .", "label": "Background", "metadata": {}}
{"text": "More generally , distributional clustering techniques ( Sch \u00c2\u00a8 utze , 1992 ; Pereira et al. , 1993 ) could be applied to extract semantic classes from the corpus itself .", "label": "Future", "metadata": {}}
{"text": "The use of the web as a corpus for teaching and research on language has been proposed a number of times ( Kilgarriff , 2001 ; Robb , 2003 ; Rundell , 2000 ; Fletcher , 2001 , 2004b ) and received a special issue of the journal Computational Linguistics ( Kilgarriff and Grefenstette , 2003 ) .", "label": "Background", "metadata": {}}
{"text": "\u00e2\u0080\u00a2 Only an automatic evaluation was performed , which relied on having model responses ( Berger and Mittal 2000 ; Berger et al. 2000 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar ( HPSG ; Pollard and Sag , 1994 ) as discussed in ( Gotz and Meurers , 1997a ) and ( Meurers and Minnen , 1997 ) .", "label": "Background", "metadata": {}}
{"text": "In Marom and Zukerman ( 2007a ) we identified several systems that resemble ours in that they provide answers to queries .", "label": "Background", "metadata": {}}
{"text": "The problem of handling ill-formed input has been studied by Carbonell and Hayes ( 1983 ) , Granger ( 1983 ) , Jensen et al. ( 1983 ) , Kwasny and Sondheimer ( 1981 ) , Riesbeck and Schank ( 1976 ) , Thompson ( 1980 ) , Weischedel and Black ( 1980 ) , and Weischedel and Sondheimer ( 1983 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Liu et al. ( 2005 ) , Meral et al. ( 2007 ) , Murphy ( 2001 ) , Murphy and Vogel ( 2007 ) and Topkara et al. ( 2006a ) all belong to the syntactic transformation category .", "label": "Background", "metadata": {}}
{"text": "We induced a two-class word-to-word model of translational equivalence from 13 million words of the Canadian Hansards , aligned using the method in ( Gale & Church , 1991 ) .", "label": "Uses", "metadata": {}}
{"text": "Tenny ( 1987 ) observes that accomplishments differ from achievements only in terms of event duration , which is often a question of granularity .", "label": "Background", "metadata": {}}
{"text": "After much exploration , Demner-Fushman et al. ( 2006 ) discovered that it was not practical to annotate PICO entities at the phrase level due to significant unresolvable disagreement and interannotator reliability issues .", "label": "Background", "metadata": {}}
{"text": "The necessity of this kind of merging of arguments has been recognized before : Charniak and McDermott ( 1985 ) call it abductive unification/matching , Hobbs ( 1978 , 1979 ) refers to such operations using the terms knitting or petty conversational implicature .", "label": "Background", "metadata": {}}
{"text": "The OntoNotes-5 .0 dataset , which is released for the CoNLL-2012 Shared Task ( Pradhan et al. , 2012 ) , contains 3,145 annotated documents .", "label": "Uses", "metadata": {}}
{"text": "and Yang et al. ( 2003 ) , as described below .", "label": "CompareOrContrast", "metadata": {}}
{"text": "We apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in ( Forster and Davis , 1984 ; Rastle et al. , 2000 ; Marslen-Wilson et al. , 1994 ; Marslen-Wilson et al. , 2008 ) for Bangla morphologically complex words .", "label": "Uses", "metadata": {}}
{"text": "Recently , several alternative , often quite sophisticated approaches to collective classification have been proposed ( Neville and Jensen , 2000 ; Lafferty et al. , 2001 ; Getoor et al. , 2002 ; Taskar et al. , 2002 ; Taskar et al. , 2003 ; Taskar et al. , 2004 ; McCallum and Wellner , 2004 ) .", "label": "Background", "metadata": {}}
{"text": "\u00e2\u0080\u00a2 Only an automatic evaluation was performed , which relied on having model responses ( Berger and Mittal 2000 ; Berger et al. 2000 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The error rate on sentence boundaries in the Brown corpus was not significantly worse than the lowest quoted before ( Riley 1989 : 0.28 % vs. 0.20 % error rate ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "We follow our previous work ( Hou et al. , 2013b ) and restrict bridging to non-coreferential cases .", "label": "Extends", "metadata": {}}
{"text": "This is in line with our previous findings from ( Prabhakaran et al. , 2014 ) that candidates with higher power attempt to shift topics less often than others when responding to moderators .", "label": "CompareOrContrast", "metadata": {}}
{"text": "As has been previously observed and exploited in the NLP literature ( Pang and Lee , 2004 ; Agarwal and Bhattacharyya , 2005 ; Barzilay and Lapata , 2005 ) , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .", "label": "CompareOrContrast", "metadata": {}}
{"text": "It is analogous to the step in other translation model induction algorithms that sets all probabilities below a certain threshold to negligible values ( Brown et al. , 1990 ; Dagan et al. , 1993 ; Chen , 1996 ) .", "label": "Background", "metadata": {}}
{"text": "Although evaluated on different data sets , this result is consistent with results from previous work ( Gatt and Belz , 2008 ; Gatt et al. , 2009 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "We used the revised experimental setup ( Gurevych , 2005 ) , based on discrete relatedness scores and presentation of word pairs in isolation , that is scalable to the higher number of pairs .", "label": "Uses", "metadata": {}}
{"text": "Robinson , 1982 ; Bobrow , 1978 ) consult relatively small lexicons , typically generated by hand .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In the United States , for example , governmental bodies are providing and soliciting political documents via the Internet , with lofty goals in mind : electronic rulemaking ( eRulemaking ) initiatives involving the `` electronic collection , distribution , synthesis , and analysis of public commentary in the regulatory rulemaking process '' , may `` [ alter ] the citizen-government relationship '' ( Shulman and Schlosberg , 2002 ) .", "label": "Background", "metadata": {}}
{"text": "This will become even more interesting when mappings of our synonym identifiers to a large medical thesaurus ( MeSH , ( NLM , 2001 ) ) are incorporated into our system .", "label": "Future", "metadata": {}}
{"text": "raw length value as a feature , we follow our previous work ( Rubino et al. , 2013 ; Wagner et al. , 2014 ) and create multiple features for length using a decision tree ( J48 ) .", "label": "Extends", "metadata": {}}
{"text": "In some systems such dependencies are learned from labeled examples ( Bikel et al. 1997 ) .", "label": "Background", "metadata": {}}
{"text": "CD for this type of descriptions along the lines of Section 4 is not difficult once relational descriptions are integrated with a standard GRE algorithm ( Krahmer and Theune 2002 , Section 8.6.2 ) : Suppose an initial description is generated describing the set of all those dogs that are in sheds over a given size ( say , size 5 ) ; if this description happens to distinguish an individual dog then this legitimizes the use of the noun phrase the dog in the large shed .", "label": "Background", "metadata": {}}
{"text": "notation of Montague ( 1970 ) is more sophisticated , and may be considered another possibility .", "label": "CompareOrContrast", "metadata": {}}
{"text": "We first identified the most informative unigrams and bigrams using the information gain measure ( Yang and Pedersen 1997 ) , and then selected only the positive outcome predictors using odds ratio ( Mladenic and Grobelnik 1999 ) .", "label": "Uses", "metadata": {}}
{"text": "Perhaps some variation of multi-level bulleted lists , appropriately integrated with interface elements for expanding and hiding items , might provide physicians a better overview of the information landscape ; see , for example , Demner-Fushman and Lin ( 2006 ) .", "label": "Future", "metadata": {}}
{"text": "Nugget F-score has been employed as a metric in the TREC question-answering track since 2003 , to evaluate so-called definition and `` other '' questions ( Voorhees 2003 ) .", "label": "Background", "metadata": {}}
{"text": "Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features ( Basili et al. , 2005a ; Basili et al. , 2005b ; Bloehdorn et al. , 2006 ; Bloehdorn and Moschitti , 2007 ) or shallow semantic trees , ( Giuglea and Moschitti , 2004 ; Giuglea and Moschitti , 2006 ; Moschitti and Bejan , 2004 ; Moschitti et al. , 2007 ; Moschitti , 2008 ; Moschitti et al. , 2008 ) .", "label": "Future", "metadata": {}}
{"text": "In a log-linear parameterization , for example , a prior that penalizes feature strengths far from 1 can be used to do feature selection and avoid overfitting ( Chen and Rosenfeld , 1999 ) .", "label": "Uses", "metadata": {}}
{"text": "This alignment is done on the basis of both length ( Gale and Church [ 7 ] ) and a notion of cognateness ( Simard [ 16 ] ) .", "label": "Uses", "metadata": {}}
{"text": "A more detailed discussion of the various available Arabic tag sets can be found in Habash ( 2010 ) .", "label": "Background", "metadata": {}}
{"text": "The resulting speech understanding system is called the Voice Natural Language Computer with Expectation ( VNLCE , Fink 1983 ) .", "label": "Background", "metadata": {}}
{"text": "In our previous papers ( Zhang and Clark 2011 ; Zhang , Blackwood , and Clark 2012 ) , we applied a set of beams to this structure , which makes it similar to the data structure used for phrase-based MT decoding ( Koehn 2010 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information ( Andrews et al. , 2009 ; Steyvers , 2010 ; Feng and Lapata , 2010b ; Bruni et al. , 2011 ; Silberer and Lapata , 2012 ; Johns and Jones , 2012 ; Bruni et al. , 2012a ; Bruni et al. , 2012b ; Silberer et al. , 2013 ) .", "label": "Background", "metadata": {}}
{"text": "In particular , since we treat each individual speech within a debate as a single `` document '' , we are considering a version of document-level sentiment-polarity classification , namely , automatically distinguishing between positive and negative documents ( Das and Chen , 2001 ; Pang et al. , 2002 ; Turney , 2002 ; Dave et al. , 2003 ) .", "label": "Background", "metadata": {}}
{"text": "A number of alignment techniques have been proposed , varying from statistical methods ( Brown et al. , 1991 ; Gale and Church , 1991 ) to lexical methods ( Kay and Roscheisen , 1993 ; Chen , 1993 ) .", "label": "Background", "metadata": {}}
{"text": "( Michiels ( 1982 ) contains further description and discussion of LDOCE . )", "label": "Background", "metadata": {}}
{"text": "We would also provide a user facility for choosing the right licence for every lexia , following the model of Creative Commons licences ( Lessig , 2004 ) .", "label": "Uses", "metadata": {}}
{"text": "There has been some controversy , at least for simple stemmers ( Lovins , 1968 ; Porter , 1980 ) , about the effectiveness of morphological analysis for document retrieval ( Harman , 1991 ; Krovetz , 1993 ; Hull , 1996 ) .", "label": "Background", "metadata": {}}
{"text": "Generally speaking , we find that the personal public diary metaphor behind blogs ( McNeill , 2005 ) may bring to an unsatisfactory representation of the context .", "label": "Background", "metadata": {}}
{"text": "Most probabilistic translation model reestimation algorithms published to date are variations on the theme proposed by Brown et al. ( 1993b ) .", "label": "Background", "metadata": {}}
{"text": "A number of proposals in the 1990s deliberately limited the extent to which they relied on domain and/or linguistic knowledge and reported promising results in knowledge-poor operational environments ( Dagan and Itai 1990 , 1991 ; Lappin and Leass 1994 ; Nasukawa 1994 ; Kennedy and Boguraev 1996 ; Williams , Harvey , and Preston 1996 ; Baldwin 1997 ; Mitkov 1996 , 1998b ) .", "label": "Background", "metadata": {}}
{"text": "The significance testing is performed by paired bootstrap re-sampling ( Koehn , 2004 ) .", "label": "Uses", "metadata": {}}
{"text": "The system is implemented based on ( Galley et al. , 2006 ) and ( Marcu et al. 2006 ) .", "label": "Uses", "metadata": {}}
{"text": "IGEN uses standard chart generation techniques ( Kay , 1996 ) in its base generator to efficiently produce generation candidates .", "label": "Background", "metadata": {}}
{"text": "Position , subcat frame , phrase type , first word , last word , subcat frame + , predicate , path , head word and its POS , predicate + head word , predicate + phrase type , path to BA and BEI , verb class 3 , verb class + head word , verb class + phrase type , from Xue ( 2008 ) .", "label": "Uses", "metadata": {}}
{"text": "Kinyon and Prolo ( 2002 ) describe a simple tool which uses fine-grained rules to identify the arguments of verb occurrences in the Penn-II Treebank .", "label": "Background", "metadata": {}}
{"text": "Zhu ( 2005 ) maintains a survey of this area .", "label": "Background", "metadata": {}}
{"text": "In the context of word alignment , Deng and Byrne ( 2005 ) use a state-duration HMM in order to model word-to-phrase translations .", "label": "Background", "metadata": {}}
{"text": "Selectional Preferences have also been a recent focus of researchers investigating the learning of paraphrases and inference rules ( Pantel et al. , 2007 ; Roberto et al. , 2007 ) .", "label": "Background", "metadata": {}}
{"text": "Previously LDA has been successfully used to infer unsupervised joint topic distributions over words and feature norms together ( Andrews et al. , 2009 ; Silberer and Lapata , 2012 ) .", "label": "Background", "metadata": {}}
{"text": "Something like this approach is in fact used in some systems ( e.g. , Elhadad and Robin 1992 ; PenMan 1989 ; Hovy 1988a ) .", "label": "Background", "metadata": {}}
{"text": "The emphasis on narrativity takes into account the use of blogs as public diaries on the web , that is still the main current interpretation of this literary genre , or metagenre ( McNeill , 2005 ) .", "label": "Background", "metadata": {}}
{"text": "For example , it would be helpful to consider strong correspondence between certain English and Chinese words , as in ( Wu , 1994 ) .", "label": "Future", "metadata": {}}
{"text": "The system utilizes several large size biological databases including three NCBI databases ( GenPept [ 11 ] , RefSeq [ 12 ] , and Entrez GENE [ 13 ] ) , PSD database from Protein Information Resources ( PIR ) [ 14 ] , and", "label": "Uses", "metadata": {}}
{"text": "While IA is generally thought to be consistent with findings on human language production ( Hermann and Deutsch 1976 ; Levelt 1989 ; Pechmann 1989 ; Sonnenschein 1982 ) , the hypothesis that incrementality is a good model of human GRE seems unfalsifiable until a preference order is specified for the properties on which it operates .", "label": "Background", "metadata": {}}
{"text": "Typical examples are Bulgarian ( Simov et al. , 2005 ; Simov and Osenova , 2003 ) , Chinese ( Chen et al. , 2003 ) , Danish ( Kromann , 2003 ) , and Swedish ( Nilsson et al. , 2005 ) .", "label": "Background", "metadata": {}}
{"text": "\u00e2\u0080\u00a2 A user study was performed , but it was either very small compared to the corpus ( Carmel , Shtalhaim , and Soffer 2000 ; Jijkoun and de Rijke 2005 ) , or the corpus itself was significantly smaller than ours ( Feng et al. 2006 ; Leuski et al. 2006 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Our work on the prosodic phrase status of clause final prepositional phrases , which we discuss below , suggests the existence of a discourse-neutral phrasing that depends on syntactic constituency mediated by string adjacency and length of a potential prosodic phrase .3 Such phrasing provides us with a typical phrasing pattern analogous to the typical phrasal stress patterns examined in Liberman and Prince ( 1977 ) , which `` are often overwhelmed by the chiaroscuro of highlight and background in discourse , but retain the status of null-hypothesis patterns that emerge when Computational Linguistics Volume 16 , Number 3 , September 1990 157 J. Bachenko and E. Fitzpatrick Discourse-Neutral Prosodic Phrasing in English there is no good reason to take some other option '' ( p. 251 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Most DOP models , such as in Bod ( 1993 ) , Goodman ( 1996 ) , Bonnema et al. ( 1997 ) , Sima'an ( 2000 ) and Collins & Duffy ( 2002 ) , use a likelihood criterion in defining the best parse tree : they take ( some notion of ) the most likely ( i.e. most probable ) tree as a candidate for the best tree of a sentence .", "label": "Background", "metadata": {}}
{"text": "Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) [ 18 ] , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase [ 22 ] , Human Nomenclature Database ( HUGO ) [ 23 ] , Online Mendelian Inheritance in Man ( OMIM ) [ 24 ] , and Enzyme Nomenclature Database ( ECNUM ) [ 25 , 26 ] .", "label": "Uses", "metadata": {}}
{"text": "The features can be easily obtained by modifying the TAT extraction algorithm described in ( Liu et al. , 2006 ) .", "label": "Extends", "metadata": {}}
{"text": "Marinov and Hemming ( 2004 ) present preliminary work on the automatic extraction of subcategorization frames for Bulgarian from the BulTreeBank ( Simov , Popova , and Osenova 2002 ) .", "label": "Background", "metadata": {}}
{"text": "The use of the web as a corpus for teaching and research on language has been proposed a number of times ( Kilgarriff , 2001 ; Robb , 2003 ; Rundell , 2000 ; Fletcher , 2001 , 2004b ) and received a special issue of the journal Computational Linguistics ( Kilgarriff and Grefenstette , 2003 ) .", "label": "Background", "metadata": {}}
{"text": "Baroni and Bernardini ( 2004 ) built a corpus by iteratively searching Google for a small set of seed terms .", "label": "Background", "metadata": {}}
{"text": "Expanding on a suggestion of Michiels ( 1982 ) , we classify verbs as Subject Equi , Object Equi , Subject Raising or Object Raising for each sense which has a predicate complement code associated with it .", "label": "Extends", "metadata": {}}
{"text": "For more information on CATiB , see Habash and Roth ( 2009 ) and Habash , Faraj , and Roth ( 2009 ) .", "label": "Background", "metadata": {}}
{"text": "For example , speech repairs , particle omission , and fillers can be dealt with in the framework of unification grammar ( Nakano et al. , 1994 ; Nakano and Shimazu , 1999 ) .", "label": "Future", "metadata": {}}
{"text": "Levenberg et al. ( 2012 ) employed a Bayesian method to learn discontinuous SCFG rules .", "label": "CompareOrContrast", "metadata": {}}
{"text": "We use the same splits as Garrette et al. ( 2014 ) .", "label": "Uses", "metadata": {}}
{"text": "These results are slightly worse than those obtained in previous studies using the same annotation scheme ( Jokinen et al. , 2008 ) , but are still sat -", "label": "CompareOrContrast", "metadata": {}}
{"text": "In Chomsky and Halle ( 1968 ) , this flattening process is not part of the grammar .", "label": "Background", "metadata": {}}
{"text": "For this research , we used a coreference resolution system ( ( Harabagiu and Maiorano , 1999 ) ) that implements different sets of heuristics corresponding to various forms of coreference .", "label": "Uses", "metadata": {}}
{"text": "The work that is most similar to ours is that of Chang et al. ( 2007 ) , who introduced the Constraint Driven Learning algorithm ( CODL ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Fraser ( 2009 ) tried to solve the inflection prediction problem by simply building an SMT system for translating from stems to inflected forms .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Various approaches for computing semantic relatedness of words or concepts have been proposed , e.g. dictionary-based ( Lesk , 1986 ) , ontology-based ( Wu and Palmer , 1994 ; Leacock and Chodorow , 1998 ) , information-based ( Resnik , 1995 ; Jiang and Conrath , 1997 ) or distributional ( Weeds and Weir , 2005 ) .", "label": "Background", "metadata": {}}
{"text": "Xia ( 1999 ) also presents a similar method for the extraction of a TAG from the Penn Treebank .", "label": "Background", "metadata": {}}
{"text": "32 In certain cases an extension of the constraint language with named disjunctions or contexted constraints ( Maxwell and Kaplan 1989 ; Eisele and Dorre 1990 ; Griffith 1996 ) can be used to circumvent constraint propagation .", "label": "Background", "metadata": {}}
{"text": "This article represents an extension of our previous work on unsupervised event coreference resolution ( Bejan et al. 2009 ; Bejan and Harabagiu 2010 ) .", "label": "Extends", "metadata": {}}
{"text": "In addition to headwords , dictionary search through the pronunciation field is available ; Carter ( 1987 ) has merged information from the pronunciation and hyphenation fields , creating an enhanced phonological representation which allows access to entries by broad phonetic class and syllable structure ( Huttenlocher and Zue , 1983 ) .", "label": "Uses", "metadata": {}}
{"text": "Despite this , to date , there has been little work on corpus-based approaches to help-desk response automation ( notable exceptions are Carmel , Shtalhaim , and Soffer 2000 ; Lapalme and Kosseim 2003 ; Bickel and Scheffer 2004 ; Malik , Subramaniam , and Kaushik 2007 ) .", "label": "Background", "metadata": {}}
{"text": "results are based on a corpus of movie subtitles ( Tiedemann 2007 ) , and are consequently shorter sentences , whereas the En \u00e2\u0086\u0092 Es results are based on a corpus of parliamentary proceedings ( Koehn 2005 ) .", "label": "Uses", "metadata": {}}
{"text": "This alignment is obtained by following the same set of rules learned from the development dataset as in ( Zhang and Chai , 2009 ) .", "label": "Uses", "metadata": {}}
{"text": "Most approaches rely on VerbNet ( Kipper et al. , 2000 ) and FrameNet ( Baker et al. , 1998 ) to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions ( Carreras and Marquez , 2004 ; Carreras and Marquez , 2005 ) and also ( Gildea and Jurafsky , 2002 ; Pradhan et al. , 2005 ; Shi and Mihalcea , 2005 ) .", "label": "Background", "metadata": {}}
{"text": "These include devices such as interleaving the components ( McDonald 1983 ; Appelt 1983 ) , backtracking on failure ( Appelt 1985 ; Nogier 1989 ) , allowing the linguistic component to interrogate the planner ( Mann 1983 ; Sondheimer and Nebel 1986 ) , and Hovy 's notion of restrictive ( i.e. , bottom-up ) planning ( Hovy 1988a , 1988c ) .", "label": "Background", "metadata": {}}
{"text": "Bolter ( 1991 ) was the first scholar who stressed the impact of the digital revolution to the medium of writing .", "label": "Background", "metadata": {}}
{"text": "Much of theoretical linguistics can be formulated in a very natural manner as stating correspondences ( translations ) between layers of representation structures ( Rambow & Satta , 1996 ) .", "label": "Background", "metadata": {}}
{"text": "In our previous work ( Tomuro , 2000 ) , we applied this method to a small subset of WordNet nouns and showed potential applicability .", "label": "Extends", "metadata": {}}
{"text": "This has been reported for other languages , too , dependent on the generality of the chosen approach ( J \u00c2\u00a8 appinen and Niemist \u00c2\u00a8 o , 1988 ; Choueka , 1990 ; Popovic and Willett , 1992 ; Ekmekc \u00c2\u00b8 ioglu et al. , 1995 ; Hedlund et al. , 2001 ; Pirkola , 2001 ) .", "label": "Background", "metadata": {}}
{"text": "Specifically , we used Decision Graphs ( Oliver 1993 ) for Doc-Pred , and SVMs ( Vapnik 1998 ) for Sent-Pred .11 Additionally , we used unigrams for clustering documents and sentences , and unigrams and bigrams for predicting document clusters and sentence clusters ( Sections 3.1.2 and 3.2.2 ) .", "label": "Uses", "metadata": {}}
{"text": "To prepare SMT outputs for post-editing , the creators of the corpus used their own WMT10 system ( Potet et al. , 2010 ) , based on the Moses phrase-based decoder ( Koehn et al. , 2007 ) with dense features .", "label": "Uses", "metadata": {}}
{"text": "In particular , ( Gross , 1989 ) lists the converses of some 3 500 predicative nouns .", "label": "Future", "metadata": {}}
{"text": "This is similar to the `` deletion '' strategy employed by Zettlemoyer and Collins ( 2007 ) , but we do it directly in the grammar .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements ( McKeown , 1985 ; Marcu and Echihabi , 2002 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Other work on modeling the meanings of verbs using video recognition has also begun showing great promise ( Mathe et al. , 2008 ; Regneri et al. , 2013 ) .", "label": "Background", "metadata": {}}
{"text": "It has been shown ( Roland and Jurafsky 1998 ) that the subcategorization tendencies of verbs vary across linguistic domains .", "label": "Motivation", "metadata": {}}
{"text": "In the system , we extract both the minimal GHKM rules ( Galley et al. , 2004 ) , and the rules of SPMT Model 1 ( Galley et al. , 2006 ) with phrases up to length L = 5 on the source side .", "label": "Uses", "metadata": {}}
{"text": "Note that this ensures that greater importance is attributed to longer chunks , as is usual in most EBMT systems ( cfXXX Sato and Nagao 1990 ; Veale and Way 1997 ; Carl 1999 ) .7 As an example , consider the translation into French of the house collapsed .", "label": "Background", "metadata": {}}
{"text": "We apply two different priming experiments namely , the cross modal priming and masked priming experiment discussed in ( Forster and Davis , 1984 ; Rastle et al. , 2000 ; Marslen-Wilson et al. , 1994 ; Marslen-Wilson et al. , 2008 ) for Bangla morphologically complex words .", "label": "Uses", "metadata": {}}
{"text": "( Watanabe et al. , 2007 ; Chiang et al. , 2008 ; Hopkins and May , 2011 ) proposed other optimization objectives by introducing a margin-based and ranking-based indirect loss functions .", "label": "Background", "metadata": {}}
{"text": "Such systems extract information from some types of syntactic units ( clauses in ( Fillmore and Atkins , 1998 ; Gildea and Jurafsky , 2002 ; Hull and Gomez , 1996 ) ; noun phrases in ( Hull and Gomez , 1996 ; Rosario et al. , 2002 ) ) .", "label": "Background", "metadata": {}}
{"text": "The changes made were inspired by those described in Stetina and Nagao ( 1997 , page 75 ) .", "label": "Motivation", "metadata": {}}
{"text": "The grammar code system used in LDOCE is based quite closely on the descriptive grammatical framework of Quirk et al. ( 1972 , 1985 ) .", "label": "Extends", "metadata": {}}
{"text": "Our task was made possible by the fact that while far from being a database in the accepted sense of the word , the LDOCE typesetting tape is the only truly computerised dictionary of English ( Michiels , 1983 ) .", "label": "Background", "metadata": {}}
{"text": "Using the GHKM algorithm ( Galley et al. 2004 ) , we can get two different STSG derivations from the two U-trees based on the fixed word alignment .", "label": "Uses", "metadata": {}}
{"text": "Task properties Determining whether or not a speaker supports a proposal falls within the realm of sentiment analysis , an extremely active research area devoted to the computational treatment of subjective or opinion-oriented language ( early work includes Wiebe and Rapaport ( 1988 ) , Hearst ( 1992 ) , Sack ( 1994 ) , and Wiebe ( 1994 ) ; see Esuli ( 2006 ) for an active bibliography ) .", "label": "Background", "metadata": {}}
{"text": "Our HDP extension is also inspired from the Bayesian model proposed by Haghighi and Klein ( 2007 ) .", "label": "Motivation", "metadata": {}}
{"text": "The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations ( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks .", "label": "Background", "metadata": {}}
{"text": "To combine the phrasal matching scores obtained at each n-gram level , and optimize their relative weights , we trained a Support Vector Machine classifier , SVMlight ( Joachims , 1999 ) , using each score as a feature .", "label": "Uses", "metadata": {}}
{"text": "Against the background of a growing interest in multilingual NLP , multilingual anaphora / coreference resolution has gained considerable momentum in recent years ( Aone and McKee 1993 ; Azzam , Humphreys , and Gaizauskas 1998 ; Harabagiu and Maiorano 2000 ; Mitkov and Barbu 2000 ; Mitkov 1999 ; Mitkov and Stys 1997 ; Mitkov , Belguith , and Stys 1998 ) .", "label": "Background", "metadata": {}}
{"text": "From an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition ( Pacak et al. , 1980 ; Norton and Pacak , 1983 ; Wolff , 1984 ; Wingert , 1985 ; Dujols et al. , 1991 ; Baud et al. , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "This approach has occasionally been taken , as in Kantrowitz and Bates ( 1992 ) and Danlos ( 1987 ) and , at least implicitly , in Paris and Scott ( 1994 ) and Delin et al. ( 1994 ) ; however , under this approach , all of the flexibility and simplicity of modular design is lost .", "label": "Background", "metadata": {}}
{"text": "Typical examples are Bulgarian ( Simov et al. , 2005 ; Simov and Osenova , 2003 ) , Chinese ( Chen et al. , 2003 ) , Danish ( Kromann , 2003 ) , and Swedish ( Nilsson et al. , 2005 ) .", "label": "Background", "metadata": {}}
{"text": "We use a standard split of 268 training documents , 68 development documents , and 106 testing documents ( Culotta et al. , 2007 ; Bengtson and Roth , 2008 ) .", "label": "Uses", "metadata": {}}
{"text": "An alternative representation based on Liberman and Prince ( 1977 ) is presented in Selkirk ( 1984 ) , which contends that prosody , including prosodic phrasing , is more properly represented as a grid instead of a tree .", "label": "CompareOrContrast", "metadata": {}}
{"text": "For the joint segmentation and POS-tagging task , we present a novel solution using the framework in this article , and show that it gives comparable accuracies to our previous work ( Zhang and Clark 2008a ) , while being more than an order of magnitude faster .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Since then this idea has been applied to several tasks , including word sense disambiguation ( Yarowsky 1995 ) and named-entity recognition ( Cucerzan and Yarowsky 1999 ) .", "label": "Background", "metadata": {}}
{"text": "However , rather than output this wrong translation directly , we use a post hoc validation and ( if required ) correction process based on Grefenstette ( 1999 ) .", "label": "Uses", "metadata": {}}
{"text": "Most approaches rely on VerbNet ( Kipper et al. , 2000 ) and FrameNet ( Baker et al. , 1998 ) to provide associations between verbs and semantic roles , that are then mapped onto the current instance , as shown by the systems competing in semantic role labelling competitions ( Carreras and Marquez , 2004 ; Carreras and Marquez , 2005 ) and also ( Gildea and Jurafsky , 2002 ; Pradhan et al. , 2005 ; Shi and Mihalcea , 2005 ) .", "label": "Background", "metadata": {}}
{"text": "The version proposed here combines a basic insight from Lewin ( 1990 ) with higher-order unification to give an analysis that has a strong resemblance to that proposed in Pereira ( 1990 , 1991 ) , with some differences that are commented on below .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Liang et al. ( 2006 ) presented a perceptron-based algorithm for learning the phrase-translation parameters in a statistical machine translation system .", "label": "CompareOrContrast", "metadata": {}}
{"text": "All experiments have been performed using MaltParser ( Nivre et al. , 2006 ) , version 0.4 , which is made available together with the suite of programs used for preand post-processing .1", "label": "Uses", "metadata": {}}
{"text": "One area of current interest concerns the left-to-right arrangement of premodifying adjectives within an NP ( e.g. , Shaw and Hatzivassiloglou 1999 ; Malouf 2000 ) .", "label": "Background", "metadata": {}}
{"text": "Better results would be expected by combining the PCFG-LA parser with discriminative reranking approaches ( Charniak and Johnson , 2005 ; Huang , 2008 ) for self training .", "label": "Future", "metadata": {}}
{"text": "Some researchers ( Cucerzan , 2007 ; Nguyen and Cao , 2008 ) have explored the use of Wikipedia information to improve the disambiguation process .", "label": "Background", "metadata": {}}
{"text": "Others have applied the NLP technologies of near-duplicate detection and topic-based text categorization to politically oriented text ( Yang and Callan , 2005 ; Purpura and Hillard , 2006 ) .", "label": "Background", "metadata": {}}
{"text": "We chose to follow Ng and Low ( 2004 ) and split the sentences evenly to facilitate further comparison .", "label": "Uses", "metadata": {}}
{"text": "The last years have seen considerable advances in the field of anaphora resolution , but a number of outstanding issues either remain unsolved or need more attention and , as a consequence , represent major challenges to the further development of the field ( Mitkov 2001a ) .", "label": "Future", "metadata": {}}
{"text": "Using an accumulator passing technique ( O'Keefe 1990 ) , we ensure that upon execution of a call to the interaction predicate q_1 a new lexical entry is derived as the result of successive application of a number of lexical rules .", "label": "Uses", "metadata": {}}
{"text": "However , most strategies are based on `` internal '' or `` external methods '' ( Grabar and Zweigenbaum , 2002 ) , i.e. methods that rely on the form of terms or on the information gathered from contexts .", "label": "CompareOrContrast", "metadata": {}}
{"text": "With the exception of ( Fung , 1995b ) , previous methods for automatically constructing statistical translation models begin by looking at word cooccurrence frequencies in bitexts ( Gale & Church , 1991 ; Kumano & Hirakawa , 1994 ; Fung , 1995a ; Melamed , 1995 ) .", "label": "Background", "metadata": {}}
{"text": "A substring in the sentence that corresponds to a node in the representation tree is denoted by assigning the interval of the substring to SNODE of 2 These definitions are based on the discussion in ( Tang , 1994 ) and Boitet & Zaharin ( 1988 ) .", "label": "Uses", "metadata": {}}
{"text": "The Web People Search task , as defined in the first WePS evaluation campaign ( Artiles et al. , 2007 ) , consists of grouping search results for a given name according to the different people that share it .", "label": "Background", "metadata": {}}
{"text": "Although this is only true in cases where y occurs in an upward monotone context ( MacCartney and Manning , 2007 ) , in practice genuine contradictions between y-values sharing a meronym relationship are extremely rare .", "label": "Motivation", "metadata": {}}
{"text": "We use the same data setting with Xue ( 2008 ) , however a bit different from Xue and Palmer ( 2005 ) .", "label": "Uses", "metadata": {}}
{"text": "The ConTroll grammar development system as described in ( Gotz and Meurers , 1997b ) implements the above mentioned techniques for compiling an HPSG theory into typed feature grammars .", "label": "Background", "metadata": {}}
{"text": "After calculating the raw score of each sentence , we use a modified version of the Adaptive Greedy Algorithm by Filatova and Hatzivassiloglou ( 2004 ) to penalize redundant sentences in cohesive clusters .", "label": "Uses", "metadata": {}}
{"text": "Therefore , in order to be able to incorporate long-range dependencies in our models , we chose to adopt a re-ranking approach ( Collins 2000 ) , which selects from likely assignments generated by a model which makes stronger independence assumptions .", "label": "Uses", "metadata": {}}
{"text": "One , the VOYAGER domain ( Zue et al. 1990 ) , answers questions about places of interest in an urban area , in our case , the vicinity of MIT and Harvard University .", "label": "Uses", "metadata": {}}
{"text": "In the seminal work by Rubenstein and Goodenough ( 1965 ) , similarity judgments were obtained from 51 test subjects on 65 noun pairs written on paper cards .", "label": "Background", "metadata": {}}
{"text": "( Och and Ney , 2002 ; Blunsom et al. , 2008 ) used maximum likelihood estimation to learn weights for MT. ( Och , 2003 ; Moore and Quirk , 2008 ; Zhao and Chen , 2009 ; Galley and Quirk , 2011 ) employed an evaluation metric as a loss function and directly optimized it .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Jackendoff ( 1983 , p. 14 ) writes `` it would be perverse not to take as a working assumption that language is a relatively efficient and accurate encoding of the information it conveys . ''", "label": "CompareOrContrast", "metadata": {}}
{"text": "See also ( Colmerauer , 1982 ; Naish , 1986 ) .", "label": "Background", "metadata": {}}
{"text": "Such a component would serve as the first stage of a clinical question answering system ( Demner-Fushman and Lin , 2005 ) or summarization system ( McKeown et al. , 2003 ) .", "label": "Future", "metadata": {}}
{"text": "It is therefore no surprise that early attempts at response automation were knowledge-driven ( Barr and Tessler 1995 ; Watson 1997 ; Delic and Lahaix 1998 ) .", "label": "Background", "metadata": {}}
{"text": "For example , the suite of LT tools ( Mikheev et al. , 1999 ; Grover et al. , 2000 ) perform tokenization , tagging and chunking on XML marked-up text directly .", "label": "Background", "metadata": {}}
{"text": "To retrieve translation examples for a test sentence , ( Watanabe and Sumita , 2003 ) defined a metric based on the combination of edit distance and TF-IDF ( Manning and Sch \u00c2\u00a8 utze , 1999 ) as follows :", "label": "Uses", "metadata": {}}
{"text": "By using the EM algorithm ( Dempster et al. , 1977 ) , they can guarantee convergence towards the globally optimum parameter set .", "label": "Background", "metadata": {}}
{"text": "Previous work has developed various approaches for grounded semantics mainly for the reference resolution task , i.e. , identifying visual objects in the environment given language descriptions ( Dhande , 2003 ; Gorniak and Roy , 2004 ; Tenbrink and Moratz , 2003 ; Siebert and Schlangen , 2008 ; Liu et al. , 2012 ) .", "label": "Extends", "metadata": {}}
{"text": "In most recent research , NEs ( person , location and organisations ) are extracted from the text and used as a source of evidence to calculate the similarity between documents - see for instance ( Blume , 2005 ; Chen and Martin , 2007 ; Popescu and Magnini , 2007 ; Kalashnikov et al. , 2007 ) .", "label": "Background", "metadata": {}}
{"text": "To provide the required configurability in the static version of the code we will use policy templates ( Alexandrescu , 2001 ) , and for the dynamic version we will use configuration classes .", "label": "Uses", "metadata": {}}
{"text": "Lee et al. ( 2003 ) demonstrates a technique for segmenting Arabic text and uses it as a morphological processing step in machine translation .", "label": "Uses", "metadata": {}}
{"text": "In informal experiments described elsewhere ( Melamed 1995 ) , I found that the G2 statistic suggested by Dunning ( 1993 ) slightly outperforms 02 .", "label": "Extends", "metadata": {}}
{"text": "Due to their remarkable ability to incorporate context structure information and long distance reordering into the translation process , tree-based translation models have shown promising progress in improving translation quality ( Liu et al. , 2006 , 2009 ; Quirk et al. , 2005 ; Galley et al. , 2004 , 2006 ; Marcu et al. , 2006 ; Shen et al. , 2008 ; Zhang et al. , 2011b ) .", "label": "Background", "metadata": {}}
{"text": "15 Hinrichs and Nakazawa ( 1996 ) show that the question of whether the application criterion of lexical rules should be a subsumption or a unification test is an important question deserving of more attention .", "label": "Background", "metadata": {}}
{"text": "Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features ( Basili et al. , 2005a ; Basili et al. , 2005b ; Bloehdorn et al. , 2006 ; Bloehdorn and Moschitti , 2007 ) or shallow semantic trees , ( Giuglea and Moschitti , 2004 ; Giuglea and Moschitti , 2006 ; Moschitti and Bejan , 2004 ; Moschitti et al. , 2007 ; Moschitti , 2008 ; Moschitti et al. , 2008 ) .", "label": "Future", "metadata": {}}
{"text": "Third , the paradigm of evidence-based medicine ( Sackett et al. 2000 ) provides a task-based model of the clinical information-seeking process .", "label": "Background", "metadata": {}}
{"text": "Koehn and Hoang ( 2007 ) introduced factored SMT .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Both systems are built around from the maximum-entropy technique ( Berger et al. , 1996 ) .", "label": "Uses", "metadata": {}}
{"text": "We chose the adjectives as follows : we first compiled a list of all the polysemous adjectives mentioned in the lexical semantics literature ( Vendler , 1968 ; Pustejovsky , 1995 ) .", "label": "Uses", "metadata": {}}
{"text": "Undesirable consequences of this fact have been termed `` label bias '' ( Lafferty et al. , 2001 ) .", "label": "Background", "metadata": {}}
{"text": "We rephrase the method of Grimley-Evans ( 1997 ) as follows : First , we construct the approximating finite automaton according to the unparameterized RTN method above .", "label": "Uses", "metadata": {}}
{"text": "The work is carried out in order to assist terminographers in the enrichment of a dictionary on computing that includes collocational information ( L'Homme , 2004 ) .", "label": "Motivation", "metadata": {}}
{"text": "Riehemann 1993 ; Oliva 1994 ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "We use an in-house statistical tagger ( based on ( Church , 1988 ) ) to tag the text in which the unknown word occurs .", "label": "Uses", "metadata": {}}
{"text": "There are very few reported attempts at corpus-based automation of help-desk responses ( Carmel , Shtalhaim , and Soffer 2000 ; Lapalme and Kosseim 2003 ; Bickel and Scheffer 2004 ; Malik , Subramaniam , and Kaushik 2007 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Both tasks are performed with a statistical framework : the mention detection system is similar to the one presented in ( Florian et al. , 2004 ) and the coreference resolution system is similar to the one described in ( Luo et al. , 2004 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The disambiguation of person names in Web results is usually compared to two other Natural Language Processing tasks : Word Sense Disambiguation ( WSD ) ( Agirre and Edmonds , 2006 ) and Cross-document Coreference ( CDC ) ( Bagga and Baldwin , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Our own work ( Wang and Callison-Burch , 2011 ) extends the first idea to paraphrase fragment extraction on monolingual parallel and comparable corpora .", "label": "Extends", "metadata": {}}
{"text": "Current state-of-the-art statistical parsers ( Collins 1999 ; Charniak 2000 ) are all trained on large annotated corpora such as the Penn Treebank ( Marcus , Santorini , and Marcinkiewicz 1993 ) .", "label": "Background", "metadata": {}}
{"text": "Although the parser only derives projective graphs , the fact that graphs are labeled allows non-projective dependencies to be captured using the pseudoprojective approach of Nivre and Nilsson ( 2005 ) .", "label": "Background", "metadata": {}}
{"text": "Riehemann 1993 ; Oliva 1994 ; Frank 1994 ; Opalka 1995 ; Sanfilippo 1995 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The idea resurfaced forcefully at several points in the more recent history of linguistic research ( Tesni`ere , 1959 ; Gruber , 1965 ; Fillmore , 1968 ) .", "label": "Background", "metadata": {}}
{"text": "A detailed introduction to the SBD problem can be found in Palmer and Hearst ( 1997 ) .", "label": "Background", "metadata": {}}
{"text": "The BEETLE II system architecture is designed to overcome these limitations ( Callaway et al. , 2007 ) .", "label": "Background", "metadata": {}}
{"text": "For the evaluation of the results we use the BLEU score ( Papineni et al. , 2001 ) .", "label": "Uses", "metadata": {}}
{"text": "This design idea was adopted from TANKA ( Barker et al. , 1997b ) .", "label": "Uses", "metadata": {}}
{"text": "The problem of handling ill-formed input has been studied by Carbonell and Hayes ( 1983 ) , Granger ( 1983 ) , Jensen et al. ( 1983 ) , Kwasny and Sondheimer ( 1981 ) , Riesbeck and Schank ( 1976 ) , Thompson ( 1980 ) , Weischedel and Black ( 1980 ) , and Weischedel and Sondheimer ( 1983 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In addition to its explanatory capacity , this symbolic acquisition technique has obtained good results for other acquisition tasks when compared to existing statistical techniques ( Bouillon et al. , 2002 ) .", "label": "Motivation", "metadata": {}}
{"text": "The context of a current token ti is clearly one of the most important features in predicting whether ti is a mention or not ( Florian et al. , 2004 ) .", "label": "Background", "metadata": {}}
{"text": "Features using the word context ( left and right tokens ) have been shown to be very helpful in coreference resolution ( Luo et al. , 2004 ) .", "label": "Uses", "metadata": {}}
{"text": "Here , the PET and GR kernel perform similar : this is different from the results of ( Nguyen et al. , 2009 ) where GR performed much worse than PET for ACE data .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In modern syntactic theories ( e.g. , lexical-functional grammar [ LFG ] [ Kaplan and Bresnan 1982 ; Bresnan 2001 ; Dalrymple 2001 ] , head-driven phrase structure grammar [ HPSG ] [ Pollard and Sag 1994 ] , tree-adjoining grammar [ TAG ] [ Joshi 1988 ] , and combinatory categorial grammar [ CCG ] [ Ades and Steedman 1982 ] ) , the lexicon is the central repository for much morphological , syntactic , and semantic information .", "label": "Background", "metadata": {}}
{"text": "This is where robust syntactic systems like SATZ ( Palmer and Hearst 1997 ) or the POS tagger reported in Mikheev ( 2000 ) , which do not heavily rely on word capitalization and are not sensitive to document length , have an advantage .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Our work is inspired by the latent left-linking model in Chang et al. ( 2013 ) and the ILP formulation from Chang et al. ( 2011 ) .", "label": "Background", "metadata": {}}
{"text": "For example , Radzinsky ( 1991 ) proves that Chinese numerals such as wu zhao zhao zhao zhao zhao wu zhao zhao zhao zhao wu zhao zhao zhao wu zhao zhao wu zhao , for the number 5000000000000000005000000000000005000000000005000000005000 , are not context-free , which implies that Chinese is not a context-free language and thus might parse in exponential worst-case time .", "label": "Background", "metadata": {}}
{"text": "Barzilay and McKeown ( 2001 ) also note that the applicability of paraphrases is strongly influenced by context .", "label": "Background", "metadata": {}}
{"text": "Promising features for classification include part of speech , frequency of co-occurrence , relative word position , and translational entropy ( Melamed , 1997 ) .", "label": "Future", "metadata": {}}
{"text": "like information extraction ( Yates and Etzioni , 2009 ) and textual entailment ( Berant et al. , 2010 ) .", "label": "Background", "metadata": {}}
{"text": "In a final processing stage , we generalize over the marker lexicon following a process found in Block ( 2000 ) .", "label": "Uses", "metadata": {}}
{"text": "One approach to this problem consists in defining , within the Cut-free atomic-id space , normal form derivations in which the succession of rule application is regulated ( Konig 1989 , Hepple 1990 , Hendriks 1993 ) .", "label": "Background", "metadata": {}}
{"text": "McKnight and Srinivasan ( 2003 ) have previously examined the task of categorizing sentences in medical abstracts using supervised discriminative machine learning techniques .", "label": "CompareOrContrast", "metadata": {}}
{"text": "For complementing this database and for converse constructions , the LADL tables ( Gross , 1975 ) can furthermore be resorted to , which list detailed syntactico-semantic descriptions for 5 000 verbs and 25 000 verbal expressions .", "label": "Future", "metadata": {}}
{"text": "These operations are not domain-specific and are similar to those of previous aggregation components ( Rambow and Korelsky ,1992 ; Shaw , 1998 ; Danlos , 2000 ) , although the various MERGE operations are , to our knowledge , novel in this form .", "label": "Background", "metadata": {}}
{"text": "Following construction of the marker lexicon , the ( source , target ) chunks are generalized further using a methodology based on Block ( 2000 ) to permit a limited form of insertion in the translation process .", "label": "Uses", "metadata": {}}
{"text": "Recent developments in linguistics , and especially on grammatical theory -- for example , Generalised Phrase Structure Grammar ( GPSG ) ( Gazdar et al. , 1985 ) , Lexical Functional Grammar ( LFG ) ( Kaplan and Bresnan , 1982 ) -- and on natural language parsing frameworks -- for example , Functional Unification Grammar ( FUG ) ( Kay , 1984a ) , PATR-II ( Shieber , 1984 ) -- make it feasible to consider the implementation of efficient systems for the syntactic analysis of substantial fragments of natural language .", "label": "Background", "metadata": {}}
{"text": "The first direct application of parse forest in translation is our previous work ( Mi et al. , 2008 ) which translates a packed forest from a parser ; it is also the base system in our experiments ( see below ) .", "label": "Extends", "metadata": {}}
{"text": "4 This interpretation of the signature is sometimes referred to as closed world ( Gerdemann and King 1994 ; Gerdemann 1995 ) .", "label": "Background", "metadata": {}}
{"text": "In their Gaijin system , Veale and Way ( 1997 ) give a result of 63 % accurate translations obtained for English \u00e2\u0088\u0092 > German on a test set of 791 sentences from CorelDRAW manuals .", "label": "CompareOrContrast", "metadata": {}}
{"text": "This method can be generalized , inspired by Stolcke and Segal ( 1994 ) , who derive N-gram probabilities from stochastic context-free grammars .", "label": "Background", "metadata": {}}
{"text": "The system was trained on the Penn Treebank ( Marcus et al. , 1993 ) WSJ Sections 221 and tested on Section 23 ( Table 1 ) , same as used by Magerman ( 1995 ) , Collins ( 1997 ) , and Ratnaparkhi ( 1997 ) , and became a common testbed .", "label": "CompareOrContrast", "metadata": {}}
{"text": "This approach has now gained wide usage , as exemplified by the work of Collins ( 1996 , 1999 ) , Charniak ( 1996 , 1997 ) , Johnson ( 1998 ) , Chiang ( 2000 ) , and many others .", "label": "Motivation", "metadata": {}}
{"text": "de URL : http://www.sfs.nphil.uni-tuebingen.de/sfb / b4home.html 1 This is , for example , the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement ( Hinrichs and Nakazawa 1989 ) that also use lexical rules such as the Complement Extraction Lexical Rule ( Pollard and Sag 1994 ) or the Complement Cliticization Lexical Rule ( Miller and Sag 1993 ) to operate on those raised elements .", "label": "Background", "metadata": {}}
{"text": "Research that is more similar in goal to that outlined in this paper is Vosse ( Vosse , 1992 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Table 5 shows our mapping from publication type and MeSH headings to evidence grades based on principles defined in the Strength of Recommendations Taxonomy ( Ebell et al. 2004 ) .", "label": "Uses", "metadata": {}}
{"text": "While we have observed reasonable results with both G2 and Fisher 's exact test , we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information ( MI ) measure ( Church and Hanks 1990 ) :", "label": "Uses", "metadata": {}}
{"text": "From an IR view , a lot of specialized research has already been carried out for medical applications , with emphasis on the lexico-semantic aspects of dederivation and decomposition ( Pacak et al. , 1980 ; Norton and Pacak , 1983 ; Wolff , 1984 ; Wingert , 1985 ; Dujols et al. , 1991 ; Baud et al. , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "The Gsearch system ( Corley et al. , 2001 ) also selects sentences by syntactic criteria from large on-line text collections .", "label": "Background", "metadata": {}}
{"text": "See also the work of Byrd and Chodorow ( 1985 ) , which considers computer-based pronunciation by analogy but does not mention the possible application to text-to-speech synthesis .", "label": "Background", "metadata": {}}
{"text": "Some methods are based on likelihood ( Och and Ney , 2002 ; Blunsom et al. , 2008 ) , error rate ( Och , 2003 ; Zhao and Chen , 2009 ; Pauls et al. , 2009 ; Galley and Quirk , 2011 ) , margin ( Watanabe et al. , 2007 ; Chiang et al. , 2008 ) and ranking ( Hopkins and May , 2011 ) , and among which minimum error rate training ( MERT ) ( Och , 2003 ) is the most popular one .", "label": "Background", "metadata": {}}
{"text": "Numerous previous pseudodisambiguation evaluations only include arguments that occur between 30 and 3000 times ( Erk , 2007 ; Keller and Lapata , 2003 ; Rooth et al. , 1999 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "\u00e2\u0080\u00a2 cross-language information retrieval ( e.g. , McCarley 1999 ) , \u00e2\u0080\u00a2 multilingual document filtering ( e.g. , Oard 1997 ) , \u00e2\u0080\u00a2 computer-assisted language learning ( e.g. , Nerbonne et al. 1997 ) , \u00e2\u0080\u00a2 certain machine-assisted translation tools ( e.g. , Macklovitch 1994 ; Melamed 1996a ) , \u00e2\u0080\u00a2 concordancing for bilingual lexicography ( e.g. , Catizone , Russell , and Warwick 1989 ; Gale and Church 1991 ) ,", "label": "Background", "metadata": {}}
{"text": "\u00e2\u0080\u00a2 language learning ( Green 1979 ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 ) \u00e2\u0080\u00a2 monolingual grammar induction ( Juola 1998 ) \u00e2\u0080\u00a2 grammar optimization ( Juola 1994 ) \u00e2\u0080\u00a2 insights into universal grammar ( Juola 1998 ) \u00e2\u0080\u00a2 machine translation ( Juola 1994 , 1997 ; Veale and Way 1997 ; Gough , Way , and Hearne 2002 )", "label": "Background", "metadata": {}}
{"text": "Notable early papers on graph-based semisupervised learning include Blum and Chawla ( 2001 ) , Bansal et al. ( 2002 ) , Kondor and Lafferty ( 2002 ) , and Joachims ( 2003 ) .", "label": "Background", "metadata": {}}
{"text": "As a result , researchers have re-adopted the once-popular knowledge-rich approach , investigating a variety of semantic knowledge sources for common noun resolution , such as the semantic relations between two NPs ( e.g. , Ji et al. ( 2005 ) ) , their semantic similarity as computed using WordNet ( e.g. , Poesio et al. ( 2004 ) ) or Wikipedia ( Ponzetto and Strube , 2006 ) , and the contextual role played by an NP ( see Bean and Riloff ( 2004 ) ) .", "label": "Background", "metadata": {}}
{"text": "An example of psycholinguistically oriented research work can be found in Bond and Hayes ( 1983 ) .", "label": "Background", "metadata": {}}
{"text": "Alternatively , we may think of user-centered comparative studies ( Hersh et al. , 1995 ) .", "label": "Future", "metadata": {}}
{"text": "Relationships between the unlabeled items Carvalho and Cohen ( 2005 ) consider sequential relations between different types of emails ( e.g. , between requests and satisfactions thereof ) to classify messages , and thus also explicitly exploit the structure of conversations .", "label": "Background", "metadata": {}}
{"text": "100000 word stems of German ( Neumann et al. , 1997 ) .", "label": "Uses", "metadata": {}}
{"text": "The computational treatment of lexical rules proposed can be seen as an extension to the principled method discussed by Gotz and Meurers ( 1995 , 1996 , 1997b ) for encoding the main building block of HPSG grammars -- the implicative constraints -- as a logic program .", "label": "Extends", "metadata": {}}
{"text": "The goal of the JAVOX toolkit is to speech-enable traditional desktop applications -- this is similar to the goals of the MELISSA project ( Schmidt et al. , 1998 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The numeral ( whether it is implicit , as in ( 3 ) , or explicit ) can be construed as allowing the reader to draw inferences about the standards employed ( Kyburg and Morreau 2000 ; DeVault and Stone 2004 ) : ( 3 ) , for example , implies a standard that counts 10 cm as large and 8 cm as not large .", "label": "Background", "metadata": {}}
{"text": "On the other hand , experiments indicate that mental representation and processing of morphologically complex words are not quite language independent ( Taft , 2004 ) .", "label": "Background", "metadata": {}}
{"text": "ASARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework ( Pustejovsky , 1995 ) and called qualia relations ( Bouillon et al. , 2001 ) .", "label": "Background", "metadata": {}}
{"text": "For english , there is for instance the 15 year old HewlettPackard test suite , a simple text file listing test sentences and grouping them according to linguistics phenomena ( Flickinger et al. , 1987 ) ; and more recently , the much more sophisticated TSNLP ( Test Suite for Natural Language Processing ) which includes some 9500 test items for English , French and German , each of them being annotated with syntactic and application related information ( Oepen and Flickinger , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Its significance is reflected both in the growing interest in annotation software for word sense tagging ( Edmonds and Kilgarriff , 2002 ) and in the long-standing use of part-of-speech taggers , parsers and morphological analysers for data from English and many other languages .", "label": "Background", "metadata": {}}
{"text": "Each of these Values has equal status , so the notion of a basic-level Value can not play a role ( cfXXX , Dale and Reiter 1995 ) .", "label": "Background", "metadata": {}}
{"text": "Accuracy is not the best measure to assess segmentation quality , therefore we also conducted experiments using the WindowDiff measure as proposed by Pevzner and Hearst ( 2002 ) .", "label": "Uses", "metadata": {}}
{"text": "The system is in the form of an agenda-driven chart-based parser whose foundation is similar to previous formalizations of Chomsky 's Minimalist Program ( Stabler , 1997 ; Harkema , 2000 ; Niyogi , 2001 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Optimizing for dependency arc length is particularly important as parsers tend to do worse on longer dependencies ( McDonald and Nivre , 2007 ) and these dependencies are typically the most meaningful for downstream tasks , e.g. , main verb dependencies for tasks", "label": "Motivation", "metadata": {}}
{"text": "Whereas Rapp & Zock ( 2010 ) dealt only with an English corpus , the current work shows that this methodology is applicable to a wide range of languages and corpora .", "label": "CompareOrContrast", "metadata": {}}
{"text": "We also experiment with a CCG parser ( Clark and Curran , 2007 ) , requiring that the contexts surrounding the original phrase and paraphrase are assigned", "label": "Uses", "metadata": {}}
{"text": "Their kernel is also very time consuming and in their more general sparse setting it requires O ( mn3 ) time and O ( mn2 ) space , where m and n are the number of nodes of the two trees ( m > = n ) ( Zelenko et al. , 2003 ) .", "label": "Future", "metadata": {}}
{"text": "Other molecular biology databases We also included several model organism databases or nomenclature databases in the construction of the dictionary , i.e. , mouse Mouse Genome Database ( MGD ) [ 18 ] , fly FlyBase [ 19 ] , yeast Saccharomyces Genome Database ( SGD ) [ 20 ] , rat -- Rat Genome Database ( RGD ) [ 21 ] , worm -- WormBase [ 22 ] , Human Nomenclature Database ( HUGO ) [ 23 ] , Online Mendelian Inheritance in Man ( OMIM ) [ 24 ] , and Enzyme Nomenclature Database ( ECNUM ) [ 25 , 26 ] .", "label": "Uses", "metadata": {}}
{"text": "include decision tree learning and Bayesian learning , nearest neighbor learning , and artificial neural networks , early such works may be found in ( Lewis and Ringnette , 1994 ) , ( Creecy and Masand , 1992 ) and ( Wiene and Pedersen , 1995 ) , respectively .", "label": "Background", "metadata": {}}
{"text": "In other words AJAX is a web development technique for creating interactive web applications using a combination of XHTML and CSS , Document Object Model ( or DOM ) , the XMLHTTPRequest object ( Wikipedia , 2005 ) .", "label": "Background", "metadata": {}}
{"text": "converted to numerical features using the standard technique of binarization , and we split values of the FEATS field into its atomic components .4 For some languages , we divide the training data into smaller sets , based on some feature s ( normally the CPOS or POS of the next input token ) , which may reduce training times without a significant loss in accuracy ( Yamada and Matsumoto , 2003 ) .", "label": "Background", "metadata": {}}
{"text": "\u00e2\u0080\u00a2 language learning ( Green 1979 ; Mori and Moeser 1983 ; Morgan , Meier , and Newport 1989 ) \u00e2\u0080\u00a2 monolingual grammar induction ( Juola 1998 ) \u00e2\u0080\u00a2 grammar optimization ( Juola 1994 ) \u00e2\u0080\u00a2 insights into universal grammar ( Juola 1998 ) \u00e2\u0080\u00a2 machine translation ( Juola 1994 , 1997 ; Veale and Way 1997 ; Gough , Way , and Hearne 2002 )", "label": "Background", "metadata": {}}
{"text": "Linguistic preprocessing of text documents is carried out by re-using smes , an information extraction core system for real-world German text processing ( Neumann et al. , 1997 ) .", "label": "Uses", "metadata": {}}
{"text": "Regarding future work , there are many research line that may be followed : i ) Capturing more features by employing external knowledge such as ontological , lexical resource or WordNet-based features ( Basili et al. , 2005a ; Basili et al. , 2005b ; Bloehdorn et al. , 2006 ; Bloehdorn and Moschitti , 2007 ) or shallow semantic trees , ( Giuglea and Moschitti , 2004 ; Giuglea and Moschitti , 2006 ; Moschitti and Bejan , 2004 ; Moschitti et al. , 2007 ; Moschitti , 2008 ; Moschitti et al. , 2008 ) .", "label": "Future", "metadata": {}}
{"text": "For English \u00e2\u0088\u0092 > Urdu , Juola ( 1997 , page 213 ) notes that `` the system learned the original training corpus ... perfectly and could reproduce it without errors '' ; that is , it scored 100 % accuracy when tested against the training corpus .", "label": "Background", "metadata": {}}
{"text": "Much previous work looks at the impact of using source side information ( i.e. , feature functions on the aligned English ) , such as those of Avramidis and Koehn ( 2008 ) , Yeniterzi and Oflazer ( 2010 ) and others .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Recent work ( Banko and Brill , 2001 ; Curran and Moens , 2002 ) has suggested that some tasks will benefit from using significantly more data .", "label": "Background", "metadata": {}}
{"text": "The shallow parser used is the SNoW-based CSCL parser ( Punyakanok and Roth , 2001 ; Munoz et al. , 1999 ) .", "label": "Uses", "metadata": {}}
{"text": "Some well-known approaches include rule-based models ( Brill and Resnik 1994 ) , backed-off models ( Collins and Brooks 1995 ) , and a maximumentropy model ( Ratnaparkhi 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Soricut and Brill ( 2006 ) compared a predictive approach ( statistical translation ) , a retrieval approach based on a language-model , and a hybrid approach which combines statistical chunking and traditional retrieval .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Indeed , such rich semantic links can be used to extend indices or reformulate queries ( similar to the work by Voorhees ( 1994 ) with WoRDNET relations ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Despite these arguments , most applied NLG systems use a pipelined architecture ; indeed , a pipeline was used in every one of the systems surveyed by Reiter ( 1994 ) and Paiva ( 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Other similar approaches include those of Cicekli and G \u00c2\u00a8 uvenir ( 1996 ) , McTait and Trujillo ( 1999 ) , Carl ( 1999 ) , and Brown ( 2000 ) , inter alia .", "label": "Background", "metadata": {}}
{"text": "In addition to headwords , dictionary search through the pronunciation field is available ; Carter ( 1987 ) has merged information from the pronunciation and hyphenation fields , creating an enhanced phonological representation which allows access to entries by broad phonetic class and syllable structure ( Huttenlocher and Zue , 1983 ) .", "label": "Background", "metadata": {}}
{"text": "Following Hockenmaier , Bierner , and Baldridge ( 2002 ) , Xia ( 1999 ) , and Miyao , Ninomiya , and Tsujii ( 2004 ) , we extract a reference lexicon from Sections 02 -- 21 of the WSJ .", "label": "Uses", "metadata": {}}
{"text": "The only disambiguation metric that we used in our previous work ( Marcu , 1997b ) was the shape-based metric , according to which the `` best '' trees are those that are skewed to the right .", "label": "Extends", "metadata": {}}
{"text": "Every arc always has a definite direction , i.e. arcs are arrows ( Novak , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "6 For Sent-Pred we also experimented with grammatical and sentence-based syntactic features , such as number of syntactic phrases , grammatical mood , and grammatical person ( Marom and Zukerman 2006 ) , but the simple binary bag-of-lemmas representation yielded similar results .", "label": "Uses", "metadata": {}}
{"text": "At present , the system uses a heuristic matching algorithm to classify relations into the appropriate category , though in the future we may consider a classifier similar to Nielsen et al. ( 2008 ) .", "label": "Future", "metadata": {}}
{"text": "It is interesting to compare this analysis with that described in Dalrymple , Shieber , and Pereira ( 1991 ) and Pereira ( 1990 , 1991 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts ( Baker et al. , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "The example used to illustrate the power of ATNs ( Woods 1986 ) , `` John was believed to have been shot , '' also parses correctly , because the [ object ] node following the verb `` believed '' acts as both an absorber and a ( re ) generator .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Problems such as these have motivated research on more abstract , dependencybased parser evaluation ( e.g. , Lin 1995 ; Carroll , Briscoe , and Sanfilippo 1998 ; Carroll et al. 2002 ; Clark and Hockenmaier 2002 ; King et al. 2003 ; Preiss 2003 ; Kaplan et al. 2004 ; Miyao and Tsujii 2004 ) .", "label": "Motivation", "metadata": {}}
{"text": "As in ( Lee et al. , 2003 ) , we used unsupervised training data which is automatically segmented to discover previously unseen stems .", "label": "Uses", "metadata": {}}
{"text": "\u00e2\u0088\u0097 A brief version of this work , with some additional material , first appeared as ( Eisner , 2001a ) .", "label": "Extends", "metadata": {}}
{"text": "They also proposed two major categories of meta-learning approaches for recommender systems , merging and ensemble , each subdivided into the more specific subclasses suggested by Burke ( 2002 ) as follows .", "label": "Background", "metadata": {}}
{"text": "This heuristic is called soft union ( DeNero and Klein 2007 ) .", "label": "Uses", "metadata": {}}
{"text": "This approach has its roots in Fillmore 's Case Grammar ( 1968 ) , and serves as the foundation for two current large-scale semantic annotation projects : FrameNet ( Baker et al. , 1998 ) and PropBank ( Kingsbury et al. , 2002 ) .", "label": "Background", "metadata": {}}
{"text": "Many investigators ( e.g. Allen 1976 ; Elowitz et al. 1976 ; Luce et al. 1983 ; Cahn 1988 ) have suggested that the poor prosody of synthetic speech , in comparison with natural speech , is the primary factor leading to difficulties in the comprehension of fluent synthetic speech .", "label": "Motivation", "metadata": {}}
{"text": "The ability to explicitly identify these sections in unstructured text could play an important role in applications such as document summarization ( Teufel and Moens , 2000 ) , information retrieval ( Tbahriti et al. , 2005 ) , information extraction ( Mizuta et al. , 2005 ) , and question answering .", "label": "Background", "metadata": {}}
{"text": "Representative systems are described in Boisen et al. ( 1989 ) , De Mattia and Giachin ( 1989 ) , Niedermair ( 1989 ) , Niemann ( 1990 ) , and Young ( 1989 ) .", "label": "Background", "metadata": {}}
{"text": "R98 ( , , , , \u00e2\u0080\u009e ) uses a variant of Kozima 's semantic similarity measure ( Kozima , 1993 ) to compute block similarity .", "label": "Extends", "metadata": {}}
{"text": "We used a publicly available tagger ( Ratnaparkhi , 1996 ) to tag the words and then used these in the input to the system .", "label": "Uses", "metadata": {}}
{"text": "An off-the-shelf speech recognition device , a Nippon Electric Corporation DP-200 , was added to an existing natural language processing system , the Natural Language Computer ( NLC ) ( Ballard 1979 , Biermann and Ballard 1980 ) .", "label": "Background", "metadata": {}}
{"text": "But their importance has grown far beyond machine translation : for instance , transferring annotations between languages ( Yarowsky and Ngai 2001 ; Hwa et al. 2005 ; Ganchev , Gillenwater , and Taskar 2009 ) ; discovery of paraphrases ( Bannard and Callison-Burch 2005 ) ; and joint unsupervised POS and parser induction across languages ( Snyder and Barzilay 2008 ) .", "label": "Motivation", "metadata": {}}
{"text": "That is , if the current hypothesis is unable to label a candidate or is uncertain about it , then the candidate might be a good training example ( Lewis and Catlett 1994 ) .", "label": "Background", "metadata": {}}
{"text": "We perceive that these results can be extended to other language models that properly embed bilexical context-free grammars , as for instance the more general history-based models used in ( Ratnaparkhi , 1997 ) and ( Chelba and Jelinek , 1998 ) .", "label": "Future", "metadata": {}}
{"text": "Another paper ( Yoshinaga et al. , 2001 ) describes the detailed analysis on the factor of the difference of parsing performance .", "label": "Background", "metadata": {}}
{"text": "The Longman lexicographers have developed a grammar coding system capable of representing in compact form a nontrivial amount of information , usually to be found only in large descriptive grammars of English ( such as Quirk et al. , 1985 ) .", "label": "Background", "metadata": {}}
{"text": "Empirical evidence has been brought forward that inflectional and/or derivational stemmers augmented by dictionaries indeed perform substantially better than those without access to such lexical repositories ( Krovetz , 1993 ; Kraaij and Pohlmann , 1996 ; Tzoukermann et al. , 1997 ) .", "label": "Background", "metadata": {}}
{"text": "Although there are other discussions of the paragraph as a central element of discourse ( e.g. Chafe 1979 , Halliday and Hasan 1976 , Longacre 1979 , Haberlandt et al. 1980 ) , all of them share a certain limitation in their formal techniques for analyzing paragraph structure .", "label": "CompareOrContrast", "metadata": {}}
{"text": "( Details of how the average-expert model performs can be found in our prior work ( Xiong and Litman , 2011 ) . )", "label": "Extends", "metadata": {}}
{"text": "Self-training should also benefit other discriminatively trained parsers with latent annotations ( Petrov and Klein , 2008 ) , although training would be much slower compared to using generative models , as in our case .", "label": "Future", "metadata": {}}
{"text": "We introduce here a clearly defined and replicable split of the ACE 2004 data , so that future investigations can accurately and correctly compare against the results presented here .", "label": "Uses", "metadata": {}}
{"text": "In most cases , the accuracy of parsers degrades when run on out-of-domain data ( Gildea , 2001 ; McClosky et al. , 2006 ; Blitzer et al. , 2006 ; Petrov et al. , 2010 ) .", "label": "Background", "metadata": {}}
{"text": "Brent ( 1993 ) relies on morphosyntactic cues in the untagged Brown corpus as indicators of six predefined subcategorization frames .", "label": "Background", "metadata": {}}
{"text": "Ideally , to distinguish between raising and equi verbs , a number of syntactic criteria should be employed ( Perlmutter and Soames , 1979:460 ff . )", "label": "Future", "metadata": {}}
{"text": "The table also presents the closest comparable experimental results reported by McKnight and Srinivasan ( 2003 ) .1 McKnight and Srinivasan ( henceforth , M&S ) created a test collection consisting of 37,151 RCTs from approximately 12 million MEDLINE abstracts dated between 1976 and 2001 .", "label": "CompareOrContrast", "metadata": {}}
{"text": "How this mismatched perceptual basis affects referential communication in situated dialogue was investigated in our previous work ( Liu et al. , 2012 ) .", "label": "Extends", "metadata": {}}
{"text": "A cooccurrence based stemmer ( Xu and Croft , 1998 ) was used to stem Spanish words .", "label": "Uses", "metadata": {}}
{"text": "The best performance on the WSJ corpus was achieved by a combination of the SATZ system ( Palmer and Hearst 1997 ) with the Alembic system ( Aberdeen et al. 1995 ) : a 0.5 % error rate .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In a number of proposals , lexical generalizations are captured using lexical underspecification ( Kathol 1994 ; Krieger and Nerbonne 1992 ;", "label": "CompareOrContrast", "metadata": {}}
{"text": "The bottom panel of table 1 lists the results for the chosen lexicalized model ( SSN-Freq > 200 ) and five recent statistical parsers ( Ratnaparkhi , 1999 ; Collins , 1999 ; Charniak , 2000 ; Collins , 2000 ; Bod , 2001 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "linguistic in nature , rather than dealing with superficial properties of the text , e.g. the amount of white space between words ( Por et al. , 2008 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Another line of research that is correlated with ours is recognition of agreement/disagreement ( Misra and Walker , 2013 ; Yin et al. , 2012 ; Abbott et al. , 2011 ; Andreas et al. , 2012 ; Galley et al. , 2004 ; Hillard et al. , 2003 ) and classification of stances ( Walker et al. , 2012 ; Somasundaran and Wiebe , 2010 ) in online forums .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The studies presented by Goldwater and Griffiths ( 2007 ) and Johnson ( 2007 ) differed in the number of states that they used .", "label": "CompareOrContrast", "metadata": {}}
{"text": "A number of alignment techniques have been proposed , varying from statistical methods ( Brown et al. , 1991 ; Gale and Church , 1991 ) to lexical methods ( Kay and Roscheisen , 1993 ; Chen , 1993 ) .", "label": "Background", "metadata": {}}
{"text": "We would like to use features that look at wide context on the input side , which is inexpensive ( Jiampojamarn et al. , 2007 ) .", "label": "Future", "metadata": {}}
{"text": "Much of the earlier work in anaphora resolution heavily exploited domain and linguistic knowledge ( Sidner 1979 ; Carter 1987 ; Rich and LuperFoy 1988 ; Carbonell and Brown 1988 ) , which was difficult both to represent and to process , and which required considerable human input .", "label": "Background", "metadata": {}}
{"text": "This is then generalized , following a methodology based on Block ( 2000 ) , to generate the `` generalized marker lexicon . ''", "label": "Uses", "metadata": {}}
{"text": "A number of speech understanding systems have been developed during the past fifteen years ( Barnett et al. 1980 , Dixon and Martin 1979 , Erman et al. 1980 , Haton and Pierrel 1976 , Lea 1980 , Lowerre and Reddy 1980 , Medress 1980 , Reddy 1976 , Walker 1978 , and Wolf and Woods 1980 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Our proposed method is based on the automatically acquired paraphrase dictionary described in Callison-Burch ( 2008 ) , in which the application of paraphrases from the dictionary encodes secret bits .", "label": "Uses", "metadata": {}}
{"text": "These knowledge sources were effectively used to build a state-of-the-art WSD program in one of our prior work ( Lee and Ng , 2002 ) .", "label": "Extends", "metadata": {}}
{"text": "Another line of research approaches grounded language knowledge by augmenting distributional approaches of word meaning with perceptual information ( Andrews et al. , 2009 ; Steyvers , 2010 ; Feng and Lapata , 2010b ; Bruni et al. , 2011 ; Silberer and Lapata , 2012 ; Johns and Jones , 2012 ; Bruni et al. , 2012a ; Bruni et al. , 2012b ; Silberer et al. , 2013 ) .", "label": "Background", "metadata": {}}
{"text": "Due to advances in statistical syntactic parsing techniques ( Collins , 1997 ; Charniak , 2001 ) , attention has recently shifted towards the harder question of analyzing the meaning of natural language sentences .", "label": "Background", "metadata": {}}
{"text": "This is where robust syntactic systems like SATZ ( Palmer and Hearst 1997 ) or the POS tagger reported in Mikheev ( 2000 ) , which do not heavily rely on word capitalization and are not sensitive to document length , have an advantage .", "label": "CompareOrContrast", "metadata": {}}
{"text": "category relationships from the weak supervision : the tag dictionary and raw corpus ( Garrette and Baldridge , 2012 ; Garrette et al. , 2015 ) .4 This procedure attempts to automatically estimate the frequency of each word/tag combination by dividing the number of raw-corpus occurrences of each word in the dictionary evenly across all of its associated tags .", "label": "Uses", "metadata": {}}
{"text": "WIT has been implemented in Common Lisp and C on UNIX , and we have built several experimental and demonstration dialogue systems using it , including a meeting room reservation system ( Nakano et al. , 1999b ) , a video-recording programming system , a schedule management system ( Nakano et al. , 1999a ) , and a weather infomiation system ( Dohsaka et al. , 2000 ) .", "label": "Extends", "metadata": {}}
{"text": "Sarkar and Zeman ( 2000 ) present an approach to learn previously unknown frames for Czech from the Prague Dependency Bank ( Hajic", "label": "Background", "metadata": {}}
{"text": "A companion paper describes the evaluation process and results in further detail ( Chu-Carroll and Nickerson , 2000 ) .", "label": "Extends", "metadata": {}}
{"text": "Hence , enumerating morphological variants in a semi-automatically generated lexicon , such as proposed for French ( Zweigenbaum et al. , 2001 ) , turns out to be infeasible , at least for German and related languages .", "label": "Background", "metadata": {}}
{"text": "The results , which partly confirm those obtained on a smaller dataset in Paggio and Navarretta ( 2010 ) , must be seen in light of the fact that our gesture annotation scheme comprises more fine-grained categories than most of the studies mentioned earlier for both head movements and face expressions .", "label": "CompareOrContrast", "metadata": {}}
{"text": "It has also been shown to be useful in joint inference of text with visual attributes obtained using visual classifiers ( Silberer et al. , 2013 ) .", "label": "Background", "metadata": {}}
{"text": "Gurevych ( 2006 ) reported a correlation of r = .69 .", "label": "CompareOrContrast", "metadata": {}}
{"text": "As has been previously observed and exploited in the NLP literature ( Pang and Lee , 2004 ; Agarwal and Bhattacharyya , 2005 ; Barzilay and Lapata , 2005 ) , the above optimization function , unlike many others that have been proposed for graph or set partitioning , can be solved exactly in an provably efficient manner via methods for finding minimum cuts in graphs .", "label": "CompareOrContrast", "metadata": {}}
{"text": "WIT features an incremental understanding method ( Nakano et al. , 1999b ) that makes it possible to build a robust and real-time system .", "label": "Uses", "metadata": {}}
{"text": "As for work on Arabic ( MSA ) , results have been reported on the PATB ( Kulick , Gabbard , and Marcus 2006 ; Diab 2007 ; Green and Manning 2010 ) , the Prague Dependency Treebank ( PADT ) ( Buchholz and Marsi 2006 ; Nivre 2008 ) and the CATiB ( Habash and Roth 2009 ) .", "label": "Background", "metadata": {}}
{"text": "Other studies which view lR as a query generation process include Maron and Kuhns , 1960 ; Hiemstra and Kraaij , 1999 ; Ponte and Croft , 1998 ; Miller et al , 1999 .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Hook ( 1981 ) considers the second verb V2 as an aspectual complex comparable to the auxiliaries .", "label": "Background", "metadata": {}}
{"text": "2We could just as easily use other symmetric `` association '' measures , such as 02 ( Gale & Church , 1991 ) or the Dice coefficient ( Smadja , 1992 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The use of the web as a corpus for teaching and research on language has been proposed a number of times ( Kilgarriff , 2001 ; Robb , 2003 ; Rundell , 2000 ; Fletcher , 2001 , 2004b ) and received a special issue of the journal Computational Linguistics ( Kilgarriff and Grefenstette , 2003 ) .", "label": "Background", "metadata": {}}
{"text": "\u00e2\u0080\u00a2 Learnability ( Zernik and Dyer 1987 ) \u00e2\u0080\u00a2 Text generation ( Hovy 1988 ; Milosavljevic , Tulloch , and Dale 1996 ) \u00e2\u0080\u00a2 Speech generation ( Rayner and Carter 1997 ) \u00e2\u0080\u00a2 Localization ( Sch \u00c2\u00a8 aler 1996 )", "label": "Background", "metadata": {}}
{"text": "Following our previous work on stance classification ( Hasan and Ng , 2013c ) , we employ three types of features computed based on the frame-semantic parse of each sentence in a post obtained from SEMAFOR ( Das et al. , 2010 ) .", "label": "Extends", "metadata": {}}
{"text": "However , the literature on Linguistic Steganography , in which linguistic properties of a text are modified to hide information , is small compared with other media ( Bergmair , 2007 ) .", "label": "Background", "metadata": {}}
{"text": "We use the Clark and Curran ( 2007 ) CCG parser to analyse the sentence before and after paraphrasing .", "label": "Uses", "metadata": {}}
{"text": "For example , consider a relational description ( cfXXX , Dale and Haddock 1991 ) involving a gradable adjective , as in the dog in the large shed .", "label": "Background", "metadata": {}}
{"text": "Previous versions of our work , as described in Bachenko et al. ( 1986 ) also assume that phrasing is dependent on predicate-argument structure .", "label": "Extends", "metadata": {}}
{"text": "The inclusion of the coreference task in the Sixth and Seventh Message Understanding Conferences ( MUC-6 and MUC-7 ) gave a considerable impetus to the development of coreference resolution algorithms and systems , such as those described in Baldwin et al. ( 1995 ) , Gaizauskas and Humphreys ( 1996 ) , and Kameyama ( 1997 ) .", "label": "Background", "metadata": {}}
{"text": "This includes work on generalized expectation ( Mann and McCallum , 2010 ) , posterior regularization ( Ganchev et al. , 2010 ) and constraint driven learning ( Chang et al. , 2007 ; Chang et al. , 2010 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The final machine is a trigram language model , specifically a Kneser-Ney ( Chen and Goodman , 1998 ) based backoff language model .", "label": "Uses", "metadata": {}}
{"text": "Hovy has described another text planner that builds similar plans ( Hovy 1988b ) .", "label": "Background", "metadata": {}}
{"text": "As an alternative , we rely on PubMed to retrieve an initial set of hits that we then postprocess in greater detail -- this is the standard pipeline architecture commonly employed in other question-answering systems ( Voorhees and Tice 1999 ; Hirschman and Gaizauskas 2001 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Since we are not generating from the model , this does not introduce difficulties ( Klein and Manning , 2002 ) .", "label": "Motivation", "metadata": {}}
{"text": "The extraction procedure consists of three steps : First , the bracketing of the trees in the Penn Treebank is corrected and extended based on the approaches of Magerman ( 1994 ) and Collins ( 1997 ) .", "label": "Background", "metadata": {}}
{"text": "Corpus frequency : ( Vosse , 1992 ) differentiates between misspellings and neologisms ( new words ) in terms of their frequency .", "label": "Uses", "metadata": {}}
{"text": "We use an in-house developed hierarchical phrase-based translation ( Chiang , 2005 ) as our baseline system , and we denote it as In-Hiero .", "label": "Uses", "metadata": {}}
{"text": "The task we used to compare different generalisation techniques is similar to that used by Pereira et al. ( 1993 ) and Rooth et al. ( 1999 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The Nash arbitration plan , for example , would allow a doubly graded description whenever the product of the Values for the referent r exceeds that of all distractors ( Nash 1950 ; cfXXX Gorniak and Roy 2003 ; Thorisson 1994 , for other plans ) .", "label": "Background", "metadata": {}}
{"text": "Notable early papers on graph-based semisupervised learning include Blum and Chawla ( 2001 ) , Bansal et al. ( 2002 ) , Kondor and Lafferty ( 2002 ) , and Joachims ( 2003 ) .", "label": "Background", "metadata": {}}
{"text": "Thus for instance , ( Copestake and Flickinger , 2000 ; Copestake et al. , 2001 ) describes a Head Driven Phrase Structure Grammar ( HPSG ) which supports the parallel construction of a phrase structure ( or derived ) tree and of a semantic representation and ( Dalrymple , 1999 ) show how to equip Lexical Functional grammar ( LFG ) with a glue semantics .", "label": "Background", "metadata": {}}
{"text": "The contextual interpreter then uses a reference resolution approach similar to Byron ( 2002 ) , and an ontology mapping mechanism ( Dzikovska et al. , 2008a ) to produce a domain-specific semantic representation of the student 's output .", "label": "Uses", "metadata": {}}
{"text": "In the transducers produced by the training method described in this paper , the source and target positions are in the set -LCB- -1 , 0,1 -RCB- , though we have also used handcoded transducers ( Alshawi and Xia 1997 ) and automatically trained transducers ( Alshawi and Douglas 2000 ) with a larger range of positions .", "label": "Uses", "metadata": {}}
{"text": "would be chunked as follows ( Tjong Kim Sang and Buchholz , 2000 ) : [ NP He ] [ VP reckons ] [ NP the current account deficit ] [ VP will narrow ] [ PP", "label": "Background", "metadata": {}}
{"text": "5An alternative strategy to step ( 4 ) is to perform a database lookup based on the ambiguous query and summarize the results ( Litman et al. , 1998 ) , which we leave for future work .", "label": "Future", "metadata": {}}
{"text": "Typed feature grammars can be used as the basis for implementations of Head-driven Phrase Structure Grammar ( HPSG ; Pollard and Sag , 1994 ) as discussed in ( Gotz and Meurers , 1997a ) and ( Meurers and Minnen , 1997 ) .", "label": "Extends", "metadata": {}}
{"text": "ones , DIRT ( Lin and Pantel , 2001 ) , VerbOcean ( Chklovski and Pantel , 2004 ) , FrameNet ( Baker et al. , 1998 ) , and Wikipedia ( Mehdad et al. , 2010 ; Kouylekov et al. , 2009 ) .", "label": "Background", "metadata": {}}
{"text": "The Ruby on Rails ( 2006 ) framework permits us to quickly develop web applications without rewriting common functions and classes .", "label": "Uses", "metadata": {}}
{"text": "Morris and Hirst ( 2004 ) pointed out that many relations between words in a text are non-classical ( i.e. other than typical taxonomic relations like synonymy or hypernymy ) and therefore not covered by semantic similarity .", "label": "Background", "metadata": {}}
{"text": "In 2009 , the second WePS campaign showed similar trends regarding the use of NE features ( Artiles et al. , 2009 ) .", "label": "Background", "metadata": {}}
{"text": "The head words can be automatically extracted using a heuristic table lookup in the manner described by Magerman ( 1994 ) .", "label": "Uses", "metadata": {}}
{"text": "Reiter describes a pipelined modular approach as a consensus architecture underlying most recent work in generation ( Reiter 1994 ) .", "label": "Background", "metadata": {}}
{"text": "The RenTAL system is implemented in LiLFeS ( Makino et al. , 1998 ) 2 .", "label": "Uses", "metadata": {}}
{"text": "In the future , we hope to evaluate the automatic annotations and extracted lexicon against Propbank ( Kingsbury and Palmer 2002 ) .", "label": "Future", "metadata": {}}
{"text": "One way to increase the precision of the mapping process is to impose some linguistic constraints on the sequences such as simple noun-phrase contraints ( Gaussier , 1995 ; Kupiec , 1993 ; hua Chen and Chen , 94 ; Fung , 1995 ; Evans and Zhai , 1996 ) .", "label": "Uses", "metadata": {}}
{"text": "Although this study falls under the general topic of discourse modeling , our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements ( McKeown , 1985 ; Marcu and Echihabi , 2002 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "`` Coherence , '' as outlined above , can be understood as a declarative ( or static ) version of marker passing ( Hirst 1987 ; Charniak 1983 ) , with one difference : the activation spreads to theories that share a predicate , not through the IS-A hierarchy , and is limited to elementary facts about predicates appearing in the text .", "label": "CompareOrContrast", "metadata": {}}
{"text": "First , it has been noted that in many natural language applications it is sufficient to use shallow parsing information ; information such as noun phrases ( NPs ) and other syntactic sequences have been found useful in many large-scale language processing applications including information extraction and text summarization ( Grishman , 1995 ; Appelt et al. , 1993 ) .", "label": "Background", "metadata": {}}
{"text": "In addition , a fully flexible access system allows the retrieval of dictionary entries on the basis of constraints specifying any combination of phonetic , lexical , syntactic , and semantic information ( Boguraev et al. , 1987 ) .", "label": "Background", "metadata": {}}
{"text": "Machine learning methods should be interchangeable : Transformation-based learning ( TBL ) ( Brill , 1993 ) and Memory-based learning ( MBL ) ( Daelemans et al. , 2002 ) have been applied to many different problems , so a single interchangeable component should be used to represent each method .", "label": "Motivation", "metadata": {}}
{"text": "We tested the classification of verbs into semantic types using a verb list of 139 pre-classified items drawn from the lists published in Rosenbaum ( 1967 ) and Stockwell et al. ( 1973 ) .", "label": "Uses", "metadata": {}}
{"text": "The combination of likelihood and prior modeling , HMMs , and Viterbi decoding is fundamentally the same as the standard probabilistic approaches to speech recognition ( Bahl , Jelinek , and Mercer 1983 ) and tagging ( Church 1988 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The EDR has close ties to the named entity recognition ( NER ) and coreference resolution tasks , which have been the focus of several recent investigations ( Bikel et al. , 1997 ; Miller et al. , 1998 ; Borthwick , 1999 ; Mikheev et al. , 1999 ; Soon et al. , 2001 ; Ng and Cardie , 2002 ; Florian et al. , 2004 ) , and have been at the center of evaluations such as : MUC-6 , MUC-7 , and the CoNLL '02 and CoNLL '03 shared tasks .", "label": "Background", "metadata": {}}
{"text": "Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit ( Ngai and Florian , 2001 ) which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging ( Roche and Schabes , 1997 ) .", "label": "Background", "metadata": {}}
{"text": "This observation has led some researchers , e.g. , Cooper and Paccia-Cooper ( 1980 ) , to claim a direct mapping between the syntactic phrase and the prosodic phrase .", "label": "Background", "metadata": {}}
{"text": "In our previous work ( Zhang and Chai , 2009 ) , conversation entailment is formulated as the following : given a conversation segment D which is represented by a set of clauses D = d1 \u00e2\u0088\u00a7 ... \u00e2\u0088\u00a7 dm , and a hypothesis H represented by another set of clauses H = h1 \u00e2\u0088\u00a7 ... \u00e2\u0088\u00a7 hn , the prediction on whether D entails H is determined by the product of probabilities that each hypothesis clause hj is entailed from all the conversation segment clauses d1 ... dm as follows .", "label": "Extends", "metadata": {}}
{"text": "In addition , we consider several types of lexical features ( LexF ) inspired by previous work on agreement and disagreement ( Galley et al. , 2004 ; Misra and Walker , 2013 ) .", "label": "Motivation", "metadata": {}}
{"text": "Berger et al. ( 2000 ) compared two retrieval approaches ( TF.IDF and query expansion ) and two predictive approaches ( statistical translation and latent variable models ) .", "label": "Background", "metadata": {}}
{"text": "At the same time , we believe our method has advantages over the approach developed initially at IBM ( Brown et al. 1990 ; Brown et al. 1993 ) for training translation systems automatically .", "label": "CompareOrContrast", "metadata": {}}
{"text": "The basic Python reflection has already been implemented and used for large scale experiments with POS tagging , using pyMPI ( a message passing interface library for Python ) to coordinate experiments across a cluster of over 100 machines ( Curran and Clark , 2003 ; Clark et al. , 2003 ) .", "label": "Background", "metadata": {}}
{"text": "The language grounding problem has received significant attention in recent years , owed in part to the wide availability of data sets ( e.g. Flickr , Von Ahn ( 2006 ) ) , computing power , improved computer vision models ( Oliva and Torralba , 2001 ; Lowe , 2004 ; Farhadi et al. , 2009 ; Parikh and Grauman , 2011 ) and neurological evidence of ties between the language , perceptual and motor systems in the brain ( Pulverm \u00c2\u00a8 uller et al. , 2005 ; Tettamanti et al. , 2005 ; Aziz-Zadeh et al. , 2006 ) .", "label": "Background", "metadata": {}}
{"text": "Although in this paper we take modus ponens as the main rule of inference , in general one can consider deductive closures with respect to weaker , nonstandard logics , ( cfXXX Levesque 1984 ; Frisch 1987 ; Patel-Schneider 1985 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "As Alshawi ( 1987 ) points out , given that no situations were envisaged where the information from the tape would be altered once installed in secondary storage , this simple and convenComputational Linguistics , Volume 13 , Numbers 3-4 , July-December 1987 205 Bran Boguraev and Ted Briscoe Large Lexicons for Natural Language Processing tional access strategy is perfectly adequate .", "label": "Background", "metadata": {}}
{"text": "This paper describes an approach for sharing resources in various grammar formalisms such as Feature-Based Lexicalized Tree Adjoining Grammar ( FB-LTAG1 ) ( Vijay-Shanker , 1987 ; Vijay-Shanker and Joshi , 1988 ) and Head-Driven Phrase Structure Grammar ( HPSG ) ( Pollard and Sag , 1994 ) by a method of grammar conversion .", "label": "Background", "metadata": {}}
{"text": "There is a general consensus among theoretical linguists that the proper representation of verbal argument structure is event structure -- representations grounded in a theory of events that decompose semantic roles in terms of primitive predicates representing concepts such as causality and inchoativity ( Dowty , 1979 ; Jackendoff , 1983 ; Pustejovsky , 1991b ; Rappaport Hovav and Levin , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Niyogi ( 2001 ) has developed an agenda-driven chart parser for the feature-driven formalism described above ; please refer to his paper for a description of the parsing algorithm .", "label": "Extends", "metadata": {}}
{"text": "An example of psycholinguistically oriented research work can be found in Bond and Hayes ( 1983 ) .", "label": "Background", "metadata": {}}
{"text": "Some well-known approaches include rule-based models ( Brill and Resnik 1994 ) , backed-off models ( Collins and Brooks 1995 ) , and a maximumentropy model ( Ratnaparkhi 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Against the background of a growing interest in multilingual NLP , multilingual anaphora / coreference resolution has gained considerable momentum in recent years ( Aone and McKee 1993 ; Azzam , Humphreys , and Gaizauskas 1998 ; Harabagiu and Maiorano 2000 ; Mitkov and Barbu 2000 ; Mitkov 1999 ; Mitkov and Stys 1997 ; Mitkov , Belguith , and Stys 1998 ) .", "label": "Background", "metadata": {}}
{"text": "The research described below is taking place in the context of three collaborative projects ( Boguraev , 1987 ; Russell et al. , 1986 ; Phillips and Thompson , 1986 ) to develop a general-purpose , wide coverage morphological and syntactic analyser for English .", "label": "Background", "metadata": {}}
{"text": "In most cases , the accuracy of parsers degrades when run on out-of-domain data ( Gildea , 2001 ; McClosky et al. , 2006 ; Blitzer et al. , 2006 ; Petrov et al. , 2010 ) .", "label": "Background", "metadata": {}}
{"text": "This paper presents experiments with generative content models for analyzing the discourse structure of medical abstracts , which has been confirmed to follow the four-section pattern discussed above ( Salanger-Meyer , 1990 ) .", "label": "Background", "metadata": {}}
{"text": "Following Lekakos and Giaglis ( 2007 ) , one approach for achieving this objective consists of applying supervised learning , where a winning method is selected for each case in the training set , all the training cases are labeled accordingly , and then the system is trained to predict a winner for unseen cases .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Thus , over the past few years , along with advances in the use of learning and statistical methods for acquisition of full parsers ( Collins , 1997 ; Charniak , 1997a ; Charniak , 1997b ; Ratnaparkhi , 1997 ) , significant progress has been made on the use of statistical learning methods to recognize shallow parsing patterns syntactic phrases or words that participate in a syntactic relationship ( Church , 1988 ; Ramshaw and Marcus , 1995 ; Argamon et al. , 1998 ; Cardie and Pierce , 1998 ; Munoz et al. , 1999 ; Punyakanok and Roth , 2001 ; Buchholz et al. , 1999 ; Tjong Kim Sang and Buchholz , 2000 ) .", "label": "Background", "metadata": {}}
{"text": "For MT the most commonly used heuristic is called grow diagonal final ( Och and Ney 2003 ) .", "label": "CompareOrContrast", "metadata": {}}
{"text": "ECM-F is an entity-constrained mention Fmeasure ( cfXXX ( Luo et al. , 2004 ) for how ECM-F is computed ) , and ACE-Value is the official ACE evaluation metric .", "label": "Uses", "metadata": {}}
{"text": "In order to obtain semantic representations of each word , we apply our previous strategy ( Schone and Jurafsky ( 2000 ) ) .", "label": "Extends", "metadata": {}}
{"text": "Finkelstein et al. ( 2002 ) annotated a larger set of word pairs ( 353 ) , too .", "label": "Background", "metadata": {}}
{"text": "A more flexible approach is used by Reiter and Sripada ( 2002 ) , where users can specify boundary values for attributes like rainfall , specifying , for example , rain counts as moderate above 7 mm/h , as heavy above 20 mm/h , and so on .", "label": "Background", "metadata": {}}
{"text": "Shaw and Hatzivassiloglou ( 1999 ) propose to generalize the direct evidence method so that it can apply to unseen pairs of adjectives by computing the transitive closure of the ordering relation .", "label": "Background", "metadata": {}}
{"text": "Other attempts to address efficiency include the fast Transformation Based Learning ( TBL ) Toolkit ( Ngai and Florian , 2001 ) which dramatically speeds up training TBL systems , and the translation of TBL rules into finite state machines for very fast tagging ( Roche and Schabes , 1997 ) .", "label": "Background", "metadata": {}}
{"text": "The best results on most of our data were obtained using Hidden Naive Bayes ( HNB ) ( Zhang et al. , 2005 ) .", "label": "Uses", "metadata": {}}
{"text": "de URL : http://www.sfs.nphil.uni-tuebingen.de/sfb / b4home.html 1 This is , for example , the case for all proposals working with verbal lexical entries that raise the arguments of a verbal complement ( Hinrichs and Nakazawa 1989 ) that also use lexical rules such as the Complement Extraction Lexical Rule ( Pollard and Sag 1994 ) or the Complement Cliticization Lexical Rule ( Miller and Sag 1993 ) to operate on those raised elements .", "label": "Background", "metadata": {}}
{"text": "A number of proposals in the 1990s deliberately limited the extent to which they relied on domain and/or linguistic knowledge and reported promising results in knowledge-poor operational environments ( Dagan and Itai 1990 , 1991 ; Lappin and Leass 1994 ; Nasukawa 1994 ; Kennedy and Boguraev 1996 ; Williams , Harvey , and Preston 1996 ; Baldwin 1997 ; Mitkov 1996 , 1998b ) .", "label": "Background", "metadata": {}}
{"text": "ASARES has been previously applied to the acquisition of word pairs sharing semantic relations defined in the Generative Lexicon framework ( Pustejovsky , 1995 ) and called qualia relations ( Bouillon et al. , 2001 ) .", "label": "Background", "metadata": {}}
{"text": "mlSystem ruleFeats + atomFeats We augment mlSystem ruleFeats with more features from our previous work ( Markert et al. , 2012 ; Hou et al. , 2013a ; Hou et al. , 2013b ) on bridging anaphora recognition and antecedent selection .", "label": "Extends", "metadata": {}}
{"text": "An exception is Grefenstette et al. ( 2004 ) , who experimented with determining the political orientation of websites essentially by classifying the concatenation of all the documents found on that site .", "label": "Background", "metadata": {}}
{"text": "The three preprocessing steps ( tokenization , POS-tagging , lemmatization ) are performed using TreeTagger ( Schmid , 1995 ) .", "label": "Uses", "metadata": {}}
{"text": "Many statistical parsers ( Ratnaparkhi , 1999 ; Collins , 1999 ; Charniak , 2001 ) are based on a history-based probability model ( Black et al. , 1993 ) , where the probability of each decision in a parse is conditioned on the previous decisions in the parse .", "label": "Background", "metadata": {}}
{"text": "This strategy is certainly the right one to start out with , since anaphora is always the more typical direction of reference in English prose ( Halliday and Hasan 1976 , p. 329 ) .", "label": "Motivation", "metadata": {}}
{"text": "This indicates that parse trees are usually not the optimal choice for training tree-based translation models ( Wang et al. , 2010 ) .", "label": "Background", "metadata": {}}
{"text": "For example , the forward-backward algorithm ( Baum , 1972 ) trains only Hidden Markov Models , while ( Ristad and Yianilos , 1996 ) trains only stochastic edit distance .", "label": "Background", "metadata": {}}
{"text": "ment ( Sarkar and Wintner , 1999 ; Doran et al. , 2000 ; Makino et al. , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Manning ( 1993 ) argues that , aside from missing domain-specific complementation trends , dictionaries produced by hand will tend to lag behind real language use because of their static nature .", "label": "Motivation", "metadata": {}}
{"text": "Burkett and Klein ( 2008 ) and Burkett et al. ( 2010 ) focused on joint parsing and alignment .", "label": "CompareOrContrast", "metadata": {}}
{"text": "But the general outlines are reasonably clear , and we can adapt some of the UDRS ( Reyle 1995 ) work to our own framework .", "label": "Uses", "metadata": {}}
{"text": "KUbler , McDonald , and Nivre ( 2009 ) describe a `` typical '' MaltParser model configuration of attributes and features .13 Starting with it , in a series of initial controlled experiments , we settled on using buf [ 0-1 ] + stk [ 0-1 ] for word-forms , and buf [ 0-3 ] + stk [ 0-2 ] for POS tags .", "label": "Uses", "metadata": {}}
{"text": "For this evaluation , we randomly selected 50 abstracts with disorders indexed as the main topic from abstracts retrieved using PubMed on the five clinical questions described in Sneiderman et al. ( 2005 ) .", "label": "Uses", "metadata": {}}
{"text": "Previous work on Chinese SRL mainly focused on how to transplant the machine learning methods which has been successful with English , such as Sun and Jurafsky ( 2004 ) , Xue and Palmer ( 2005 ) and Xue ( 2008 ) .", "label": "Background", "metadata": {}}
{"text": "`` Coherence , '' as outlined above , can be understood as a declarative ( or static ) version of marker passing ( Hirst 1987 ; Charniak 1983 ) , with one difference : the activation spreads to theories that share a predicate , not through the IS-A hierarchy , and is limited to elementary facts about predicates appearing in the text .", "label": "CompareOrContrast", "metadata": {}}
{"text": "In addition , the advantages of using linguistically annotated data over raw data are well documented ( Mair , 2005 ; Granger and Rayson , 1998 ) .", "label": "Background", "metadata": {}}
{"text": "Other similar approaches include those of Cicekli and G \u00c2\u00a8 uvenir ( 1996 ) , McTait and Trujillo ( 1999 ) , Carl ( 1999 ) , and Brown ( 2000 ) , inter alia .", "label": "Background", "metadata": {}}
{"text": "Burkett and Klein ( 2012 ) utilized a transformation-based method to learn a sequence of monolingual tree transformations for translation .", "label": "CompareOrContrast", "metadata": {}}
{"text": "Therefore , we preprocess Ontonote-5 .0 to derive mention heads using Collins head rules ( Collins , 1999 ) with gold constituency parsing information and gold named entity information .", "label": "Uses", "metadata": {}}
{"text": "We have presented an ensemble approach to word sense disambiguation ( Pedersen , 2000 ) where multiple Naive Bayesian classifiers , each based on co -- occurrence features from varying sized windows of context , is shown to perform well on the widely studied nouns interest and line .", "label": "Background", "metadata": {}}
{"text": "Nevertheless , the full document text is present in most systems , sometimes as the only feature ( Sugiyama and Okumura , 2007 ) and sometimes in combination with others see for instance ( Chen and Martin , 2007 ; Popescu and Magnini , 2007 ) - .", "label": "Background", "metadata": {}}
{"text": "The recognizer for these systems is the SUMMIT system ( Zue et al. 1989 ) , which uses a segmental-based framework and includes an auditory model in the front-end processing .", "label": "Uses", "metadata": {}}
{"text": "To sample from our proposal distribution , we use a blocked Gibbs sampler based on the one proposed by Goodman ( 1998 ) and used by Johnson et al. ( 2007 ) that samples entire parse trees .", "label": "Uses", "metadata": {}}
{"text": "Semantic construction proceeds from the derived tree ( Gardent and Kallmeyer , 2003 ) rather than -- as is more common in TAG -- from the derivation tree .", "label": "Background", "metadata": {}}
{"text": "It allows the construction of a non-TAL ( Shieber , 1994 ) , ( Harbusch & Poller , 2000 ) .", "label": "Background", "metadata": {}}
{"text": "Following previous work ( e.g. , Soon et al. ( 2001 ) and Ponzetto and Strube ( 2006 ) ) , we generate training instances as follows : a positive instance is created for each anaphoric NP , NPj , and its closest antecedent , NPi ; and a negative instance is created for NPj paired with each of the intervening NPs , NPi +1 , NPi +2 , ... , NPj_1 .", "label": "Uses", "metadata": {}}
{"text": "The gap mechanism resembles the Hold register idea of ATNs ( Woods 1970 ) and the treatment of bounded domination metavariables in lexical functional grammars ( LFGs ) ( Bresnan 1982 , p. 235 ff . )", "label": "CompareOrContrast", "metadata": {}}
